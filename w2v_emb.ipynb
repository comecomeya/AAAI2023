{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5133a39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T06:48:16.778360Z",
     "start_time": "2023-01-03T06:48:13.669778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=False)\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "def groupApplyParallel(dfGrouped, func_dict):\n",
    "    # groupApplyParallel(df.groupby('abc'), {'add':lambda df: df['a']=df['b']+df['c']})\n",
    "    def multi_agg(group, func_dict):\n",
    "        for name, func in func_dict.items():\n",
    "            df[name] = func(group)\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(multi_agg)(group, func_dict) for name, group in dfGrouped)\n",
    "    return pd.concat(retLst)\n",
    "\n",
    "def quant(n):\n",
    "    def quantile_(x):\n",
    "        return np.quantile(x, n)\n",
    "    quantile_.__name__ = 'quantile_%s' % n\n",
    "    return quantile_\n",
    "\n",
    "def groupAggParallel(dfGrouped, func_dict):\n",
    "    # groupAggParallel(df.groupby('abc'), {'mean':np.mean, 'count':len})\n",
    "    def multi_agg(group, group_name, func_list):\n",
    "        res = list(group_name) if type(group_name) in (list, tuple) else [group_name]\n",
    "        for func in func_list:\n",
    "            res.append(func(group))\n",
    "        return res\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(multi_agg)(group, group_name, func_dict.values()) for group_name, group in dfGrouped)\n",
    "    print(retLst)\n",
    "    retLst = pd.DataFrame(retLst, columns=list(dfGrouped.grouper.result_index.names)+list(func_dict.keys()))\n",
    "    return retLst\n",
    "\n",
    "from tqdm import tqdm as tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from chinese_calendar import is_workday\n",
    "import datetime\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "\n",
    "RANDOM_SEED = 1\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88722888",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T07:09:40.639747Z",
     "start_time": "2023-01-03T06:56:03.100414Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "PREFIX = './'\n",
    "#df_train1 = pd.read_csv(PREFIX+'/input/AAAI2023Competition/train.csv')\n",
    "#df_test1 = pd.read_csv(PREFIX+'/input/AAAI2023Competition/test.csv')\n",
    "df_train1 = pd.read_feather(PREFIX+'/input/df_train.feather')\n",
    "df_test1 = pd.read_feather(PREFIX+'/input/df_test.feather')\n",
    "df1 = pd.concat([df_train1, df_test1], axis=0)\n",
    "df1['question'] = df1['question'].apply(lambda x: str(x))\n",
    "#df1 = df1[df1['is_repeat']==0]\n",
    "df1_group = df1[['uid', 'question']].groupby('uid')['question'].apply(','.join)\n",
    "\n",
    "\n",
    "try:\n",
    "    import gensim\n",
    "except:\n",
    "    !pip install gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from time import time\n",
    "import multiprocessing\n",
    "\n",
    "class MonitorCallback(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.loss = 0\n",
    "        self.epoch = 1\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "#         print(\"Epoch No:\" + str(self.epoch))\n",
    "        self.epoch += 1\n",
    "        loss = model.get_latest_training_loss()\n",
    "#         print(\"Model loss: \", loss - self.loss)  # print loss\n",
    "        self.loss = loss\n",
    "        \n",
    "def train(seqs, iters=50, size=100, window=5, negative=5, min_count=1, ns_exponent=0.75, sg=1, hs=0):\n",
    "    t = time()\n",
    "    monitor = MonitorCallback()  # monitor with demo words\n",
    "    model = Word2Vec(seqs, epochs=iters,\n",
    "                     vector_size=size, window=window, min_count=min_count,\n",
    "                     sg=sg, hs=hs, negative=negative, ns_exponent=ns_exponent,\n",
    "                     workers=cores-1, compute_loss=True, callbacks=[monitor])\n",
    "    print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(wv, df):\n",
    "    wv_norm = {id: wv[id]/np.linalg.norm(wv[id]) for id in wv.vocab}\n",
    "\n",
    "    def calc_ndgc(df):\n",
    "        positives = [wv_norm[positive] for positive in df['positives']]\n",
    "        target_id = df['target_id']\n",
    "\n",
    "        ranks = [id for (id, sim) in wv.most_similar(\n",
    "            positive=positives, topn=10)]\n",
    "        if target_id in ranks:\n",
    "            hr = 1\n",
    "            r = ranks.index(target_id)\n",
    "            ndgc = 1.0 / math.log(r+2, 2)\n",
    "        else:\n",
    "            hr = 0\n",
    "            ndgc = 0\n",
    "        return pd.Series([hr, ndgc])\n",
    "\n",
    "    return df.apply(calc_ndgc, axis=1).mean()\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "def get_emb_df_wv(wv, group=False):\n",
    "    w2v_emb = pd.DataFrame([[int(word), ','.join(map(str, wv.get_vector(word)))] for index, word in enumerate(wv.index_to_key)])\n",
    "    w2v_emb.columns = ['question', 'embedding']\n",
    "    for i in range(len(w2v_emb.iloc[0]['embedding'].split(','))):\n",
    "        w2v_emb['question_emb'+str(i)] = w2v_emb['embedding'].apply(lambda x:float(x.split(',')[i]))\n",
    "    if group:\n",
    "        lstm_emb = pd.read_csv(PREFIX+'input/question_lstm_emb.csv')\n",
    "        lstm_emb = lstm_emb.drop(['question_emb'+str(i) for i in range(8)], axis=1)\n",
    "        lstm_emb = lstm_emb.merge(w2v_emb[['question']+['question_emb'+str(i) for i in range(5)]], how='left', on='question')\n",
    "        lstm_emb['concept'] = lstm_emb['concept_routes'].apply(lambda x:int(literal_eval(x)[0].split('----')[-1]))\n",
    "        concept_emb = lstm_emb[['concept']+['question_emb'+str(i) for i in range(5)]].groupby('concept').agg('mean')\n",
    "        lstm_emb = lstm_emb.merge(concept_emb, on='concept', how='left', suffixes=(None,'_group'))\n",
    "        print(\"Shape of lstm_emb:\", lstm_emb.shape)\n",
    "        return lstm_emb\n",
    "    return w2v_emb\n",
    "\n",
    "# def test_emb(df_tr, df_val, emb, length=5, suffix='_group'):\n",
    "#     df_tr = df_tr.merge(emb[['question']+['question_emb'+str(i)+suffix for i in range(length)]], how='left', on='question')\n",
    "#     df_val = df_val.merge(emb[['question']+['question_emb'+str(i)+suffix for i in range(length)]], how='left', on='question')\n",
    "#     gc.collect()\n",
    "#     res = get_result(lgb_params, df_tr, df_val, cols+['question_emb'+str(i)+suffix for i in range(length)], 'real_response', [metric,metric2], verbose=0, weight_func=weight_func)\n",
    "#     # 清理数据\n",
    "#     df_tr = df_tr.drop(['question_emb'+str(i)+suffix for i in range(length)], axis=1)\n",
    "#     df_val = df_val.drop(['question_emb'+str(i)+suffix for i in range(length)], axis=1)\n",
    "#     assert [col for col in df_tr.columns if 'question_emb' in col] == []\n",
    "#     return res \n",
    "\n",
    "\n",
    "config = {'iters':10, 'size':5, 'window':256, 'negative':5, 'sg':1}\n",
    "model = train([x.split(',') for x in df1_group], **config)\n",
    "wv = model.wv\n",
    "w2v_emb = get_emb_df_wv(wv)\n",
    "#score = test_emb(df_tr, df_val, w2v_emb, length=config['size'], suffix='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75beb692",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T07:12:06.962063Z",
     "start_time": "2023-01-03T07:12:06.948074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>embedding</th>\n",
       "      <th>question_emb0</th>\n",
       "      <th>question_emb1</th>\n",
       "      <th>question_emb2</th>\n",
       "      <th>question_emb3</th>\n",
       "      <th>question_emb4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182</td>\n",
       "      <td>0.21612895,0.124061614,0.94540304,-0.35554838,...</td>\n",
       "      <td>0.216129</td>\n",
       "      <td>0.124062</td>\n",
       "      <td>0.945403</td>\n",
       "      <td>-0.355548</td>\n",
       "      <td>-0.010761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313</td>\n",
       "      <td>-0.17996608,0.7829615,1.2150885,-0.38109714,-0...</td>\n",
       "      <td>-0.179966</td>\n",
       "      <td>0.782961</td>\n",
       "      <td>1.215089</td>\n",
       "      <td>-0.381097</td>\n",
       "      <td>-0.058842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181</td>\n",
       "      <td>0.30566648,0.21535926,0.8359815,-0.44348496,-0...</td>\n",
       "      <td>0.305666</td>\n",
       "      <td>0.215359</td>\n",
       "      <td>0.835982</td>\n",
       "      <td>-0.443485</td>\n",
       "      <td>-0.174992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>-1.3390198,0.8790246,1.7617677,-0.38630235,-0....</td>\n",
       "      <td>-1.339020</td>\n",
       "      <td>0.879025</td>\n",
       "      <td>1.761768</td>\n",
       "      <td>-0.386302</td>\n",
       "      <td>-0.240272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>409</td>\n",
       "      <td>-3.849838,2.1938562,4.2878475,-1.0281198,-1.49...</td>\n",
       "      <td>-3.849838</td>\n",
       "      <td>2.193856</td>\n",
       "      <td>4.287847</td>\n",
       "      <td>-1.028120</td>\n",
       "      <td>-1.490355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7647</th>\n",
       "      <td>5964</td>\n",
       "      <td>-1.2107998,-1.8678441,1.410139,-0.8014248,0.35...</td>\n",
       "      <td>-1.210800</td>\n",
       "      <td>-1.867844</td>\n",
       "      <td>1.410139</td>\n",
       "      <td>-0.801425</td>\n",
       "      <td>0.358806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7648</th>\n",
       "      <td>5965</td>\n",
       "      <td>-1.2183412,-1.8519108,1.2442461,-0.80626017,0....</td>\n",
       "      <td>-1.218341</td>\n",
       "      <td>-1.851911</td>\n",
       "      <td>1.244246</td>\n",
       "      <td>-0.806260</td>\n",
       "      <td>0.358229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7649</th>\n",
       "      <td>5967</td>\n",
       "      <td>-1.1887653,-1.8129925,1.3449147,-0.8082158,0.3...</td>\n",
       "      <td>-1.188765</td>\n",
       "      <td>-1.812993</td>\n",
       "      <td>1.344915</td>\n",
       "      <td>-0.808216</td>\n",
       "      <td>0.387356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7650</th>\n",
       "      <td>7206</td>\n",
       "      <td>-0.88806415,2.5467634,-0.214021,-0.7542569,1.3...</td>\n",
       "      <td>-0.888064</td>\n",
       "      <td>2.546763</td>\n",
       "      <td>-0.214021</td>\n",
       "      <td>-0.754257</td>\n",
       "      <td>1.324391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7651</th>\n",
       "      <td>7651</td>\n",
       "      <td>-1.0427114,0.60974467,0.98529035,0.18031333,0....</td>\n",
       "      <td>-1.042711</td>\n",
       "      <td>0.609745</td>\n",
       "      <td>0.985290</td>\n",
       "      <td>0.180313</td>\n",
       "      <td>0.733485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7652 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      question                                          embedding  \\\n",
       "0          182  0.21612895,0.124061614,0.94540304,-0.35554838,...   \n",
       "1          313  -0.17996608,0.7829615,1.2150885,-0.38109714,-0...   \n",
       "2          181  0.30566648,0.21535926,0.8359815,-0.44348496,-0...   \n",
       "3          372  -1.3390198,0.8790246,1.7617677,-0.38630235,-0....   \n",
       "4          409  -3.849838,2.1938562,4.2878475,-1.0281198,-1.49...   \n",
       "...        ...                                                ...   \n",
       "7647      5964  -1.2107998,-1.8678441,1.410139,-0.8014248,0.35...   \n",
       "7648      5965  -1.2183412,-1.8519108,1.2442461,-0.80626017,0....   \n",
       "7649      5967  -1.1887653,-1.8129925,1.3449147,-0.8082158,0.3...   \n",
       "7650      7206  -0.88806415,2.5467634,-0.214021,-0.7542569,1.3...   \n",
       "7651      7651  -1.0427114,0.60974467,0.98529035,0.18031333,0....   \n",
       "\n",
       "      question_emb0  question_emb1  question_emb2  question_emb3  \\\n",
       "0          0.216129       0.124062       0.945403      -0.355548   \n",
       "1         -0.179966       0.782961       1.215089      -0.381097   \n",
       "2          0.305666       0.215359       0.835982      -0.443485   \n",
       "3         -1.339020       0.879025       1.761768      -0.386302   \n",
       "4         -3.849838       2.193856       4.287847      -1.028120   \n",
       "...             ...            ...            ...            ...   \n",
       "7647      -1.210800      -1.867844       1.410139      -0.801425   \n",
       "7648      -1.218341      -1.851911       1.244246      -0.806260   \n",
       "7649      -1.188765      -1.812993       1.344915      -0.808216   \n",
       "7650      -0.888064       2.546763      -0.214021      -0.754257   \n",
       "7651      -1.042711       0.609745       0.985290       0.180313   \n",
       "\n",
       "      question_emb4  \n",
       "0         -0.010761  \n",
       "1         -0.058842  \n",
       "2         -0.174992  \n",
       "3         -0.240272  \n",
       "4         -1.490355  \n",
       "...             ...  \n",
       "7647       0.358806  \n",
       "7648       0.358229  \n",
       "7649       0.387356  \n",
       "7650       1.324391  \n",
       "7651       0.733485  \n",
       "\n",
       "[7652 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_emb.to_csv('input/question_w2v_emb_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dcb5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
