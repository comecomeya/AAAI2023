{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T03:36:08.049144Z",
     "start_time": "2022-12-30T03:36:06.413754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 20 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=False)\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "def groupApplyParallel(dfGrouped, func_dict):\n",
    "    # groupApplyParallel(df.groupby('abc'), {'add':lambda df: df['a']=df['b']+df['c']})\n",
    "    def multi_agg(group, func_dict):\n",
    "        for name, func in func_dict.items():\n",
    "            df[name] = func(group)\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(multi_agg)(group, func_dict) for name, group in dfGrouped)\n",
    "    return pd.concat(retLst)\n",
    "\n",
    "def quant(n):\n",
    "    def quantile_(x):\n",
    "        return np.quantile(x, n)\n",
    "    quantile_.__name__ = 'quantile_%s' % n\n",
    "    return quantile_\n",
    "\n",
    "def groupAggParallel(dfGrouped, func_dict):\n",
    "    # groupAggParallel(df.groupby('abc'), {'mean':np.mean, 'count':len})\n",
    "    def multi_agg(group, group_name, func_list):\n",
    "        res = list(group_name) if type(group_name) in (list, tuple) else [group_name]\n",
    "        for func in func_list:\n",
    "            res.append(func(group))\n",
    "        return res\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(multi_agg)(group, group_name, func_dict.values()) for group_name, group in dfGrouped)\n",
    "    print(retLst)\n",
    "    retLst = pd.DataFrame(retLst, columns=list(dfGrouped.grouper.result_index.names)+list(func_dict.keys()))\n",
    "    return retLst\n",
    "\n",
    "from tqdm import tqdm as tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from chinese_calendar import is_workday\n",
    "import datetime\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "\n",
    "RANDOM_SEED = 1\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T03:36:08.070434Z",
     "start_time": "2022-12-30T03:36:08.051364Z"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def file2zip(zip_file_name: str, file_names: list):\n",
    "    \"\"\" 将多个文件夹中文件压缩存储为zip\n",
    "    \n",
    "    :param zip_file_name:   /root/Document/test.zip\n",
    "    :param file_names:      ['/root/user/doc/test.txt', ...]\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # 读取写入方式 ZipFile requires mode 'r', 'w', 'x', or 'a'\n",
    "    # 压缩方式  ZIP_STORED： 存储； ZIP_DEFLATED： 压缩存储\n",
    "    with zipfile.ZipFile(zip_file_name, mode='w', compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        for fn in file_names:\n",
    "            parent_path, name = os.path.split(fn)\n",
    "            \n",
    "            # zipfile 内置提供的将文件压缩存储在.zip文件中， arcname即zip文件中存入文件的名称\n",
    "            # 给予的归档名为 arcname (默认情况下将与 filename 一致，但是不带驱动器盘符并会移除开头的路径分隔符)\n",
    "            zf.write(fn, arcname=name)\n",
    "\n",
    "# 写成dict方便索引\n",
    "def submit(df_test, zip_file_name='./submission/prediction.zip'):\n",
    "    predict_dict = {}\n",
    "    cols = ['uid','question','timestamp','predict']\n",
    "    for _, row in tqdm_notebook(df_test.loc[df_test['response']==-1,cols].iterrows()):\n",
    "        predict_dict[(int(row[cols[0]]),int(row[cols[1]]),int(row[cols[2]]))] = row[cols[3]]\n",
    "\n",
    "\n",
    "    with open(\"input/keyid2idx.json\",'r') as f:\n",
    "        keyid2idx = json.load(f)\n",
    "    keyidx2id = {\n",
    "        \"questions\":dict(zip(keyid2idx['questions'].values(),keyid2idx['questions'].keys())),\n",
    "        \"concepts\":dict(zip(keyid2idx['concepts'].values(),keyid2idx['concepts'].keys()))\n",
    "    }\n",
    "    df_test_raw = pd.read_csv(os.path.join(\"./input/pykt_test.csv\"))\n",
    "\n",
    "    predict_str_list = []\n",
    "    num_test = 0\n",
    "    for _, row in tqdm_notebook(df_test_raw.iterrows()):\n",
    "        predict_results = []\n",
    "        uid = int(row['uid'])\n",
    "        for question, response, timestamp, is_repeat in zip(row['questions'].split(\",\"), \n",
    "                                                 row['responses'].split(\",\"), \n",
    "                                                 row['timestamps'].split(\",\"), \n",
    "                                                 row['is_repeat'].split(\",\")):\n",
    "            question, response,timestamp, is_repeat = int(question), int(response),int(timestamp),int(is_repeat)\n",
    "            question_raw = int(keyidx2id['questions'][int(question)])\n",
    "            if is_repeat!=0:#skip the repeat\n",
    "                continue\n",
    "            if response == -1:\n",
    "                num_test += 1\n",
    "                predict_results.append(predict_dict[(uid,question,timestamp)])\n",
    "        predict_str = \",\".join([str(x) for x in predict_results])\n",
    "        predict_str_list.append(predict_str)\n",
    "    print('num_test:',num_test)\n",
    "    df_submit = pd.DataFrame({\"responses\":predict_str_list})\n",
    "    df_submit.to_csv(\"./submission/prediction.csv\",index=False)\n",
    "    file2zip(zip_file_name=zip_file_name, file_names=['./submission/prediction.csv'])\n",
    "    \n",
    "from scipy.misc import derivative\n",
    "#import numba as nb\n",
    "#@nb.jit(nopython=True,parallel=True)\n",
    "def focal_loss_lgb(y_pred, dtrain, alpha, gamma):\n",
    "    a,g = alpha, gamma\n",
    "    y_true = dtrain.label\n",
    "    def fl(x,t):\n",
    "        p = 1/(1+np.exp(-x))\n",
    "        return -( a*t + (1-a)*(1-t) ) * (( 1 - ( t*p + (1-t)*(1-p)) )**g) * ( t*np.log(p)+(1-t)*np.log(1-p) )\n",
    "    partial_fl = lambda x: fl(x, y_true)\n",
    "    grad = derivative(partial_fl, y_pred, n=1, dx=1e-6)\n",
    "    hess = derivative(partial_fl, y_pred, n=2, dx=1e-6)\n",
    "    return grad, hess\n",
    "#@nb.jit(nopython=True,parallel=True)\n",
    "def focal_loss_lgb_eval_error(y_pred, dtrain, alpha, gamma):\n",
    "    a,g = alpha, gamma\n",
    "    y_true = dtrain.label\n",
    "    p = 1/(1+np.exp(-y_pred))\n",
    "    loss = -( a*y_true + (1-a)*(1-y_true) ) * (( 1 - ( y_true*p + (1-y_true)*(1-p)) )**g) * ( y_true*np.log(p)+(1-y_true)*np.log(1-p) )\n",
    "    return 'focal_loss', np.mean(loss), False\n",
    "focal_loss = lambda x,y: focal_loss_lgb(x, y, 0.25, 1.)\n",
    "eval_error = lambda x,y: focal_loss_lgb_eval_error(x, y, 0.25, 1.)\n",
    "\n",
    "def my_final_sub(y_test_np, output_name='./submission/sub_all.zip'):\n",
    "    global df_test\n",
    "    df_test['predict'] = np.array(y_test_np)\n",
    "    df_test['predict_copy'] = df_test['predict']\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "    df_test_response = df_test[df_test['response']!=-1]\n",
    "    # 检查平均response，看是否有预测的逻辑问题\n",
    "    tmp1 = df.groupby('question')['response'].mean()\n",
    "    tmp2 = df_test[df_test['response']==-1].groupby('question')['predict'].mean()\n",
    "    print(tmp1.reset_index().merge(tmp2, left_on='question', right_index=True,how='left').head(10))\n",
    "    \n",
    "    tmp = df_test.groupby(['uid','timestamp','question'])['response'].agg(['count','mean','max','min'])\n",
    "    tmp2 = df_test_response.groupby(['uid','timestamp','question'])['response'].agg('mean').rename('split_cross_accrate')\n",
    "    if 'split_cross_accrate' in df_test.columns:\n",
    "        df_test.drop(columns=['split_cross_accrate'],inplace=True)\n",
    "    tmp = tmp[(tmp['max']!=-1)&(tmp['min']==-1)].merge(tmp2, how='left', left_index=True, right_index=True)\n",
    "    df_test = df_test.merge(tmp['split_cross_accrate'], how='left', left_on=['uid','timestamp','question'], right_index=True)\n",
    "    df_test['predict'] = df_test[['predict_copy','split_cross_accrate']].apply(lambda x:x['predict_copy'] if np.isnan(x['split_cross_accrate']) or abs(x['predict_copy']-x['split_cross_accrate'])>1.0 else x['split_cross_accrate'], axis=1)\n",
    "    submit(df_test, zip_file_name=output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T03:29:48.553930Z",
     "start_time": "2022-12-25T03:29:37.616950Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_feather('./input/df_train.feather')\n",
    "df_test = pd.read_feather('./input/df_test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T16:04:41.107231Z",
     "start_time": "2022-12-19T16:04:41.099565Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_rows_washed(df, df_test, verbose=0):\n",
    "    df_response = pd.concat([df[df['response']!=-1], df_test[df_test['response']!=-1]], axis=0)\n",
    "    tmp = df_response.groupby('question')['response'].agg('mean').rename('question_accrate')\n",
    "    tmp2 = df_response.groupby(['uid','timestamp'])['response'].agg(['count','mean']).rename(columns={'count':'tmp_count','mean':'tmp_mean'})\n",
    "    tmp3 = df_response.groupby('uid')['response'].agg('mean').rename('uid_accrate')\n",
    "    \n",
    "    def wash(df):\n",
    "        if verbose: print(df.shape)\n",
    "        df = df.merge(tmp, how='left', left_on='question', right_index=True).merge(tmp2, how='left', left_on=['uid','timestamp'], right_index=True).merge(tmp3, how='left', left_on='uid', right_index=True)\n",
    "        #\"\"\"\n",
    "        # 删除同一时间内提交多道题，但是正确率很低的情况，说明可能乱做的\n",
    "        df = df[(~((((df['tmp_mean']<0.3)&(df['uid_accrate']>0.7))|(df['tmp_mean']==0.)) & (df['tmp_count']>=10)))|(df['response']==-1)]\n",
    "        if verbose: print(df.shape)\n",
    "        #\"\"\"\n",
    "        # 删除差生、较难的题目，不该做对，会拉高这道题的平均正确率\n",
    "        df = df[~((df['type']==1)&\\\n",
    "                  (((df['question_accrate']<0.7)&(df['uid_accrate']<0.5))|((df['question_accrate']<0.5)&(df['uid_accrate']<0.7)))&\\\n",
    "                  (df['response']==1))]\n",
    "        if verbose: print(df.shape)\n",
    "        #\"\"\"\n",
    "        df.drop(columns=['tmp_count','tmp_mean','question_accrate','uid_accrate'], inplace=True)\n",
    "        return df.reset_index(drop=True)\n",
    "    df = wash(df)\n",
    "    df_test = wash(df_test)\n",
    "    return df, df_test\n",
    "# df, df_test = get_rows_washed(df, df_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T16:05:04.950246Z",
     "start_time": "2022-12-19T16:04:41.108856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(df):\n",
    "    # 时间相关特征\n",
    "    df['time_day'] = (df['timestamp']/86400000+8/24).astype('int')\n",
    "    df['time_hour'] = ((df['timestamp']/86400000+8/24 - (df['timestamp']/86400000+8/24).astype('int'))*24).astype('int')\n",
    "    def tmp_func(x):\n",
    "        from chinese_calendar import is_workday\n",
    "        import datetime\n",
    "        try:\n",
    "            res = int(is_workday(datetime.datetime.utcfromtimestamp(x//1000) + datetime.timedelta(hours=8)))\n",
    "        except:\n",
    "            res = -1\n",
    "        return res\n",
    "    df['time_is_workday'] = df['timestamp'].parallel_apply(tmp_func)\n",
    "    def tmp_func(x):\n",
    "        import datetime\n",
    "        return (datetime.datetime.utcfromtimestamp(x//1000) + datetime.timedelta(hours=8)).weekday()\n",
    "    df['time_weekday'] = df['timestamp'].parallel_apply(tmp_func)\n",
    "    def tmp_func(x):\n",
    "        import datetime\n",
    "        return (datetime.datetime.utcfromtimestamp(x//1000) + datetime.timedelta(hours=8)).year\n",
    "    df['time_year'] = df['timestamp'].parallel_apply(tmp_func)\n",
    "    \n",
    "    return df \n",
    "\n",
    "df = preprocess(df)\n",
    "df_test = preprocess(df_test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T16:05:07.821072Z",
     "start_time": "2022-12-19T16:05:04.952834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020    2565765\n",
      "2021    1880948\n",
      "2018         23\n",
      "Name: time_year, dtype: int64 2020    635300\n",
      "2021    467503\n",
      "2001         7\n",
      "Name: time_year, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 删除训练集中2018年的老数据\n",
    "print(df['time_year'].value_counts(),df_test['time_year'].value_counts())\n",
    "df = df[df['time_year']!=2018].reset_index(drop=True)\n",
    "# 删除用不到的列\n",
    "df = df.drop(['content','kc','analysis','concepts_raw','concepts'],axis=1)\n",
    "df_test = df_test.drop(['content','kc','analysis','concepts_raw','concepts'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T16:05:14.055701Z",
     "start_time": "2022-12-19T16:05:07.823099Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of properties dataframe is : 1017.7719573974609  MB\n",
      "******************************\n",
      "Column:  uid\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  question\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  response\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  timestamp\n",
      "dtype before:  int64\n",
      "dtype after:  int64\n",
      "******************************\n",
      "******************************\n",
      "Column:  type\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_cnt\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_hot_cnt\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_1\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_2\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_3\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_4\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_5\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_6\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  content_cnt\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_group_cnt\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_cnt\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_1\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_2\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_3\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_4\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_5\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_6\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_7\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_8\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  analysis_cnt\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_day\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_hour\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_is_workday\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_weekday\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_year\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  237.48021697998047  MB\n",
      "This is  23.333342528638717 % of the initial size\n",
      "nan_list: []\n",
      "Memory usage of properties dataframe is : 252.41329956054688  MB\n",
      "******************************\n",
      "Column:  uid\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  question\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  response\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  timestamp\n",
      "dtype before:  int64\n",
      "dtype after:  int64\n",
      "******************************\n",
      "******************************\n",
      "Column:  type\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_cnt\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_hot_cnt\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_1\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_2\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_3\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_4\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_5\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_6\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  content_cnt\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_group_cnt\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_cnt\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_1\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_2\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_3\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_4\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_5\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_6\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_7\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_8\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  analysis_cnt\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_day\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_hour\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_is_workday\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_weekday\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_year\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  58.89653015136719  MB\n",
      "This is  23.333370410317688 % of the initial size\n",
      "nan_list: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reduce_mem_usage(props, use_uint=False):\n",
    "    start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
    "    for col in props.columns:\n",
    "        if props[col].dtype != object:  # Exclude strings\n",
    "            \n",
    "            # Print current column type\n",
    "            print(\"******************************\")\n",
    "            print(\"Column: \",col)\n",
    "            print(\"dtype before: \",props[col].dtype)\n",
    "            \n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            mx = props[col].max()\n",
    "            mn = props[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(props[col]).all(): \n",
    "                NAlist.append(col)\n",
    "                props[col].fillna(mn-1,inplace=True)  \n",
    "                   \n",
    "            # test if column can be converted to an integer\n",
    "            asint = props[col].fillna(0).astype(np.int64)\n",
    "            result = (props[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result > -0.01 and result < 0.01:\n",
    "                IsInt = True\n",
    "\n",
    "            \n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                if mn >= 0 and use_uint:\n",
    "                    if mx < 255:\n",
    "                        props[col] = props[col].astype(np.uint8)\n",
    "                    elif mx < 65535:\n",
    "                        props[col] = props[col].astype(np.uint16)\n",
    "                    elif mx < 4294967295:\n",
    "                        props[col] = props[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        props[col] = props[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
    "                        props[col] = props[col].astype(np.int8)\n",
    "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
    "                        props[col] = props[col].astype(np.int16)\n",
    "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
    "                        props[col] = props[col].astype(np.int32)\n",
    "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
    "                        props[col] = props[col].astype(np.int64)    \n",
    "            \n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                props[col] = props[col].astype(np.float32)\n",
    "            \n",
    "            # Print new column type\n",
    "            print(\"dtype after: \",props[col].dtype)\n",
    "            print(\"******************************\")\n",
    "    \n",
    "    # Print final result\n",
    "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    print('nan_list:', NAlist)\n",
    "    return props, NAlist\n",
    "df, nalist = reduce_mem_usage(df)\n",
    "df_test, nalist = reduce_mem_usage(df_test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全局特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T16:05:14.190497Z",
     "start_time": "2022-12-19T16:05:14.057625Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf_tmp,df_tmp2, columns_tmp = feature_engineering(df.iloc[:1000].copy()[['uid', 'question', 'response', 'timestamp', 'type', 'concept_cnt',\\n       'concept_hot_cnt', 'concept_1', 'concept_2', 'concept_3',\\n       'concept_4', 'concept_5', 'concept_6', 'content_cnt',\\n       'kc_group_cnt', 'kc_cnt', 'kc_1', 'kc_2', 'kc_3', 'kc_4', 'kc_5',\\n       'kc_6', 'kc_7', 'kc_8', 'analysis_cnt', 'time_day', 'time_hour',\\n       'time_is_workday', 'time_weekday', 'time_year']], df_test.iloc[:1000].copy()[['uid', 'question', 'response', 'timestamp', 'type', 'concept_cnt',\\n       'concept_hot_cnt', 'concept_1', 'concept_2', 'concept_3',\\n       'concept_4', 'concept_5', 'concept_6', 'content_cnt',\\n       'kc_group_cnt', 'kc_cnt', 'kc_1', 'kc_2', 'kc_3', 'kc_4', 'kc_5',\\n       'kc_6', 'kc_7', 'kc_8', 'analysis_cnt', 'time_day', 'time_hour',\\n       'time_is_workday', 'time_weekday', 'time_year']])\\nprint(columns_tmp)\\ndf_tmp\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将测试集的已有信息也放进来（特征工程和训练集）\n",
    "def feature_engineering(df_tr, df_test, verbose=0):\n",
    "    # 不同统计方式得到的特征，用于不同类型的模型\n",
    "    columns = {\n",
    "        'at':[], # 可以直接使用的特征\n",
    "        'bs':[], # 统计这次提交以前的label\n",
    "        'bt':[], # 统计今天以前的label\n",
    "        'bh':[]  # 只使用一半的label进行统计\n",
    "    }\n",
    "    df_tr['data_type'] = 'tr'\n",
    "    df_tr['raw_index'] = df_tr.index.values\n",
    "    df_test['data_type'] = 'test'\n",
    "    df_test['raw_index'] = df_test.index.values\n",
    "    df = pd.concat([df_tr, df_test], axis=0).sort_values(['uid','timestamp','question']).reset_index(drop=True)\n",
    "    \n",
    "    # 在这之前已经提交了多少题目了\n",
    "    tmp = df.groupby(['uid','timestamp'])['response'].count()\n",
    "    tmp = (tmp.groupby('uid').cumsum()-tmp).rename('uid_record_cumsum')\n",
    "    df = df.merge(tmp, how='left', left_on=['uid','timestamp'], right_index=True, suffixes=(None,'_y'))\n",
    "    # 一共提交多少题目\n",
    "    tmp = df.groupby(['uid'])['response'].count().rename('uid_record_sum')\n",
    "    df = df.merge(tmp, how='left', left_on=['uid'], right_index=True, suffixes=(None,'_y'))\n",
    "    columns['at'].extend(['uid_record_cumsum','uid_record_sum'])\n",
    "    \n",
    "    df_response = df[df['response']!=-1].reset_index(drop=True)\n",
    "    if verbose: print('df shape:', df.shape)\n",
    "    \n",
    "    # 现存的特征，放入columns列表\n",
    "    columns['at'].extend(['question','timestamp', 'type', 'concept_cnt', 'concept_hot_cnt', 'concept_1','concept_2', 'concept_3', \n",
    "                          'concept_4','concept_5', 'concept_6', 'content_cnt', 'kc_group_cnt', 'kc_cnt',\n",
    "                          'kc_1', 'kc_2', 'kc_3', 'kc_4', 'kc_5', 'kc_6', 'kc_7', 'kc_8', 'analysis_cnt',\n",
    "                         'time_day','time_hour','time_is_workday','time_weekday','time_year',])\n",
    "    \n",
    "    # concept\n",
    "    df_tmp = pd.concat([\n",
    "        df_response.loc[df_response['concept_1']!=-1,['uid','response','concept_1','time_day','time_hour','timestamp','type']].rename(columns={'concept_1':'concept'}),\n",
    "        df_response.loc[df_response['concept_2']!=-1,['uid','response','concept_2','time_day','time_hour','timestamp','type']].rename(columns={'concept_2':'concept'}),\n",
    "        df_response.loc[df_response['concept_3']!=-1,['uid','response','concept_3','time_day','time_hour','timestamp','type']].rename(columns={'concept_3':'concept'}),\n",
    "        df_response.loc[df_response['concept_4']!=-1,['uid','response','concept_4','time_day','time_hour','timestamp','type']].rename(columns={'concept_4':'concept'}),\n",
    "        df_response.loc[df_response['concept_5']!=-1,['uid','response','concept_5','time_day','time_hour','timestamp','type']].rename(columns={'concept_5':'concept'}),\n",
    "        df_response.loc[df_response['concept_6']!=-1,['uid','response','concept_6','time_day','time_hour','timestamp','type']].rename(columns={'concept_6':'concept'}),\n",
    "    ])\n",
    "    col = 'concept'\n",
    "    tmp = df_tmp.groupby(col)['response'].agg(['count','mean']).rename(columns={'count':col+'_showcnt', 'mean':col+'_accrate'})\n",
    "    df=df.merge(tmp, how='left', left_on=col+'_1', right_index=True, suffixes=(None,'_1'))\\\n",
    "        .merge(tmp, how='left', left_on=col+'_2', right_index=True, suffixes=(None,'_2'))\\\n",
    "        .merge(tmp, how='left', left_on=col+'_3', right_index=True, suffixes=(None,'_3'))\\\n",
    "        .merge(tmp, how='left', left_on=col+'_4', right_index=True, suffixes=(None,'_4'))\\\n",
    "        .merge(tmp, how='left', left_on=col+'_5', right_index=True, suffixes=(None,'_5'))\\\n",
    "        .merge(tmp, how='left', left_on=col+'_6', right_index=True, suffixes=(None,'_6'))\\\n",
    "        .rename(columns={col+'_showcnt':col+'_showcnt'+'_1',col+'_accrate':col+'_accrate'+'_1'})\\\n",
    "        .fillna(-1.)\n",
    "    col2 = 'type'  # {'count':len,'mean':np.mean}\n",
    "    tmp = df_tmp.groupby([col,col2])['response'].agg(['count','mean']).rename(columns={'count':col+'_'+col2+'_showcnt', 'mean':col+'_'+col2+'_accrate'})\n",
    "    df=df.merge(tmp, how='left', left_on=[col+'_1',col2], right_index=True, suffixes=(None,'_1'))\\\n",
    "        .merge(tmp, how='left', left_on=[col+'_2',col2], right_index=True, suffixes=(None,'_2'))\\\n",
    "        .merge(tmp, how='left', left_on=[col+'_3',col2], right_index=True, suffixes=(None,'_3'))\\\n",
    "        .merge(tmp, how='left', left_on=[col+'_4',col2], right_index=True, suffixes=(None,'_4'))\\\n",
    "        .merge(tmp, how='left', left_on=[col+'_5',col2], right_index=True, suffixes=(None,'_5'))\\\n",
    "        .merge(tmp, how='left', left_on=[col+'_6',col2], right_index=True, suffixes=(None,'_6'))\\\n",
    "        .rename(columns={col+'_'+col2+'_showcnt':col+'_'+col2+'_showcnt'+'_1',col+'_'+col2+'_accrate':col+'_'+col2+'_accrate'+'_1'})\\\n",
    "        .fillna(-1.)\n",
    "    df[col+'_min_accrate'] = df[['concept_accrate_1','concept_accrate_2','concept_accrate_3','concept_accrate_4','concept_accrate_5','concept_accrate_6']].parallel_apply(lambda x: min([xx if xx!=-1 else 99999999 for xx in x]), axis=1)\n",
    "    df[col+'_mean_accrate'] = df[['concept_accrate_1','concept_accrate_2','concept_accrate_3','concept_accrate_4','concept_accrate_5','concept_accrate_6']].parallel_apply(lambda x: sum([xx for xx in x if xx!=-1])/(len([xx for xx in x if xx!=-1])+0.0001), axis=1)\n",
    "    df[col+'_max_accrate'] = df[['concept_accrate_1','concept_accrate_2','concept_accrate_3','concept_accrate_4','concept_accrate_5','concept_accrate_6']].parallel_apply(lambda x: max([xx if xx!=-1 else -9 for xx in x]), axis=1)\n",
    "    df[col+'_min_showcnt'] = df[['concept_showcnt_1','concept_showcnt_2','concept_showcnt_3','concept_showcnt_4','concept_showcnt_5','concept_showcnt_6']].parallel_apply(lambda x: min([xx if xx!=-1 else 99999999 for xx in x]), axis=1)\n",
    "    df[col+'_mean_showcnt'] = df[['concept_showcnt_1','concept_showcnt_2','concept_showcnt_3','concept_showcnt_4','concept_showcnt_5','concept_showcnt_6']].parallel_apply(lambda x: sum([xx for xx in x if xx!=-1])/(len([xx for xx in x if xx!=-1])+0.0001), axis=1)\n",
    "    df[col+'_max_showcnt'] = df[['concept_showcnt_1','concept_showcnt_2','concept_showcnt_3','concept_showcnt_4','concept_showcnt_5','concept_showcnt_6']].parallel_apply(lambda x: max([xx if xx!=-1 else -9 for xx in x]), axis=1)\n",
    "    columns['at'].extend([col+'_min_accrate',col+'_min_showcnt',col+'_mean_accrate',col+'_mean_showcnt',col+'_max_accrate',col+'_max_showcnt'])\n",
    "    for i in range(1,7):\n",
    "        columns['at'].extend([col+'_showcnt_'+str(i),col+'_accrate_'+str(i),col+'_'+col2+'_showcnt_'+str(i),col+'_'+col2+'_accrate_'+str(i)])\n",
    "    df[col+col2+'_min_accrate'] = df[['concept_type_accrate_1','concept_type_accrate_2','concept_type_accrate_3','concept_type_accrate_4','concept_type_accrate_5','concept_type_accrate_6']].parallel_apply(lambda x: min([xx if xx!=-1 else 99999999 for xx in x]), axis=1)\n",
    "    df[col+col2+'_mean_accrate'] = df[['concept_type_accrate_1','concept_type_accrate_2','concept_type_accrate_3','concept_type_accrate_4','concept_type_accrate_5','concept_type_accrate_6']].parallel_apply(lambda x: sum([xx for xx in x if xx!=-1])/(len([xx for xx in x if xx!=-1])+0.0001), axis=1)\n",
    "    df[col+col2+'_max_accrate'] = df[['concept_type_accrate_1','concept_type_accrate_2','concept_type_accrate_3','concept_type_accrate_4','concept_type_accrate_5','concept_type_accrate_6']].parallel_apply(lambda x: max([xx if xx!=-1 else -9 for xx in x]), axis=1)\n",
    "    df[col+col2+'_min_showcnt'] = df[['concept_type_showcnt_1','concept_type_showcnt_2','concept_type_showcnt_3','concept_type_showcnt_4','concept_type_showcnt_5','concept_type_showcnt_6']].parallel_apply(lambda x: min([xx if xx!=-1 else 99999999 for xx in x]), axis=1)\n",
    "    df[col+col2+'_mean_showcnt'] = df[['concept_type_showcnt_1','concept_type_showcnt_2','concept_type_showcnt_3','concept_type_showcnt_4','concept_type_showcnt_5','concept_type_showcnt_6']].parallel_apply(lambda x: sum([xx for xx in x if xx!=-1])/(len([xx for xx in x if xx!=-1])+0.0001), axis=1)\n",
    "    df[col+col2+'_max_showcnt'] = df[['concept_type_showcnt_1','concept_type_showcnt_2','concept_type_showcnt_3','concept_type_showcnt_4','concept_type_showcnt_5','concept_type_showcnt_6']].parallel_apply(lambda x: max([xx if xx!=-1 else -9 for xx in x]), axis=1)\n",
    "    columns['at'].extend([col+col2+'_min_accrate',col+col2+'_min_showcnt',col+col2+'_mean_accrate',col+col2+'_mean_showcnt',col+col2+'_max_accrate',col+col2+'_max_showcnt'])\n",
    "    \n",
    "    # kc\n",
    "    df_tmp = pd.concat([\n",
    "        df_response.loc[df_response['kc_1']!=-1,['uid','response','kc_1','time_day','time_hour','timestamp','type']].rename(columns={'kc_1':'kc'}),\n",
    "        df_response.loc[df_response['kc_2']!=-1,['uid','response','kc_2','time_day','time_hour','timestamp','type']].rename(columns={'kc_2':'kc'}),\n",
    "        df_response.loc[df_response['kc_3']!=-1,['uid','response','kc_3','time_day','time_hour','timestamp','type']].rename(columns={'kc_3':'kc'}),\n",
    "        df_response.loc[df_response['kc_4']!=-1,['uid','response','kc_4','time_day','time_hour','timestamp','type']].rename(columns={'kc_4':'kc'}),\n",
    "        df_response.loc[df_response['kc_5']!=-1,['uid','response','kc_5','time_day','time_hour','timestamp','type']].rename(columns={'kc_5':'kc'}),\n",
    "        df_response.loc[df_response['kc_6']!=-1,['uid','response','kc_6','time_day','time_hour','timestamp','type']].rename(columns={'kc_6':'kc'}),\n",
    "        df_response.loc[df_response['kc_7']!=-1,['uid','response','kc_7','time_day','time_hour','timestamp','type']].rename(columns={'kc_7':'kc'}),\n",
    "        df_response.loc[df_response['kc_8']!=-1,['uid','response','kc_8','time_day','time_hour','timestamp','type']].rename(columns={'kc_8':'kc'}),\n",
    "    ])\n",
    "    col = 'kc'\n",
    "    tmp = df_tmp.groupby(col)['response'].agg(['count','mean']).rename(columns={'count':col+'_showcnt', 'mean':col+'_accrate'})\n",
    "    df=df.merge(tmp, how='left', left_on=col+'_1', right_index=True, suffixes=(None,'_1'))\\\n",
    "        .merge(tmp, how='left', left_on=col+'_2', right_index=True, suffixes=(None,'_2'))\\\n",
    "        .merge(tmp, how='left', left_on=col+'_3', right_index=True, suffixes=(None,'_3'))\\\n",
    "        .merge(tmp, how='left', left_on=col+'_4', right_index=True, suffixes=(None,'_4'))\\\n",
    "        .merge(tmp, how='left', left_on=col+'_5', right_index=True, suffixes=(None,'_5'))\\\n",
    "        .merge(tmp, how='left', left_on=col+'_6', right_index=True, suffixes=(None,'_6'))\\\n",
    "        .merge(tmp, how='left', left_on=col+'_7', right_index=True, suffixes=(None,'_7'))\\\n",
    "        .merge(tmp, how='left', left_on=col+'_8', right_index=True, suffixes=(None,'_8'))\\\n",
    "        .rename(columns={col+'_showcnt':col+'_showcnt'+'_1',col+'_accrate':col+'_accrate'+'_1'}).fillna(-1)\n",
    "    col2 = 'type'\n",
    "    tmp = df_tmp.groupby([col,col2])['response'].agg(['count','mean']).rename(columns={'count':col+'_'+col2+'_showcnt', 'mean':col+'_'+col2+'_accrate'})\n",
    "    df=df.merge(tmp, how='left', left_on=[col+'_1',col2], right_index=True, suffixes=(None,'_1'))\\\n",
    "        .merge(tmp, how='left', left_on=[col+'_2',col2], right_index=True, suffixes=(None,'_2'))\\\n",
    "        .merge(tmp, how='left', left_on=[col+'_3',col2], right_index=True, suffixes=(None,'_3'))\\\n",
    "        .merge(tmp, how='left', left_on=[col+'_4',col2], right_index=True, suffixes=(None,'_4'))\\\n",
    "        .merge(tmp, how='left', left_on=[col+'_5',col2], right_index=True, suffixes=(None,'_5'))\\\n",
    "        .merge(tmp, how='left', left_on=[col+'_6',col2], right_index=True, suffixes=(None,'_6'))\\\n",
    "        .merge(tmp, how='left', left_on=[col+'_7',col2], right_index=True, suffixes=(None,'_7'))\\\n",
    "        .merge(tmp, how='left', left_on=[col+'_8',col2], right_index=True, suffixes=(None,'_8'))\\\n",
    "        .rename(columns={col+'_'+col2+'_showcnt':col+'_'+col2+'_showcnt'+'_1',col+'_'+col2+'_accrate':col+'_'+col2+'_accrate'+'_1'}).fillna(-1)\n",
    "    for i in range(1,8):\n",
    "        columns['at'].extend([col+'_showcnt_'+str(i),col+'_accrate_'+str(i),col+'_'+col2+'_showcnt_'+str(i),col+'_'+col2+'_accrate_'+str(i)])\n",
    "    df[col+'_min_accrate'] = df[['kc_accrate_1','kc_accrate_2','kc_accrate_3','kc_accrate_4','kc_accrate_5','kc_accrate_6','kc_accrate_7','kc_accrate_8']].parallel_apply(lambda x: min([xx if xx!=-1 else 99999999 for xx in x]), axis=1)\n",
    "    df[col+'_mean_accrate'] = df[['kc_accrate_1','kc_accrate_2','kc_accrate_3','kc_accrate_4','kc_accrate_5','kc_accrate_6','kc_accrate_7','kc_accrate_8']].parallel_apply(lambda x: sum([xx for xx in x if xx!=-1])/(len([xx for xx in x if xx!=-1])+0.0001), axis=1)\n",
    "    df[col+'_max_accrate'] = df[['kc_accrate_1','kc_accrate_2','kc_accrate_3','kc_accrate_4','kc_accrate_5','kc_accrate_6','kc_accrate_7','kc_accrate_8']].parallel_apply(lambda x: max([xx if xx!=-1 else -9 for xx in x]), axis=1)\n",
    "    df[col+'_min_showcnt'] = df[['kc_showcnt_1','kc_showcnt_2','kc_showcnt_3','kc_showcnt_4','kc_showcnt_5','kc_showcnt_6','kc_showcnt_7','kc_showcnt_8']].parallel_apply(lambda x: min([xx if xx!=-1 else 99999999 for xx in x]), axis=1)\n",
    "    df[col+'_mean_showcnt'] = df[['kc_showcnt_1','kc_showcnt_2','kc_showcnt_3','kc_showcnt_4','kc_showcnt_5','kc_showcnt_6','kc_showcnt_7','kc_showcnt_8']].parallel_apply(lambda x: sum([xx for xx in x if xx!=-1])/(len([xx for xx in x if xx!=-1])+0.0001), axis=1)\n",
    "    df[col+'_max_showcnt'] = df[['kc_showcnt_1','kc_showcnt_2','kc_showcnt_3','kc_showcnt_4','kc_showcnt_5','kc_showcnt_6','kc_showcnt_7','kc_showcnt_8']].parallel_apply(lambda x: max([xx if xx!=-1 else -9 for xx in x]), axis=1)\n",
    "    columns['at'].extend([col+'_min_accrate',col+'_min_showcnt',col+'_mean_accrate',col+'_mean_showcnt',col+'_max_accrate',col+'_max_showcnt'])\n",
    "    df[col+col2+'_min_accrate'] = df[['kc_type_accrate_1','kc_type_accrate_2','kc_type_accrate_3','kc_type_accrate_4','kc_type_accrate_5','kc_type_accrate_6','kc_type_accrate_7','kc_type_accrate_8']].parallel_apply(lambda x: min([xx if xx!=-1 else 99999999 for xx in x]), axis=1)\n",
    "    df[col+col2+'_mean_accrate'] = df[['kc_type_accrate_1','kc_type_accrate_2','kc_type_accrate_3','kc_type_accrate_4','kc_type_accrate_5','kc_type_accrate_6','kc_type_accrate_7','kc_type_accrate_8']].parallel_apply(lambda x: sum([xx for xx in x if xx!=-1])/(len([xx for xx in x if xx!=-1])+0.0001), axis=1)\n",
    "    df[col+col2+'_max_accrate'] = df[['kc_type_accrate_1','kc_type_accrate_2','kc_type_accrate_3','kc_type_accrate_4','kc_type_accrate_5','kc_type_accrate_6','kc_type_accrate_7','kc_type_accrate_8']].parallel_apply(lambda x: max([xx if xx!=-1 else -9 for xx in x]), axis=1)\n",
    "    df[col+col2+'_min_showcnt'] = df[['kc_type_showcnt_1','kc_type_showcnt_2','kc_type_showcnt_3','kc_type_showcnt_4','kc_type_showcnt_5','kc_type_showcnt_6','kc_type_showcnt_7','kc_type_showcnt_8']].parallel_apply(lambda x: min([xx if xx!=-1 else 99999999 for xx in x]), axis=1)\n",
    "    df[col+col2+'_mean_showcnt'] = df[['kc_type_showcnt_1','kc_type_showcnt_2','kc_type_showcnt_3','kc_type_showcnt_4','kc_type_showcnt_5','kc_type_showcnt_6','kc_type_showcnt_7','kc_type_showcnt_8']].parallel_apply(lambda x: sum([xx for xx in x if xx!=-1])/(len([xx for xx in x if xx!=-1])+0.0001), axis=1)\n",
    "    df[col+col2+'_max_showcnt'] = df[['kc_type_showcnt_1','kc_type_showcnt_2','kc_type_showcnt_3','kc_type_showcnt_4','kc_type_showcnt_5','kc_type_showcnt_6','kc_type_showcnt_7','kc_type_showcnt_8']].parallel_apply(lambda x: max([xx if xx!=-1 else -9 for xx in x]), axis=1)\n",
    "    columns['at'].extend([col+col2+'_min_accrate',col+col2+'_min_showcnt',col+col2+'_mean_accrate',col+col2+'_mean_showcnt',col+col2+'_max_accrate',col+col2+'_max_showcnt'])\n",
    "    if verbose: print('df shape:', df.shape)\n",
    "    \n",
    "    # question\n",
    "    col = 'question'\n",
    "    tmp = df.groupby(col)['response'].agg('count').rename(col+'_showcnt')\n",
    "    df=df.merge(tmp, how='left', left_on=col, right_index=True, suffixes=(None,'_1'))\n",
    "    tmp = df_response.groupby(col)['response'].agg('mean').rename(col+'_accrate')\n",
    "    df=df.merge(tmp, how='left', left_on=col, right_index=True, suffixes=(None,'_1'))\n",
    "    columns['at'].extend([col+'_showcnt',col+'_accrate'])\n",
    "    \n",
    "    # type\n",
    "    cols = ['uid','type','time_hour','time_is_workday','time_weekday']\n",
    "    for col in cols:\n",
    "        tmp = df_response.groupby(col)['response'].agg(['count','mean']).rename(columns={'count':col+'_showcnt', 'mean':col+'_accrate'})\n",
    "        df=df.merge(tmp, how='left', left_on=col, right_index=True, suffixes=(None,'_1'))\n",
    "        columns['at'].extend([col+'_showcnt',col+'_accrate'])\n",
    "    for col in ['type','time_is_workday']:\n",
    "        for cc in ['showcnt','accrate']:\n",
    "            df[f'{col}_1_{cc}'] = df[f'{col}_{cc}']*df[col]\n",
    "            df[f'{col}_0_{cc}'] = df[f'{col}_{cc}']*(1-df[col])\n",
    "    if verbose: print('df shape:', df.shape)\n",
    "    \n",
    "    # 同时提交的question：正确率的分布与平时不同，可考虑：\n",
    "    # 1. 剔除后再进行全局统计（需注释掉原question统计）\n",
    "    # 2. 用其作为一个特征\n",
    "    col, col2 = 'timestamp', 'question'\n",
    "    tmp = df.groupby([col,col2])['uid'].agg('nunique').rename(col+'_'+col2+'_cnt')\n",
    "    df=df.merge(tmp, how='left', left_on=[col,col2], right_index=True, suffixes=(None,'_1'))\n",
    "    #tmp1 = df_response.groupby([col,col2])['response'].agg('mean').rename(col+'_'+col2+'_accrate')\n",
    "    #tmp = tmp[tmp>=10].reset_index().merge(tmp1[tmp1<0.0001], how='left', left_on=['timestamp','question'], right_index=True)[[col,col2,col+'_'+col2+'_accrate']]\n",
    "    #df=df.merge(tmp, how='left', left_on=[col,col2], right_on=[col,col2], suffixes=(None,'_1'))\n",
    "    columns['at'].extend([col+'_'+col2+'_cnt']) # , col+'_'+col2+'_accrate'\n",
    "    #tmp = df[df[col+'_'+col2+'_cnt']<=2].groupby('question')['response'].agg(['count','mean']).rename(columns={'count':'question_showcnt_without_'+col+'_'+col2, 'mean':'question_accrate_without_'+col+'_'+col2})\n",
    "    #df=df.merge(tmp, how='left', left_on=[col2], right_index=True, suffixes=(None,'_1'))\n",
    "    #columns['at'].extend(['question_accrate_without_'+col+'_'+col2, 'question_showcnt_without_'+col+'_'+col2])\n",
    "    if verbose: print('df shape:', df.shape)\n",
    "    \n",
    "    # \"\"\"\n",
    "    # 题目迄今做过次数\n",
    "    # 短期内题目做的次数\n",
    "    # 短期内提交次数 / 长期内提交次数\n",
    "    def tmp_func(df, timelimit=3600000, print_timedistance=None, col='question', only_once=False, timestamp_once=False):\n",
    "        print_timedistance = '_asc' if print_timedistance is None else '_'+print_timedistance\n",
    "        tt, qq = list(df['timestamp']), list(df[col])\n",
    "        times_dct = defaultdict(int)\n",
    "        unique_submittimes = 0  # 截止此时提交了多少次\n",
    "        question_submittimes = 0  # 截止此时提交了多少个问题\n",
    "        timestamp_question_submit = 0\n",
    "        last_question_ti = -1  # 当前时间与之前记录的时间不一致，此时需要写入“截止此时提交了多少个问题”\n",
    "        times_continue_learning = 0  # 连续学习时长\n",
    "        times_continue_learning_res = []\n",
    "        times_until_now_res = []\n",
    "        unique_submittimes_res = []\n",
    "        question_submittimes_res = []\n",
    "        distance_to_last_timestamp_res = []\n",
    "        timestamp_question_submit_res = []\n",
    "        s = -1  # 时间范围节点的开始位置\n",
    "        for e,t,q in zip(range(len(tt)),tt,qq):\n",
    "            if s == -1:\n",
    "                times_continue_learning = 0\n",
    "                s = 0\n",
    "                unique_submittimes = 1\n",
    "                times_dct[q] += 1\n",
    "                question_submittimes = 1\n",
    "                last_question_ti = 0\n",
    "                timestamp_question_submit = 1\n",
    "            else:\n",
    "                if tt[last_question_ti] != t:\n",
    "                    question_submittimes_res.extend([question_submittimes]*(e-last_question_ti))\n",
    "                    distance_to_last_timestamp_res.extend([int((t-tt[last_question_ti])/1000)]*(e-last_question_ti))\n",
    "                    timestamp_question_submit_res.extend([timestamp_question_submit]*(e-last_question_ti))\n",
    "                    timestamp_question_submit = 1\n",
    "                    last_question_ti = e\n",
    "                else:\n",
    "                    timestamp_question_submit += 1\n",
    "                while (t-tt[s]>timelimit and print_timedistance=='_asc') or (tt[s]-t>timelimit and print_timedistance=='_desc'):\n",
    "                    question_submittimes -= 1\n",
    "                    if tt[s] != tt[s+1]:\n",
    "                        unique_submittimes-=1\n",
    "                    times_dct[qq[s]] -= 1\n",
    "                    s += 1\n",
    "                if t != tt[e-1]:\n",
    "                    unique_submittimes+=1\n",
    "                times_dct[q] += 1\n",
    "                question_submittimes += 1\n",
    "                if t - tt[e-1] <= 10800000:\n",
    "                    times_continue_learning += int((t - tt[e-1])/60000)\n",
    "                else:\n",
    "                    times_continue_learning = 0\n",
    "            times_continue_learning_res.append(times_continue_learning)\n",
    "            times_until_now_res.append(times_dct[q])\n",
    "            unique_submittimes_res.append(unique_submittimes)\n",
    "        question_submittimes_res.extend([question_submittimes]*(len(tt)-last_question_ti))\n",
    "        distance_to_last_timestamp_res.extend([int((t-tt[last_question_ti])/1000)]*(len(tt)-last_question_ti))\n",
    "        timestamp_question_submit_res.extend([timestamp_question_submit]*(len(tt)-last_question_ti))\n",
    "        df[f'uid_{col}_utilnow_{str(int(timelimit/1000))}{print_timedistance}'] = times_until_now_res  # 截止此时，当前问题出现了多少次\n",
    "        if timestamp_once:\n",
    "            df[f'uid_question_submittimes_{str(int(timelimit/1000))}{print_timedistance}'] = question_submittimes_res  # 截止此时，提交了多少个问题\n",
    "            df[f'uid_unique_submittimes_{str(int(timelimit/1000))}{print_timedistance}'] = unique_submittimes_res  # 截止此时，提交了多少次\n",
    "            if only_once:\n",
    "                df[f'uid_timedistance_to_last_submit{print_timedistance}'] = distance_to_last_timestamp_res # 距离上次提交过去了多久\n",
    "                if print_timedistance == '_asc':\n",
    "                    df[f'uid_timestamp_question_submit'] = timestamp_question_submit_res # 当前timestamp提交了多少个问题\n",
    "                    df['uid_continue_learning_mins'] = times_continue_learning_res  # 截止当前timestamp，持续学习了多久（中断3小时即重新计算）\n",
    "        return df\n",
    "\n",
    "    \n",
    "    col = 'question'\n",
    "    timelimit = 3600*1000\n",
    "    df_tmp_groupby = df[['uid','timestamp',col]].groupby(['uid'])\n",
    "    tmp=df_tmp_groupby.parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='asc', col=col, only_once=True, timestamp_once=True))\n",
    "    cols = [x for x in tmp.columns if x not in ['uid','timestamp',col]]\n",
    "    df[cols] = tmp.reset_index(drop=True)[cols]\n",
    "    \n",
    "    df['timediff1'] = (df['timestamp'].diff(1)).fillna(0).astype('int32')\n",
    "    df['timediff-1'] = (df['timestamp'].diff(-1)).fillna(0).astype('int32')\n",
    "    tmp_uid_diff = (df['uid'].diff(-1)).fillna(-1).astype('int32')\n",
    "    df.loc[tmp_uid_diff!=0,'timediff-1'] = 0\n",
    "    df = df.merge(df[df['timediff-1']<-10800000].groupby('uid')['uid_continue_learning_mins'].mean().rename('uid_avg_continue_learning_mins'), left_on='uid', right_index=True,how='left')\n",
    "    df['uid_continue_learning_mins_level'] = df['uid_continue_learning_mins']/df['uid_avg_continue_learning_mins']\n",
    "    if verbose: print('df shape:', df.shape)\n",
    "    \n",
    "    timelimit = 6*3600*1000\n",
    "    tmp=df_tmp_groupby.parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='asc', col=col, timestamp_once=True))\n",
    "    cols = [x for x in tmp.columns if x not in ['uid','timestamp',col]]\n",
    "    df[cols] = tmp.reset_index(drop=True)[cols]\n",
    "    timelimit = 3*24*3600*1000\n",
    "    tmp=df_tmp_groupby.parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='asc', col=col, timestamp_once=True))\n",
    "    cols = [x for x in tmp.columns if x not in ['uid','timestamp',col]]\n",
    "    df[cols] = tmp.reset_index(drop=True)[cols]\n",
    "    timelimit = 14*24*3600*1000\n",
    "    tmp=df_tmp_groupby.parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='asc', col=col, timestamp_once=True))\n",
    "    cols = [x for x in tmp.columns if x not in ['uid','timestamp',col]]\n",
    "    df[cols] = tmp.reset_index(drop=True)[cols]\n",
    "    timelimit = 365*24*3600*1000\n",
    "    tmp=df_tmp_groupby.parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='asc', col=col, timestamp_once=True))\n",
    "    cols = [x for x in tmp.columns if x not in ['uid','timestamp',col]]\n",
    "    df[cols] = tmp.reset_index(drop=True)[cols]\n",
    "    timelimit = 3600*1000\n",
    "    tmp=df[['uid','timestamp',col]].sort_values(by=['uid','timestamp','question'], ascending=False).groupby(['uid']).parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='desc', col=col, only_once=True, timestamp_once=True))\n",
    "    cols = [x for x in tmp.columns if x not in ['uid','timestamp',col]]\n",
    "    df[cols] = tmp.reset_index(drop=True).sort_values(by=['uid','timestamp','question'], ascending=True).reset_index(drop=True)[cols]\n",
    "    timelimit = 6*3600*1000\n",
    "    tmp=df[['uid','timestamp',col]].sort_values(by=['uid','timestamp','question'], ascending=False).groupby(['uid']).parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='desc', col=col, only_once=True, timestamp_once=True))\n",
    "    cols = [x for x in tmp.columns if x not in ['uid','timestamp',col]]\n",
    "    df[cols] = tmp.reset_index(drop=True).sort_values(by=['uid','timestamp','question'], ascending=True).reset_index(drop=True)[cols]\n",
    "    timelimit = 3*3600*1000\n",
    "    tmp=df[['uid','timestamp',col]].sort_values(by=['uid','timestamp','question'], ascending=False).groupby(['uid']).parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='desc', col=col, only_once=True, timestamp_once=True))\n",
    "    cols = [x for x in tmp.columns if x not in ['uid','timestamp',col]]\n",
    "    df[cols] = tmp.reset_index(drop=True).sort_values(by=['uid','timestamp','question'], ascending=True).reset_index(drop=True)[cols]\n",
    "    timelimit = 14*24*3600*1000\n",
    "    tmp=df[['uid','timestamp',col]].sort_values(by=['uid','timestamp','question'], ascending=False).groupby(['uid']).parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='desc', col=col, timestamp_once=True))\n",
    "    cols = [x for x in tmp.columns if x not in ['uid','timestamp',col]]\n",
    "    df[cols] = tmp.reset_index(drop=True).sort_values(by=['uid','timestamp','question'], ascending=True).reset_index(drop=True)[cols]\n",
    "    timelimit = 365*3600*1000\n",
    "    tmp=df[['uid','timestamp',col]].sort_values(by=['uid','timestamp','question'], ascending=False).groupby(['uid']).parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='desc', col=col, only_once=True, timestamp_once=True))\n",
    "    cols = [x for x in tmp.columns if x not in ['uid','timestamp',col]]\n",
    "    df[cols] = tmp.reset_index(drop=True).sort_values(by=['uid','timestamp','question'], ascending=True).reset_index(drop=True)[cols]\n",
    "\n",
    "    for col in ['concept']:  # 'kc'\n",
    "        if col == 'kc':\n",
    "            df_tmp = pd.concat([\n",
    "                df.loc[df['kc_1']!=-1,['uid','kc_1','timestamp','question']].rename(columns={'kc_1':'kc'}),\n",
    "                df.loc[df['kc_2']!=-1,['uid','kc_2','timestamp','question']].rename(columns={'kc_2':'kc'}),\n",
    "                df.loc[df['kc_3']!=-1,['uid','kc_3','timestamp','question']].rename(columns={'kc_3':'kc'}),\n",
    "                df.loc[df['kc_4']!=-1,['uid','kc_4','timestamp','question']].rename(columns={'kc_4':'kc'}),\n",
    "                df.loc[df['kc_5']!=-1,['uid','kc_5','timestamp','question']].rename(columns={'kc_5':'kc'}),\n",
    "                df.loc[df['kc_6']!=-1,['uid','kc_6','timestamp','question']].rename(columns={'kc_6':'kc'}),\n",
    "                df.loc[df['kc_7']!=-1,['uid','kc_7','timestamp','question']].rename(columns={'kc_7':'kc'}),\n",
    "                df.loc[df['kc_8']!=-1,['uid','kc_8','timestamp','question']].rename(columns={'kc_8':'kc'}),\n",
    "            ])\n",
    "        elif col == 'concept':\n",
    "            df_tmp = pd.concat([\n",
    "                df.loc[df['concept_1']!=-1,['uid','concept_1','timestamp','question']].rename(columns={'concept_1':'concept'}),\n",
    "                df.loc[df['concept_2']!=-1,['uid','concept_2','timestamp','question']].rename(columns={'concept_2':'concept'}),\n",
    "                df.loc[df['concept_3']!=-1,['uid','concept_3','timestamp','question']].rename(columns={'concept_3':'concept'}),\n",
    "                df.loc[df['concept_4']!=-1,['uid','concept_4','timestamp','question']].rename(columns={'concept_4':'concept'}),\n",
    "                df.loc[df['concept_5']!=-1,['uid','concept_5','timestamp','question']].rename(columns={'concept_5':'concept'}),\n",
    "                df.loc[df['concept_6']!=-1,['uid','concept_6','timestamp','question']].rename(columns={'concept_6':'concept'}),\n",
    "            ])\n",
    "        timelimit = 3600*1000\n",
    "        df_tmp_groupby = df_tmp[['uid','timestamp', 'question',col]].groupby(['uid'])\n",
    "        tmp=df_tmp_groupby.parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='asc', col=col))\n",
    "        tmp = tmp.reset_index(drop=True)[[x for x in tmp.columns if x != col]].groupby(['uid','timestamp','question']).max()\n",
    "        df = df.merge(tmp, left_on=['uid','timestamp','question'], right_index=True)\n",
    "        timelimit = 6*3600*1000\n",
    "        tmp=df_tmp_groupby.parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='asc', col=col))\n",
    "        tmp = tmp.reset_index(drop=True)[[x for x in tmp.columns if x != col]].groupby(['uid','timestamp','question']).max()\n",
    "        df = df.merge(tmp, left_on=['uid','timestamp','question'], right_index=True)\n",
    "        timelimit = 3*24*3600*1000\n",
    "        tmp=df_tmp_groupby.parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='asc', col=col))\n",
    "        tmp = tmp.reset_index(drop=True)[[x for x in tmp.columns if x != col]].groupby(['uid','timestamp','question']).max()\n",
    "        df = df.merge(tmp, left_on=['uid','timestamp','question'], right_index=True)\n",
    "        timelimit = 14*24*3600*1000\n",
    "        tmp=df_tmp_groupby.parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='asc', col=col))\n",
    "        tmp = tmp.reset_index(drop=True)[[x for x in tmp.columns if x != col]].groupby(['uid','timestamp','question']).max()\n",
    "        df = df.merge(tmp, left_on=['uid','timestamp','question'], right_index=True)\n",
    "        timelimit = 365*24*3600*1000\n",
    "        tmp=df_tmp_groupby.parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='asc', col=col))\n",
    "        tmp = tmp.reset_index(drop=True)[[x for x in tmp.columns if x != col]].groupby(['uid','timestamp','question']).max()\n",
    "        df = df.merge(tmp, left_on=['uid','timestamp','question'], right_index=True)\n",
    "        timelimit = 3600*1000\n",
    "        tmp=df_tmp.sort_values(by=['uid','timestamp'], ascending=False).groupby(['uid']).parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='desc', col=col))\n",
    "        tmp = tmp.reset_index(drop=True)[[x for x in tmp.columns if x != col]].groupby(['uid','timestamp','question']).max()\n",
    "        df = df.merge(tmp, left_on=['uid','timestamp','question'], right_index=True)\n",
    "        timelimit = 6*3600*1000\n",
    "        tmp=df_tmp.sort_values(by=['uid','timestamp'], ascending=False).groupby(['uid']).parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='desc', col=col))\n",
    "        tmp = tmp.reset_index(drop=True)[[x for x in tmp.columns if x != col]].groupby(['uid','timestamp','question']).max()\n",
    "        df = df.merge(tmp, left_on=['uid','timestamp','question'], right_index=True)\n",
    "        timelimit = 3*24*3600*1000\n",
    "        tmp=df_tmp.sort_values(by=['uid','timestamp'], ascending=False).groupby(['uid']).parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='desc', col=col))\n",
    "        tmp = tmp.reset_index(drop=True)[[x for x in tmp.columns if x != col]].groupby(['uid','timestamp','question']).max()\n",
    "        df = df.merge(tmp, left_on=['uid','timestamp','question'], right_index=True)\n",
    "        timelimit = 14*24*3600*1000\n",
    "        tmp=df_tmp.sort_values(by=['uid','timestamp'], ascending=False).groupby(['uid']).parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='desc', col=col))\n",
    "        tmp = tmp.reset_index(drop=True)[[x for x in tmp.columns if x != col]].groupby(['uid','timestamp','question']).max()\n",
    "        df = df.merge(tmp, left_on=['uid','timestamp','question'], right_index=True)\n",
    "        timelimit = 365*24*3600*1000\n",
    "        tmp=df_tmp.sort_values(by=['uid','timestamp'], ascending=False).groupby(['uid']).parallel_apply(partial(tmp_func, timelimit=timelimit, print_timedistance='desc', col=col))\n",
    "        tmp = tmp.reset_index(drop=True)[[x for x in tmp.columns if x != col]].groupby(['uid','timestamp','question']).max()\n",
    "        df = df.merge(tmp, left_on=['uid','timestamp','question'], right_index=True)\n",
    "        \n",
    "        range_n = 8 if col == 'kc' else 6\n",
    "        df_tmp2 = df[['uid','question','kc_1','kc_2','kc_3','kc_4','kc_5','kc_6','kc_7','kc_8','concept_1','concept_2','concept_3','concept_4','concept_5','concept_6']].copy()\n",
    "        for i in range(1, range_n+1):\n",
    "            df_tmp2 = df_tmp2.merge(df_tmp.groupby([col])['timestamp'].min().rename(f'new_{col}_{str(i)}_days'), how='left', left_on=f'{col}_{str(i)}', right_index=True)\n",
    "            df_tmp2 = df_tmp2.merge(df_tmp.groupby(['uid',col])['timestamp'].min().rename(f'uid_new_{col}_{str(i)}_days'), how='left', left_on=['uid',f'{col}_{str(i)}'], right_index=True)\n",
    "        df[f'new_{col}_days_min'] = df_tmp2[[f'new_{col}_{str(i)}_days' for i in range(1, range_n+1)]].min(axis=1)\n",
    "        df[f'new_{col}_days_min'] = df[f'new_{col}_days_min']/1000/3600/24\n",
    "        df[f'uid_new_{col}_days_min'] = df_tmp2[[f'uid_new_{col}_{str(i)}_days' for i in range(1, range_n+1)]].min(axis=1)\n",
    "        df[f'uid_new_{col}_days_min'] = df[f'uid_new_{col}_days_min']/1000/3600/24\n",
    "        columns['at'].extend([f'new_{col}_days_min'])\n",
    "        columns['at'].extend([f'uid_new_{col}_days_min'])\n",
    "    \n",
    "    if verbose: print('df shape:', df.shape)\n",
    "    df[f'uid_timestamp_question_meansubmit'] = df[f'uid_timestamp_question_submit'] / (df[f'uid_timedistance_to_last_submit_asc']+0.00001)\n",
    "    \n",
    "    columns['at'].extend(['uid_concept_utilnow_21600_asc', 'uid_concept_utilnow_3600_asc', 'uid_concept_utilnow_94608000_asc', 'uid_concept_utilnow_94608000_desc', 'uid_kc_utilnow_21600_asc', 'uid_kc_utilnow_3600_asc', 'uid_kc_utilnow_94608000_asc', 'uid_kc_utilnow_94608000_desc', 'uid_question_submittimes_21600_asc', 'uid_question_submittimes_3600_asc', 'uid_question_submittimes_94608000_asc', 'uid_question_submittimes_94608000_desc', 'uid_question_utilnow_21600_asc', 'uid_question_utilnow_3600_asc', 'uid_question_utilnow_94608000_asc', 'uid_question_utilnow_94608000_desc', 'uid_timedistance_to_last_submit_asc', 'uid_timedistance_to_last_submit_desc', 'uid_timestamp_question_meansubmit', 'uid_timestamp_question_submit', 'uid_unique_submittimes_21600_asc', 'uid_unique_submittimes_3600_asc', 'uid_unique_submittimes_94608000_asc', 'uid_unique_submittimes_94608000_desc'])\n",
    "    # \"\"\"\n",
    "    \n",
    "    col = 'uid'\n",
    "    for col2 in ['timestamp']:\n",
    "        tmp = df.groupby([col,col2])['response'].agg(['count']).rename(columns={'count':col+'_'+col2+'_showcnt'})\n",
    "        df=df.merge(tmp, how='left', left_on=[col,col2], right_index=True, suffixes=(None,'_1'))\n",
    "        columns['at'].extend([col+'_'+col2+'_showcnt'])\n",
    "        \n",
    "    df = df.merge(df.groupby(['question'])['timestamp'].min().rename('new_question_days'), how='left', left_on='question', right_index=True)\n",
    "    df[f'new_question_days'] = df[f'new_question_days']/1000/3600/24\n",
    "    columns['at'].extend(['new_question_days'])\n",
    "    df = df.merge(df.groupby(['uid','question'])['timestamp'].min().rename('uid_new_question_days'), how='left', left_on=['uid','question'], right_index=True)\n",
    "    df[f'uid_new_question_days'] = df[f'uid_new_question_days']/1000/3600/24\n",
    "    columns['at'].extend(['uid_new_question_days'])\n",
    "    \n",
    "    df.fillna(-1, inplace=True)\n",
    "    if verbose: print('df shape:', df.shape)\n",
    "    \n",
    "    df_tr = df[df['data_type']=='tr'].reset_index(drop=True)\n",
    "    df_tr.set_index(df_tr['raw_index'], inplace=True)\n",
    "    df_test = df[df['data_type']=='test'].reset_index(drop=True)\n",
    "    df_test.set_index(df_test['raw_index'], inplace=True)\n",
    "    \n",
    "    return df_tr, df_test, columns\n",
    "\n",
    "\"\"\"\n",
    "df_tmp,df_tmp2, columns_tmp = feature_engineering(df.iloc[:1000].copy()[['uid', 'question', 'response', 'timestamp', 'type', 'concept_cnt',\n",
    "       'concept_hot_cnt', 'concept_1', 'concept_2', 'concept_3',\n",
    "       'concept_4', 'concept_5', 'concept_6', 'content_cnt',\n",
    "       'kc_group_cnt', 'kc_cnt', 'kc_1', 'kc_2', 'kc_3', 'kc_4', 'kc_5',\n",
    "       'kc_6', 'kc_7', 'kc_8', 'analysis_cnt', 'time_day', 'time_hour',\n",
    "       'time_is_workday', 'time_weekday', 'time_year']], df_test.iloc[:1000].copy()[['uid', 'question', 'response', 'timestamp', 'type', 'concept_cnt',\n",
    "       'concept_hot_cnt', 'concept_1', 'concept_2', 'concept_3',\n",
    "       'concept_4', 'concept_5', 'concept_6', 'content_cnt',\n",
    "       'kc_group_cnt', 'kc_cnt', 'kc_1', 'kc_2', 'kc_3', 'kc_4', 'kc_5',\n",
    "       'kc_6', 'kc_7', 'kc_8', 'analysis_cnt', 'time_day', 'time_hour',\n",
    "       'time_is_workday', 'time_weekday', 'time_year']])\n",
    "print(columns_tmp)\n",
    "df_tmp\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T16:17:57.807244Z",
     "start_time": "2022-12-19T16:05:14.192061Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (5549523, 34)\n",
      "df shape: (5549523, 114)\n",
      "df shape: (5549523, 134)\n",
      "df shape: (5549523, 135)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (5549523, 145)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n",
      "/home/maoshijian/anaconda3/envs/msj-aaai2023/lib/python3.10/site-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  iterator = iter(dataframe_groupby)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (5549523, 185)\n",
      "df shape: (5549523, 189)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, df_test, columns = feature_engineering(df, df_test, verbose=1)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T16:20:03.745064Z",
     "start_time": "2022-12-19T16:17:57.809196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of properties dataframe is : 5631.670822143555  MB\n",
      "******************************\n",
      "Column:  uid\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  question\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  response\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  timestamp\n",
      "dtype before:  int64\n",
      "dtype after:  int64\n",
      "******************************\n",
      "******************************\n",
      "Column:  type\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_cnt\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_hot_cnt\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_1\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_2\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_3\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_4\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_5\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_6\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  content_cnt\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_group_cnt\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_cnt\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_1\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_2\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_3\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_4\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_5\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_6\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_7\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_8\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  analysis_cnt\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_day\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_hour\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_is_workday\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_weekday\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_year\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  raw_index\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_record_cumsum\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_record_sum\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_showcnt_1\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_accrate_1\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_showcnt_2\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_accrate_2\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_showcnt_3\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_accrate_3\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_showcnt_4\n",
      "dtype before:  float64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_accrate_4\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_showcnt_5\n",
      "dtype before:  float64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_accrate_5\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_showcnt_6\n",
      "dtype before:  float64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_accrate_6\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_showcnt_1\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_accrate_1\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_showcnt_2\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_accrate_2\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_showcnt_3\n",
      "dtype before:  float64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_accrate_3\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_showcnt_4\n",
      "dtype before:  float64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_accrate_4\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_showcnt_5\n",
      "dtype before:  float64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_accrate_5\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_showcnt_6\n",
      "dtype before:  float64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_accrate_6\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_min_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_mean_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_max_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_min_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_mean_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_max_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concepttype_min_accrate\n",
      "dtype before:  float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concepttype_mean_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concepttype_max_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concepttype_min_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concepttype_mean_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concepttype_max_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_showcnt_1\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_accrate_1\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_showcnt_2\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_accrate_2\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_showcnt_3\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_accrate_3\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_showcnt_4\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_accrate_4\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_showcnt_5\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_accrate_5\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_showcnt_6\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_accrate_6\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_showcnt_7\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_accrate_7\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_showcnt_8\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_accrate_8\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_showcnt_1\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_accrate_1\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_showcnt_2\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_accrate_2\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_showcnt_3\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_accrate_3\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_showcnt_4\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_accrate_4\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_showcnt_5\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_accrate_5\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_showcnt_6\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_accrate_6\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_showcnt_7\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_accrate_7\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_showcnt_8\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_accrate_8\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_min_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_mean_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_max_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_min_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_mean_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_max_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kctype_min_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kctype_mean_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kctype_max_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kctype_min_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kctype_mean_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kctype_max_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  question_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  question_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  type_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  type_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_hour_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_hour_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_is_workday_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_is_workday_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_weekday_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_weekday_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  type_1_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  type_0_showcnt\n",
      "dtype before:  int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  type_1_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  type_0_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_is_workday_1_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_is_workday_0_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_is_workday_1_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_is_workday_0_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  timestamp_question_cnt\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_3600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_3600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_3600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_timedistance_to_last_submit_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_timestamp_question_submit\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_continue_learning_mins\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  timediff1\n",
      "dtype before:  int32\n",
      "dtype after:  int64\n",
      "******************************\n",
      "******************************\n",
      "Column:  timediff-1\n",
      "dtype before:  int32\n",
      "dtype after:  int64\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_avg_continue_learning_mins\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_continue_learning_mins_level\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_21600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_21600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_21600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_259200_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_259200_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_259200_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_1209600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_1209600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_1209600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_31536000_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_31536000_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_31536000_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_3600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_3600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_3600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_timedistance_to_last_submit_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_21600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_21600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_21600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_10800_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_10800_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_10800_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_1209600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_1209600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_1209600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_1314000_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_1314000_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_1314000_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_3600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_21600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_259200_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_1209600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_31536000_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_3600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_21600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_259200_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_1209600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_31536000_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  new_concept_days_min\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_new_concept_days_min\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_timestamp_question_meansubmit\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_timestamp_showcnt\n",
      "dtype before:  int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  new_question_days\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_new_question_days\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  2421.4488248825073  MB\n",
      "This is  42.99698795180723 % of the initial size\n",
      "nan_list: []\n",
      "Memory usage of properties dataframe is : 1396.6862487792969  MB\n",
      "******************************\n",
      "Column:  uid\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  question\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  response\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  timestamp\n",
      "dtype before:  int64\n",
      "dtype after:  int64\n",
      "******************************\n",
      "******************************\n",
      "Column:  type\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_cnt\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_hot_cnt\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_1\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_2\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_3\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_4\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_5\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_6\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  content_cnt\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_group_cnt\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_cnt\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_1\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_2\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_3\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_4\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_5\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_6\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_7\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_8\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  analysis_cnt\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_day\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_hour\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_is_workday\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_weekday\n",
      "dtype before:  int8\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_year\n",
      "dtype before:  int16\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  raw_index\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_record_cumsum\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_record_sum\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_showcnt_1\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_accrate_1\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_showcnt_2\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_accrate_2\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_showcnt_3\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_accrate_3\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_showcnt_4\n",
      "dtype before:  float64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_accrate_4\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_showcnt_5\n",
      "dtype before:  float64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_accrate_5\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_showcnt_6\n",
      "dtype before:  float64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_accrate_6\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_showcnt_1\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_accrate_1\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_showcnt_2\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_accrate_2\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_showcnt_3\n",
      "dtype before:  float64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_accrate_3\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_showcnt_4\n",
      "dtype before:  float64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_accrate_4\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_showcnt_5\n",
      "dtype before:  float64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_accrate_5\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_showcnt_6\n",
      "dtype before:  float64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_type_accrate_6\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_min_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_mean_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_max_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_min_showcnt\n",
      "dtype before:  float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_mean_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concept_max_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concepttype_min_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concepttype_mean_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concepttype_max_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concepttype_min_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concepttype_mean_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  concepttype_max_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_showcnt_1\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_accrate_1\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_showcnt_2\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_accrate_2\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_showcnt_3\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_accrate_3\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_showcnt_4\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_accrate_4\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_showcnt_5\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_accrate_5\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_showcnt_6\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_accrate_6\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_showcnt_7\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_accrate_7\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_showcnt_8\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_accrate_8\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_showcnt_1\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_accrate_1\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_showcnt_2\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_accrate_2\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_showcnt_3\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_accrate_3\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_showcnt_4\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_accrate_4\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_showcnt_5\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_accrate_5\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_showcnt_6\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_accrate_6\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_showcnt_7\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_accrate_7\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_showcnt_8\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_type_accrate_8\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_min_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_mean_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_max_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_min_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_mean_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kc_max_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kctype_min_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kctype_mean_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kctype_max_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kctype_min_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kctype_mean_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  kctype_max_showcnt\n",
      "dtype before:  float64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  question_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  question_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  type_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  type_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_hour_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_hour_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_is_workday_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_is_workday_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_weekday_showcnt\n",
      "dtype before:  int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_weekday_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  type_1_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  type_0_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  type_1_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  type_0_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_is_workday_1_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_is_workday_0_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_is_workday_1_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  time_is_workday_0_accrate\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  timestamp_question_cnt\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_3600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_3600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_3600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_timedistance_to_last_submit_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_timestamp_question_submit\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_continue_learning_mins\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  timediff1\n",
      "dtype before:  int32\n",
      "dtype after:  int64\n",
      "******************************\n",
      "******************************\n",
      "Column:  timediff-1\n",
      "dtype before:  int32\n",
      "dtype after:  int64\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_avg_continue_learning_mins\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_continue_learning_mins_level\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_21600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_21600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_21600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_259200_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_259200_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_259200_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_1209600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_1209600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_1209600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_31536000_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_31536000_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_31536000_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_3600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_3600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_3600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_timedistance_to_last_submit_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_21600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_21600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_21600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_10800_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_10800_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_10800_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_1209600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_1209600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_1209600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_utilnow_1314000_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_question_submittimes_1314000_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int16\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_unique_submittimes_1314000_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_3600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_21600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_259200_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_1209600_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_31536000_asc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_3600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_21600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_259200_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_1209600_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_concept_utilnow_31536000_desc\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  new_concept_days_min\n",
      "dtype before:  float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_new_concept_days_min\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_timestamp_question_meansubmit\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_timestamp_showcnt\n",
      "dtype before:  int64\n",
      "dtype after:  int8\n",
      "******************************\n",
      "******************************\n",
      "Column:  new_question_days\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  uid_new_question_days\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  600.5330181121826  MB\n",
      "This is  42.99698795180723 % of the initial size\n",
      "nan_list: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, nalist = reduce_mem_usage(df)\n",
    "df_test, nalist = reduce_mem_usage(df_test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 临时保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T16:20:10.069714Z",
     "start_time": "2022-12-19T16:20:03.746835Z"
    }
   },
   "outputs": [],
   "source": [
    "df.reset_index(drop=True).to_feather('./input/df_features_v1214_3.feather')\n",
    "df_test.reset_index(drop=True).to_feather('./input/df_test_features_v1214_3.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T03:36:11.396527Z",
     "start_time": "2022-12-30T03:36:10.484339Z"
    }
   },
   "outputs": [],
   "source": [
    "#df = pd.read_feather('./input/df_features_v1214_3.feather')\n",
    "#df_test = pd.read_feather('./input/df_test_features_v1214_3.feather')\n",
    "#columns = {'at': ['uid_record_cumsum', 'uid_record_sum', 'question', 'timestamp', 'type', 'concept_cnt', 'concept_hot_cnt', 'concept_1', 'concept_2', 'concept_3', 'concept_4', 'concept_5', 'concept_6', 'content_cnt', 'kc_group_cnt', 'kc_cnt', 'kc_1', 'kc_2', 'kc_3', 'kc_4', 'kc_5', 'kc_6', 'kc_7', 'kc_8', 'analysis_cnt', 'time_day', 'time_hour', 'time_is_workday', 'time_weekday', 'time_year', 'concept_min_accrate', 'concept_min_showcnt', 'concept_mean_accrate', 'concept_mean_showcnt', 'concept_max_accrate', 'concept_max_showcnt', 'concept_showcnt_1', 'concept_accrate_1', 'concept_type_showcnt_1', 'concept_type_accrate_1', 'concept_showcnt_2', 'concept_accrate_2', 'concept_type_showcnt_2', 'concept_type_accrate_2', 'concept_showcnt_3', 'concept_accrate_3', 'concept_type_showcnt_3', 'concept_type_accrate_3', 'concept_showcnt_4', 'concept_accrate_4', 'concept_type_showcnt_4', 'concept_type_accrate_4', 'concept_showcnt_5', 'concept_accrate_5', 'concept_type_showcnt_5', 'concept_type_accrate_5', 'concept_showcnt_6', 'concept_accrate_6', 'concept_type_showcnt_6', 'concept_type_accrate_6', 'concepttype_min_accrate', 'concepttype_min_showcnt', 'concepttype_mean_accrate', 'concepttype_mean_showcnt', 'concepttype_max_accrate', 'concepttype_max_showcnt', 'kc_showcnt_1', 'kc_accrate_1', 'kc_type_showcnt_1', 'kc_type_accrate_1', 'kc_showcnt_2', 'kc_accrate_2', 'kc_type_showcnt_2', 'kc_type_accrate_2', 'kc_showcnt_3', 'kc_accrate_3', 'kc_type_showcnt_3', 'kc_type_accrate_3', 'kc_showcnt_4', 'kc_accrate_4', 'kc_type_showcnt_4', 'kc_type_accrate_4', 'kc_showcnt_5', 'kc_accrate_5', 'kc_type_showcnt_5', 'kc_type_accrate_5', 'kc_showcnt_6', 'kc_accrate_6', 'kc_type_showcnt_6', 'kc_type_accrate_6', 'kc_showcnt_7', 'kc_accrate_7', 'kc_type_showcnt_7', 'kc_type_accrate_7', 'kc_min_accrate', 'kc_min_showcnt', 'kc_mean_accrate', 'kc_mean_showcnt', 'kc_max_accrate', 'kc_max_showcnt', 'kctype_min_accrate', 'kctype_min_showcnt', 'kctype_mean_accrate', 'kctype_mean_showcnt', 'kctype_max_accrate', 'kctype_max_showcnt', 'question_showcnt', 'question_accrate', 'uid_showcnt', 'uid_accrate', 'type_showcnt', 'type_accrate', 'time_hour_showcnt', 'time_hour_accrate', 'time_is_workday_showcnt', 'time_is_workday_accrate', 'time_weekday_showcnt', 'time_weekday_accrate', 'timestamp_question_cnt', 'timestamp_question_accrate', 'question_accrate_without_timestamp_question', 'question_showcnt_without_timestamp_question', 'uid_concept_utilnow_21600_asc', 'uid_concept_utilnow_3600_asc', 'uid_concept_utilnow_94608000_asc', 'uid_concept_utilnow_94608000_desc', 'uid_kc_utilnow_21600_asc', 'uid_kc_utilnow_3600_asc', 'uid_kc_utilnow_94608000_asc', 'uid_kc_utilnow_94608000_desc', 'uid_question_submittimes_21600_asc', 'uid_question_submittimes_3600_asc', 'uid_question_submittimes_94608000_asc', 'uid_question_submittimes_94608000_desc', 'uid_question_utilnow_21600_asc', 'uid_question_utilnow_3600_asc', 'uid_question_utilnow_94608000_asc', 'uid_question_utilnow_94608000_desc', 'uid_timedistance_to_last_submit_asc', 'uid_timedistance_to_last_submit_desc', 'uid_timestamp_question_meansubmit', 'uid_timestamp_question_submit', 'uid_unique_submittimes_21600_asc', 'uid_unique_submittimes_3600_asc', 'uid_unique_submittimes_94608000_asc', 'uid_unique_submittimes_94608000_desc', 'uid_timestamp_showcnt'], 'bs': [], 'bt': [], 'bh': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T03:36:11.427218Z",
     "start_time": "2022-12-30T03:36:11.399223Z"
    }
   },
   "outputs": [],
   "source": [
    "kf_or=['uid_question_utilnow_10800_desc', 'uid_question_submittimes_3600_desc', 'uid_concept_utilnow_1209600_asc', 'uid_question_utilnow_31536000_asc', 'concept_showcnt_2', 'uid_question_submittimes_21600_asc', 'kc_type_showcnt_1', 'cnt_finishsimiliar_contentsimstrict_31536000000', 'concepttype_max_showcnt', 'kc_showcnt_1', 'question_accrate', 'kc_type_accrate_4', 'accrate_similiar_strict_contentsim_86400000', 'concept_accrate_1', 'uid_showcnt', 'acctop5max_similiar_contentsim_-21600000', 'concept_type_accrate_1', 'time_day', 'uid_concept_utilnow_31536000_asc', 'kc_type_accrate_5', 'cnt_finishstrictsimiliar_-21600000', 'uid_new_concept_days_min', 'time_weekday_showcnt', 'cnt_accstrictsimiliar_31536000000', 'time_weekday_accrate', 'uid_question_utilnow_259200_asc', 'acctop5_finishstrictsimiliar_contentsimstrict_-1209600000', 'concept_5', 'kc_accrate_2', 'uid_concept_utilnow_21600_asc', 'type_accrate', 'uid_unique_submittimes_21600_asc', 'kc_showcnt_6', 'cnt_accsimiliar_contentsimstrict_1209600000', 'cnt_finishstrictsimiliar_contentsimstrict_-21600000', 'concept_2', 'cnt_accsimiliar_contentsim_1209600000', 'concepttype_min_accrate', 'kc_type_showcnt_5', 'uid_question_utilnow_3600_desc', 'kc_4', 'acctop5_finishsimiliar_contentsim_31536000000', 'kc_6', 'uid_timedistance_to_last_submit_desc', 'time_is_workday_0_accrate', 'uid_accrate', 'acctop1max_similiar_strict_-21600000', 'concept_cnt', 'kc_max_accrate', 'concept_showcnt_3', 'uid_concept_utilnow_21600_desc', 'uid_question_utilnow_1209600_desc', 'kc_type_accrate_7', 'cnt_finishsimiliar_contentsimstrict_-21600000', 'acctop5_finishstrictsimiliar_contentsim_-21600000', 'kc_type_showcnt_4', 'new_concept_days_min', 'acctop5max_similiar_strict_3600000', 'uid_concept_type_accrate_2', 'uid_kc_accrate_8', 'kctype_max_showcnt', 'acctop5_accsimiliar_contentsim_31536000000', 'accrate_similiar_contentsimstrict_3600000', 'kctype_min_showcnt', 'concept_hot_cnt', 'kc_accrate_5', 'accrate_similiar_strict_contentsimstrict_1209600000', 'uid_concept_type_accrate_4', 'concepttype_min_showcnt', 'acctop5max_similiar_contentsim_31536000000', 'concept_type_showcnt_6', 'concept_type_showcnt_5', 'concept_type_showcnt_1', 'kc_type_accrate_2', 'uidconcepttype_max_accrate', 'acctop5_finishsimiliar_contentsimstrict_86400000', 'concept_1', 'uid_timestamp_question_meansubmit', 'kc_group_cnt', 'acctop5max_similiar_-21600000', 'kc_type_accrate_1', 'concept_4', 'uid_timestamp_showcnt', 'uid_question_submittimes_1209600_desc', 'concepttype_max_accrate', 'concept_mean_showcnt', 'uid_timestamp_question_submit', 'kc_5', 'concepttype_mean_showcnt', 'kctype_min_accrate', 'acctop5max_similiar_strict_-21600000', 'concept_type_showcnt_3', 'uid_question_utilnow_21600_desc', 'uid_concept_type_accrate_5', 'timestamp_question_cnt', 'kc_1', 'concept_showcnt_1', 'kctype_max_accrate', 'uid_kc_accrate_4', 'concept_type_accrate_2', 'concept_type_showcnt_2', 'uid_unique_submittimes_10800_desc', 'timediff1', 'concept_accrate_4', 'question_showcnt', 'uid_timedistance_to_last_submit_asc', 'kc_type_accrate_8', 'kc_type_showcnt_3', 'kc_mean_showcnt', 'acctop5max_similiar_contentsimstrict_-21600000', 'uid_record_cumsum', 'acctop5max_similiar_strict_contentsim_31536000000', 'kc_min_accrate', 'kctype_mean_showcnt', 'question', 'concept_mean_accrate', 'uid_concept_accrate_4', 'uidkc_mean_accrate', 'timediff-1', 'uid_concept_utilnow_259200_desc', 'accrate_similiar_86400000', 'uid_kc_accrate_1', 'kctype_mean_accrate', 'analysis_cnt', 'acctop5max_similiar_strict_contentsim_86400000', 'uid_question_utilnow_21600_asc', 'kc_accrate_4', 'concept_min_showcnt', 'kc_type_showcnt_6', 'concept_showcnt_4', 'acctop1_accstrictsimiliar_86400000', 'uid_concept_type_accrate_1', 'uid_question_utilnow_1209600_asc', 'kc_max_showcnt', 'acctop5_finishstrictsimiliar_contentsimstrict_-21600000', 'concept_max_accrate', 'kc_2', 'concept_type_accrate_4', 'time_hour', 'concept_accrate_2', 'acctop1max_similiar_strict_contentsimstrict_-21600000', 'content_cnt', 'kc_type_accrate_3', 'concept_type_accrate_3', 'timestamp', 'kc_3', 'new_question_days', 'acctop5_finishstrictsimiliar_-21600000', 'time_year', 'kc_cnt', 'uid_question_utilnow_1314000_desc', 'acctop5max_similiar_strict_contentsim_-21600000', 'uid_concept_utilnow_1209600_desc', 'uid_concept_type_accrate_6', 'acctop1_finishstrictsimiliar_contentsimstrict_3600000', 'uid_kc_accrate_2', 'kc_showcnt_4', 'kc_type_showcnt_2', 'kc_type_showcnt_8', 'uid_question_utilnow_3600_asc', 'uid_unique_submittimes_21600_desc', 'concept_type_accrate_6', 'uid_question_submittimes_3600_asc', 'kc_accrate_1']\n",
    "kf0=['kc_type_accrate_1', 'concept_showcnt_3', 'cnt_finishstrictsimiliar_-21600000', 'acctop5_finishsimiliar_contentsimstrict_86400000', 'kc_6', 'uid_accrate', 'concept_type_showcnt_5', 'kc_type_showcnt_6', 'time_weekday_accrate', 'acctop5max_similiar_contentsim_-21600000', 'accrate_similiar_strict_contentsimstrict_1209600000', 'concept_cnt', 'kc_type_showcnt_8', 'concept_type_showcnt_1', 'uid_concept_utilnow_21600_asc', 'kc_2', 'kc_accrate_5', 'uid_unique_submittimes_21600_desc', 'uid_kc_accrate_4', 'concepttype_min_showcnt', 'concept_accrate_1', 'accrate_similiar_strict_contentsim_86400000', 'acctop1max_similiar_strict_-21600000', 'uid_concept_utilnow_259200_desc', 'uid_question_utilnow_21600_asc', 'kc_type_showcnt_4', 'uid_kc_accrate_8', 'uid_concept_type_accrate_4', 'acctop5_finishstrictsimiliar_contentsim_-21600000', 'kc_type_accrate_4', 'kc_3', 'uid_unique_submittimes_21600_asc', 'concept_type_accrate_3', 'uid_kc_accrate_2', 'kctype_mean_showcnt', 'uid_question_utilnow_31536000_asc', 'question_accrate', 'acctop5max_similiar_strict_contentsim_86400000', 'concept_accrate_4', 'kc_type_accrate_7', 'uid_timestamp_showcnt', 'kc_type_showcnt_2', 'uid_question_utilnow_3600_desc', 'acctop5_finishstrictsimiliar_contentsimstrict_-1209600000', 'acctop5max_similiar_strict_-21600000', 'uid_concept_accrate_4', 'time_hour', 'kctype_min_accrate', 'concept_max_accrate', 'kc_group_cnt', 'accrate_similiar_contentsimstrict_3600000', 'uid_concept_utilnow_21600_desc', 'uid_timestamp_question_meansubmit', 'acctop5_accsimiliar_contentsim_31536000000', 'concept_mean_showcnt', 'concept_1', 'uid_timedistance_to_last_submit_desc', 'acctop5_finishstrictsimiliar_contentsimstrict_-21600000', 'time_year', 'time_weekday_showcnt', 'cnt_accsimiliar_contentsimstrict_1209600000', 'kc_min_accrate', 'uid_question_submittimes_3600_asc', 'uid_showcnt', 'concepttype_mean_showcnt', 'cnt_finishsimiliar_contentsimstrict_31536000000', 'cnt_finishsimiliar_contentsimstrict_-21600000', 'acctop1_finishstrictsimiliar_contentsimstrict_3600000', 'uidconcepttype_max_accrate', 'uid_question_utilnow_21600_desc', 'kc_type_accrate_8', 'uid_concept_utilnow_1209600_asc', 'kc_type_showcnt_1', 'timediff1', 'uid_concept_utilnow_1209600_desc', 'concept_type_showcnt_2', 'uid_question_utilnow_3600_asc', 'uid_concept_type_accrate_2', 'analysis_cnt', 'concepttype_max_showcnt', 'uid_question_utilnow_10800_desc', 'concepttype_min_accrate', 'kctype_max_showcnt', 'kctype_min_showcnt', 'timestamp_question_cnt', 'concept_type_accrate_4', 'concept_2', 'kc_type_accrate_3', 'concepttype_max_accrate', 'concept_5', 'kc_cnt', 'kc_max_accrate', 'acctop5_finishstrictsimiliar_-21600000', 'uid_question_utilnow_1209600_desc', 'uid_question_utilnow_1314000_desc', 'type_accrate', 'uid_unique_submittimes_10800_desc', 'concept_hot_cnt', 'cnt_finishstrictsimiliar_contentsimstrict_-21600000', 'uid_question_utilnow_1209600_asc', 'kc_type_accrate_2', 'concept_min_showcnt', 'kc_5', 'kc_accrate_1', 'acctop5max_similiar_-21600000', 'acctop5max_similiar_strict_contentsim_31536000000', 'kc_accrate_4', 'concept_type_accrate_6', 'kc_type_showcnt_3', 'uid_question_submittimes_21600_asc', 'question_showcnt', 'kctype_max_accrate', 'content_cnt', 'uid_new_concept_days_min', 'acctop5max_similiar_contentsim_31536000000', 'acctop1max_similiar_strict_contentsimstrict_-21600000', 'concept_4', 'question', 'kc_type_showcnt_5', 'uidkc_mean_accrate', 'acctop5max_similiar_contentsimstrict_-21600000', 'kc_max_showcnt', 'acctop5_finishsimiliar_contentsim_31536000000', 'acctop1_accstrictsimiliar_86400000', 'acctop5max_similiar_strict_3600000', 'kc_accrate_2', 'uid_concept_utilnow_31536000_asc', 'kc_showcnt_4', 'kc_showcnt_6', 'kc_4', 'uid_question_utilnow_259200_asc', 'kc_type_accrate_5', 'kc_mean_showcnt', 'kc_showcnt_1', 'kc_1', 'new_concept_days_min', 'new_question_days', 'uid_timedistance_to_last_submit_asc', 'uid_question_submittimes_1209600_desc', 'kctype_mean_accrate', 'timestamp', 'uid_concept_type_accrate_6', 'accrate_similiar_86400000', 'cnt_accsimiliar_contentsim_1209600000', 'uid_kc_accrate_1', 'cnt_accstrictsimiliar_31536000000', 'acctop5max_similiar_strict_contentsim_-21600000', 'uid_question_submittimes_3600_desc']\n",
    "kf1=['concepttype_min_accrate', 'kc_3', 'concept_cnt', 'uid_question_utilnow_1314000_desc', 'acctop5max_similiar_contentsim_31536000000', 'kc_type_showcnt_4', 'acctop5max_similiar_strict_3600000', 'acctop5max_similiar_-21600000', 'cnt_accsimiliar_contentsimstrict_1209600000', 'kc_accrate_2', 'concept_type_showcnt_6', 'uid_concept_accrate_4', 'kc_showcnt_6', 'uid_question_submittimes_1209600_desc', 'timestamp', 'concept_type_accrate_6', 'kc_mean_showcnt', 'kctype_min_accrate', 'acctop5_finishstrictsimiliar_-21600000', 'uid_timedistance_to_last_submit_asc', 'kc_accrate_4', 'uid_question_utilnow_1209600_asc', 'uid_record_cumsum', 'concept_showcnt_4', 'concept_4', 'kc_type_showcnt_1', 'uid_concept_utilnow_259200_desc', 'timediff-1', 'kc_4', 'uidconcepttype_max_accrate', 'kc_accrate_1', 'time_is_workday_0_accrate', 'kctype_mean_showcnt', 'kc_5', 'uid_question_utilnow_31536000_asc', 'kctype_mean_accrate', 'kc_type_accrate_3', 'acctop5_finishstrictsimiliar_contentsimstrict_-1209600000', 'concept_accrate_4', 'kc_type_showcnt_2', 'concept_5', 'uid_question_utilnow_10800_desc', 'acctop5max_similiar_strict_contentsim_86400000', 'uid_kc_accrate_8', 'concept_max_accrate', 'concept_hot_cnt', 'kc_type_accrate_2', 'uid_kc_accrate_2', 'concept_2', 'uid_question_submittimes_3600_asc', 'uid_question_utilnow_3600_desc', 'concept_accrate_2', 'uid_concept_type_accrate_2', 'concepttype_min_showcnt', 'kc_2', 'uid_accrate', 'uid_question_utilnow_21600_desc', 'time_year', 'concept_type_accrate_4', 'kc_type_accrate_7', 'uid_concept_type_accrate_6', 'cnt_accstrictsimiliar_31536000000', 'new_question_days', 'kc_type_showcnt_5', 'acctop5_finishstrictsimiliar_contentsimstrict_-21600000', 'uid_concept_utilnow_21600_desc', 'kc_type_showcnt_6', 'concept_showcnt_1', 'kc_type_showcnt_8', 'concepttype_max_accrate', 'acctop5_accsimiliar_contentsim_31536000000', 'kc_showcnt_1', 'question_accrate', 'uid_timestamp_question_meansubmit', 'kc_accrate_5', 'kc_cnt', 'uid_concept_utilnow_1209600_asc', 'new_concept_days_min', 'cnt_finishsimiliar_contentsimstrict_31536000000', 'concept_accrate_1', 'acctop5_finishstrictsimiliar_contentsim_-21600000', 'uid_unique_submittimes_21600_desc', 'time_weekday_accrate', 'kc_type_accrate_4', 'concept_1', 'concept_mean_showcnt', 'uid_timedistance_to_last_submit_desc', 'accrate_similiar_strict_contentsim_86400000', 'time_day', 'concept_showcnt_2', 'uid_timestamp_question_submit', 'uid_concept_type_accrate_5', 'acctop5max_similiar_strict_contentsim_-21600000', 'kc_type_showcnt_3', 'kc_type_accrate_8', 'uid_question_submittimes_21600_asc', 'uid_kc_accrate_4', 'concept_type_showcnt_1', 'content_cnt', 'concept_mean_accrate', 'kc_max_accrate', 'analysis_cnt', 'kc_max_showcnt', 'concepttype_mean_showcnt', 'type_accrate', 'uid_concept_utilnow_31536000_asc', 'question_showcnt', 'timestamp_question_cnt', 'uidkc_mean_accrate', 'kc_showcnt_4', 'kc_type_accrate_1', 'acctop5max_similiar_contentsimstrict_-21600000', 'uid_unique_submittimes_10800_desc', 'kc_6', 'kc_1', 'acctop5max_similiar_strict_contentsim_31536000000', 'uid_unique_submittimes_21600_asc', 'uid_question_submittimes_3600_desc', 'kctype_max_showcnt', 'accrate_similiar_86400000', 'concept_type_accrate_2', 'cnt_finishstrictsimiliar_-21600000', 'acctop5_finishsimiliar_contentsimstrict_86400000', 'kctype_max_accrate', 'concept_showcnt_3', 'uid_timestamp_showcnt', 'uid_concept_type_accrate_1', 'cnt_finishsimiliar_contentsimstrict_-21600000', 'acctop1_finishstrictsimiliar_contentsimstrict_3600000', 'concept_type_showcnt_5', 'question', 'concept_type_accrate_1', 'acctop1_accstrictsimiliar_86400000', 'concept_type_showcnt_3', 'accrate_similiar_contentsimstrict_3600000', 'uid_concept_utilnow_21600_asc', 'acctop1max_similiar_strict_-21600000', 'kc_type_accrate_5', 'kctype_min_showcnt', 'concepttype_max_showcnt', 'uid_concept_type_accrate_4', 'uid_question_utilnow_21600_asc', 'cnt_accsimiliar_contentsim_1209600000', 'uid_question_utilnow_3600_asc', 'uid_new_concept_days_min', 'acctop5_finishsimiliar_contentsim_31536000000', 'uid_question_utilnow_1209600_desc', 'timediff1', 'uid_question_utilnow_259200_asc', 'concept_type_accrate_3', 'kc_group_cnt', 'cnt_finishstrictsimiliar_contentsimstrict_-21600000', 'kc_min_accrate', 'time_weekday_showcnt', 'uid_concept_utilnow_1209600_desc', 'acctop5max_similiar_strict_-21600000', 'acctop1max_similiar_strict_contentsimstrict_-21600000', 'time_hour']\n",
    "kf9=['kc_showcnt_6', 'uid_kc_accrate_8', 'acctop5max_similiar_-21600000', 'acctop5max_similiar_contentsim_31536000000', 'uid_timestamp_question_meansubmit', 'type_accrate', 'acctop1max_similiar_strict_-21600000', 'uid_kc_accrate_4', 'kctype_max_showcnt', 'acctop5_finishstrictsimiliar_-21600000', 'concepttype_mean_showcnt', 'content_cnt', 'uid_new_concept_days_min', 'kc_1', 'kc_cnt', 'kc_3', 'acctop5_finishstrictsimiliar_contentsimstrict_-21600000', 'concept_hot_cnt', 'acctop5_finishstrictsimiliar_contentsim_-21600000', 'acctop1_finishstrictsimiliar_contentsimstrict_3600000', 'uid_unique_submittimes_21600_asc', 'uid_question_utilnow_1209600_desc', 'kc_type_accrate_7', 'new_question_days', 'uid_timedistance_to_last_submit_desc', 'cnt_accsimiliar_contentsim_1209600000', 'kc_showcnt_1', 'accrate_similiar_contentsimstrict_3600000', 'uid_question_utilnow_259200_asc', 'timestamp_question_cnt', 'uid_concept_utilnow_1209600_asc', 'kc_accrate_4', 'uid_unique_submittimes_21600_desc', 'uid_concept_accrate_4', 'acctop5max_similiar_contentsimstrict_-21600000', 'uid_concept_utilnow_21600_desc', 'uid_question_utilnow_10800_desc', 'kctype_min_showcnt', 'cnt_finishsimiliar_contentsimstrict_-21600000', 'acctop5max_similiar_strict_3600000', 'acctop1max_similiar_strict_contentsimstrict_-21600000', 'kc_type_showcnt_6', 'concepttype_min_accrate', 'acctop1_accstrictsimiliar_86400000', 'uid_concept_type_accrate_4', 'kc_5', 'kc_type_accrate_4', 'question_showcnt', 'concept_max_accrate', 'acctop5_accsimiliar_contentsim_31536000000', 'timediff1', 'uid_kc_accrate_2', 'kc_2', 'uid_question_utilnow_1209600_asc', 'kc_type_accrate_2', 'kc_mean_showcnt', 'kc_min_accrate', 'analysis_cnt', 'kc_type_showcnt_4', 'uid_concept_utilnow_31536000_asc', 'acctop5_finishsimiliar_contentsim_31536000000', 'uidconcepttype_max_accrate', 'cnt_accsimiliar_contentsimstrict_1209600000', 'kc_accrate_5', 'kc_accrate_1', 'accrate_similiar_86400000', 'concept_2', 'acctop5max_similiar_strict_contentsim_86400000', 'concept_1', 'kctype_mean_showcnt', 'kc_group_cnt', 'concept_type_accrate_6', 'acctop5_finishsimiliar_contentsimstrict_86400000', 'acctop5max_similiar_strict_contentsim_31536000000', 'cnt_finishstrictsimiliar_contentsimstrict_-21600000', 'concept_type_accrate_4', 'question', 'kctype_max_accrate', 'uid_question_utilnow_1314000_desc', 'concept_mean_showcnt', 'kc_type_showcnt_2', 'acctop5max_similiar_strict_-21600000', 'kc_6', 'kc_showcnt_4', 'kctype_min_accrate', 'uid_concept_utilnow_259200_desc', 'uid_question_utilnow_3600_asc', 'new_concept_days_min', 'concepttype_min_showcnt', 'question_accrate', 'uid_question_utilnow_3600_desc', 'time_weekday_accrate', 'kc_type_showcnt_1', 'uid_question_submittimes_1209600_desc', 'kctype_mean_accrate', 'uid_question_utilnow_21600_asc', 'concept_accrate_4', 'uid_question_utilnow_21600_desc', 'kc_max_accrate', 'kc_type_accrate_3', 'kc_type_showcnt_5', 'uid_question_submittimes_3600_asc', 'concept_min_showcnt', 'uid_concept_type_accrate_6', 'concept_type_showcnt_5', 'time_hour', 'cnt_accstrictsimiliar_31536000000', 'kc_type_accrate_8', 'uid_unique_submittimes_10800_desc', 'uid_concept_type_accrate_2', 'kc_type_accrate_1', 'uid_question_submittimes_21600_asc', 'kc_type_showcnt_8', 'cnt_finishsimiliar_contentsimstrict_31536000000', 'time_weekday_showcnt', 'concept_4', 'uid_concept_utilnow_1209600_desc', 'acctop5max_similiar_contentsim_-21600000', 'concept_type_showcnt_1', 'kc_4', 'time_year', 'uid_accrate', 'uid_question_submittimes_3600_desc', 'uidkc_mean_accrate', 'accrate_similiar_strict_contentsim_86400000', 'concept_cnt', 'uid_question_utilnow_31536000_asc', 'concept_showcnt_3', 'cnt_finishstrictsimiliar_-21600000', 'concepttype_max_showcnt', 'kc_accrate_2', 'uid_timedistance_to_last_submit_asc', 'uid_timestamp_showcnt', 'timestamp', 'concepttype_max_accrate', 'concept_type_accrate_3', 'accrate_similiar_strict_contentsimstrict_1209600000', 'uid_showcnt', 'kc_type_showcnt_3', 'uid_kc_accrate_1', 'concept_5', 'kc_max_showcnt', 'concept_type_showcnt_2', 'acctop5_finishstrictsimiliar_contentsimstrict_-1209600000']\n",
    "kf_and=['concepttype_max_accrate', 'concept_mean_showcnt', 'kc_5', 'concepttype_mean_showcnt', 'kctype_min_accrate', 'uid_question_utilnow_10800_desc', 'acctop5max_similiar_strict_-21600000', 'uid_question_submittimes_3600_desc', 'uid_question_utilnow_21600_desc', 'uid_concept_utilnow_1209600_asc', 'uid_question_utilnow_31536000_asc', 'uid_question_submittimes_21600_asc', 'kc_type_showcnt_1', 'cnt_finishsimiliar_contentsimstrict_31536000000', 'concepttype_max_showcnt', 'timestamp_question_cnt', 'kc_1', 'kctype_max_accrate', 'kc_showcnt_1', 'uid_kc_accrate_4', 'question_accrate', 'uid_unique_submittimes_10800_desc', 'kc_type_accrate_4', 'timediff1', 'accrate_similiar_strict_contentsim_86400000', 'concept_accrate_4', 'question_showcnt', 'uid_timedistance_to_last_submit_asc', 'kc_type_accrate_8', 'uid_concept_utilnow_31536000_asc', 'kc_type_showcnt_3', 'cnt_finishstrictsimiliar_-21600000', 'kc_mean_showcnt', 'acctop5max_similiar_contentsimstrict_-21600000', 'uid_new_concept_days_min', 'acctop5max_similiar_strict_contentsim_31536000000', 'kc_min_accrate', 'kctype_mean_showcnt', 'question', 'time_weekday_showcnt', 'uid_concept_accrate_4', 'uidkc_mean_accrate', 'cnt_accstrictsimiliar_31536000000', 'time_weekday_accrate', 'uid_concept_utilnow_259200_desc', 'uid_question_utilnow_259200_asc', 'acctop5_finishstrictsimiliar_contentsimstrict_-1209600000', 'concept_5', 'kc_accrate_2', 'accrate_similiar_86400000', 'type_accrate', 'uid_unique_submittimes_21600_asc', 'kctype_mean_accrate', 'analysis_cnt', 'kc_showcnt_6', 'acctop5max_similiar_strict_contentsim_86400000', 'cnt_accsimiliar_contentsimstrict_1209600000', 'uid_question_utilnow_21600_asc', 'cnt_finishstrictsimiliar_contentsimstrict_-21600000', 'concept_2', 'kc_accrate_4', 'cnt_accsimiliar_contentsim_1209600000', 'kc_type_showcnt_6', 'concepttype_min_accrate', 'kc_type_showcnt_5', 'acctop1_accstrictsimiliar_86400000', 'uid_question_utilnow_3600_desc', 'uid_question_utilnow_1209600_asc', 'kc_4', 'acctop5_finishsimiliar_contentsim_31536000000', 'kc_max_showcnt', 'acctop5_finishstrictsimiliar_contentsimstrict_-21600000', 'kc_6', 'uid_timedistance_to_last_submit_desc', 'concept_max_accrate', 'uid_accrate', 'kc_2', 'concept_type_accrate_4', 'uid_question_submittimes_1209600_desc', 'acctop1max_similiar_strict_-21600000', 'time_hour', 'acctop1max_similiar_strict_contentsimstrict_-21600000', 'concept_cnt', 'kc_max_accrate', 'concept_showcnt_3', 'uid_concept_utilnow_21600_desc', 'content_cnt', 'kc_type_accrate_3', 'uid_question_utilnow_1209600_desc', 'concept_type_accrate_3', 'timestamp', 'kc_type_accrate_7', 'kc_3', 'cnt_finishsimiliar_contentsimstrict_-21600000', 'new_question_days', 'acctop5_finishstrictsimiliar_contentsim_-21600000', 'acctop5_finishstrictsimiliar_-21600000', 'time_year', 'kc_cnt', 'uid_question_utilnow_1314000_desc', 'kc_type_showcnt_4', 'new_concept_days_min', 'uid_concept_utilnow_1209600_desc', 'uid_concept_type_accrate_2', 'acctop5max_similiar_strict_3600000', 'uid_kc_accrate_8', 'kctype_max_showcnt', 'acctop5_accsimiliar_contentsim_31536000000', 'uid_concept_type_accrate_6', 'accrate_similiar_contentsimstrict_3600000', 'kctype_min_showcnt', 'concept_hot_cnt', 'kc_accrate_5', 'acctop1_finishstrictsimiliar_contentsimstrict_3600000', 'uid_concept_type_accrate_4', 'concepttype_min_showcnt', 'acctop5max_similiar_contentsim_31536000000', 'concept_type_showcnt_5', 'concept_type_showcnt_1', 'uid_kc_accrate_2', 'kc_type_accrate_2', 'kc_showcnt_4', 'kc_type_showcnt_2', 'uidconcepttype_max_accrate', 'acctop5_finishsimiliar_contentsimstrict_86400000', 'kc_type_showcnt_8', 'concept_1', 'uid_question_utilnow_3600_asc', 'uid_unique_submittimes_21600_desc', 'uid_timestamp_question_meansubmit', 'kc_group_cnt', 'concept_4', 'acctop5max_similiar_-21600000', 'kc_type_accrate_1', 'concept_type_accrate_6', 'uid_timestamp_showcnt', 'uid_question_submittimes_3600_asc', 'kc_accrate_1']\n",
    "# 可能要用到的局部特征\n",
    "columns_sim_res = [[],[]]\n",
    "for col in kf_or:\n",
    "    if col not in df.columns:\n",
    "        if '00' in col:\n",
    "            columns_sim_res[1].append(col)\n",
    "        else:\n",
    "            columns_sim_res[0].append(col)\n",
    "columns_sim_res[0] = sorted(columns_sim_res[0])\n",
    "columns_sim_res[1] = sorted(columns_sim_res[1], key=lambda x:int(x.split('_')[-1]))\n",
    "columns_sim_set = set(['_'.join(x.split('_')[:-1]) for x in columns_sim_res[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T08:28:26.475428Z",
     "start_time": "2022-12-13T08:28:26.472800Z"
    }
   },
   "source": [
    "### 相似问题的历史特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T03:36:13.598816Z",
     "start_time": "2022-12-30T03:36:13.587103Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sim_metrix(df, df_test, df_val=None):\n",
    "    global question_interact_ok,question_interact,question_interact_true_ok,question_interact_true\n",
    "    global question_similiar_reverse,question_true_similiar_reverse,question_similiar_reverse_strict,question_true_similiar_reverse_strict\n",
    "    global question_info_sim,question_info_sim_strict\n",
    "    max_question_id = 7651\n",
    "        \n",
    "    useful_cols = ['response','question','uid']\n",
    "    if df_val is not None:\n",
    "        df_all_response = pd.concat([df[df['response']!=-1],df_test[df_test['response']!=-1],df_val[df_val['response']!=-1]], axis=0).reset_index(drop=True)\n",
    "    else:\n",
    "        df_all_response = pd.concat([df[df['response']!=-1],df_test[df_test['response']!=-1]], axis=0)\n",
    "\n",
    "    question_accrate = df_all_response.groupby('question')['response'].mean()\n",
    "    question_interact_ok = np.zeros([max_question_id+1, max_question_id+1])\n",
    "    question_interact = np.zeros([max_question_id+1, max_question_id+1])\n",
    "    question_interact_true_ok = np.zeros([max_question_id+1, max_question_id+1])\n",
    "    question_interact_true = np.zeros([max_question_id+1, max_question_id+1])\n",
    "    \n",
    "    last_uid = -1\n",
    "    finished_questions = []\n",
    "    true_questions = []\n",
    "    for idx, (uid, question, response) in df_all_response[['uid', 'question', 'response']].iterrows():\n",
    "        if uid != last_uid:\n",
    "            last_uid = uid\n",
    "            finished_questions = [question]\n",
    "            true_questions = [question] if response==1 else []\n",
    "            continue\n",
    "        #for i in finished_questions:\n",
    "        question_interact[finished_questions, question] += 1\n",
    "        #for i in true_questions:\n",
    "        question_interact_true[true_questions, question] += 1\n",
    "        if response == 1:\n",
    "            #for i in finished_questions:\n",
    "            question_interact_ok[finished_questions, question] += 1\n",
    "            #for i in true_questions:\n",
    "            question_interact_true_ok[true_questions, question] += 1\n",
    "            true_questions.append(question)\n",
    "        finished_questions.append(question)\n",
    "\n",
    "    # 相似题目(i->j), A-》B是否能做对；A做过之后，是否做了B\n",
    "    question_interact_accrate = question_interact_ok/(question_interact+0.00001)*(question_interact>20)\n",
    "    question_interact_true_accrate = question_interact_true_ok/(question_interact_true+0.00001)*(question_interact_true>20)\n",
    "    #question_similiar = [{j:acc for j, acc in enumerate(question_interact_accrate[i,:]) if acc>0.95 and (1-question_accrate[j])*0.5>(1-acc)} for i in range(len(question_interact_accrate))]\n",
    "    question_similiar_reverse = [{j:acc for j, acc in enumerate(question_interact_accrate[:,i]) if acc>0.95 and (1-question_accrate[i])*0.5>(1-acc)} for i in range(len(question_interact_accrate))]\n",
    "    #question_true_similiar = [{j:acc for j, acc in enumerate(question_interact_true_accrate[i,:]) if acc>0.95 and (1-question_accrate[j])*0.5>(1-acc)} for i in range(len(question_interact_true_accrate))]\n",
    "    question_true_similiar_reverse = [{j:acc for j, acc in enumerate(question_interact_true_accrate[:,i]) if acc>0.95 and (1-question_accrate[i])*0.5>(1-acc)} for i in range(len(question_interact_true_accrate))]\n",
    "    question_interact_accrate = question_interact_ok/(question_interact+0.00001)*(question_interact>40)\n",
    "    question_interact_true_accrate = question_interact_true_ok/(question_interact_true+0.00001)*(question_interact_true>40)\n",
    "    question_similiar_reverse_strict = [{j:acc for j, acc in enumerate(question_interact_accrate[:,i]) if acc>0.95 and (1-question_accrate[i])*0.25>(1-acc)} for i in range(len(question_interact_accrate))]\n",
    "    question_true_similiar_reverse_strict = [{j:acc for j, acc in enumerate(question_interact_true_accrate[:,i]) if acc>0.95 and (1-question_accrate[i])*0.25>(1-acc)} for i in range(len(question_interact_true_accrate))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T03:36:50.354258Z",
     "start_time": "2022-12-30T03:36:14.460584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.concat([df,df_test], axis=0)\n",
    "df_all_response = pd.concat([df,df_test[df_test['response']!=-1]], axis=0)\n",
    "\n",
    "question_info = pd.concat([df,df_test],axis=0).groupby('question')[['concept_1','concept_2','concept_3','concept_4','concept_5','concept_6']].max()\n",
    "question_accrate = pd.concat([df,df_test[df_test['response']!=-1]],axis=0).groupby('question')['response'].mean()\n",
    "\n",
    "question_info_dict = [set() for _ in range(7652)]\n",
    "for i, (c1,c2,c3,c4,c5,c6) in question_info.iterrows():\n",
    "    question_info_dict[i] = set([x for x in [c1,c2,c3,c4,c5,c6] if x != -1])\n",
    "question_info_sim = [set() for _ in range(7652)]\n",
    "question_info_sim_strict = [set() for _ in range(7652)]  # 目前要做j题，求j的相似，幂等\n",
    "for i in range(7652):\n",
    "    for j in range(i+1, 7652):\n",
    "        if question_info_dict[i] == question_info_dict[j]:\n",
    "            question_info_sim_strict[i].add(j)\n",
    "            question_info_sim_strict[j].add(i)\n",
    "        if question_info_dict[i] == question_info_dict[j] or ((len(question_info_dict[i])>1 or len(question_info_dict[j])>1) and len(question_info_dict[i]-question_info_dict[j])<=1 and len(question_info_dict[j]-question_info_dict[i])<=1):\n",
    "            question_info_sim[i].add(j)\n",
    "            question_info_sim[j].add(i)\n",
    "question_accrate = df_all_response.groupby('question')['response'].mean()\n",
    "question_interact_ok = np.zeros([df_all['question'].max()+1, df_all['question'].max()+1])\n",
    "question_interact = np.zeros([df_all['question'].max()+1, df_all['question'].max()+1])\n",
    "question_interact_true_ok = np.zeros([df_all['question'].max()+1, df_all['question'].max()+1])\n",
    "question_interact_true = np.zeros([df_all['question'].max()+1, df_all['question'].max()+1])\n",
    "\n",
    "del df_all,df_all_response #, question_accrate, question_interact_ok, question_interact, question_interact_true_ok, question_interact_true\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T15:14:40.416163Z",
     "start_time": "2022-12-19T14:42:57.184928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4997233it [30:52, 2697.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 注意去除value_counts 特别小的question，太抖\n",
    "df_all_response = pd.concat([df,df_test[df_test['response']!=-1]], axis=0)\n",
    "question_accrate = df_all_response.groupby('question')['response'].mean()\n",
    "\n",
    "last_uid = -1\n",
    "finished_questions = []\n",
    "true_questions = []\n",
    "for idx, (uid, question, response) in tqdm(df_all_response[['uid', 'question', 'response']].iterrows()):\n",
    "    if uid != last_uid:\n",
    "        last_uid = uid\n",
    "        finished_questions = [question]\n",
    "        true_questions = [question] if response==1 else []\n",
    "        continue\n",
    "    #for i in finished_questions:\n",
    "    question_interact[finished_questions, question] += 1\n",
    "    #for i in true_questions:\n",
    "    question_interact_true[true_questions, question] += 1\n",
    "    if response == 1:\n",
    "        #for i in finished_questions:\n",
    "        question_interact_ok[finished_questions, question] += 1\n",
    "        #for i in true_questions:\n",
    "        question_interact_true_ok[true_questions, question] += 1\n",
    "        true_questions.append(question)\n",
    "    finished_questions.append(question)\n",
    "   \n",
    "# 相似题目(i->j)\n",
    "question_interact_accrate = question_interact_ok/(question_interact+0.00001)*(question_interact>20)\n",
    "question_interact_true_accrate = question_interact_true_ok/(question_interact_true+0.00001)*(question_interact_true>20)\n",
    "#question_similiar = [{j:acc for j, acc in enumerate(question_interact_accrate[i,:]) if acc>0.95 and (1-question_accrate[j])*0.5>(1-acc)} for i in range(len(question_interact_accrate))]\n",
    "question_similiar_reverse = [{j:acc for j, acc in enumerate(question_interact_accrate[:,i]) if acc>0.95 and (1-question_accrate[i])*0.5>(1-acc)} for i in range(len(question_interact_accrate))]\n",
    "#question_true_similiar = [{j:acc for j, acc in enumerate(question_interact_true_accrate[i,:]) if acc>0.95 and (1-question_accrate[j])*0.5>(1-acc)} for i in range(len(question_interact_true_accrate))]\n",
    "question_true_similiar_reverse = [{j:acc for j, acc in enumerate(question_interact_true_accrate[:,i]) if acc>0.95 and (1-question_accrate[i])*0.5>(1-acc)} for i in range(len(question_interact_true_accrate))]\n",
    "question_interact_accrate = question_interact_ok/(question_interact+0.00001)*(question_interact>40)\n",
    "question_interact_true_accrate = question_interact_true_ok/(question_interact_true+0.00001)*(question_interact_true>40)\n",
    "question_similiar_reverse_strict = [{j:acc for j, acc in enumerate(question_interact_accrate[:,i]) if acc>0.95 and (1-question_accrate[i])*0.25>(1-acc)} for i in range(len(question_interact_accrate))]\n",
    "question_true_similiar_reverse_strict = [{j:acc for j, acc in enumerate(question_interact_true_accrate[:,i]) if acc>0.95 and (1-question_accrate[i])*0.25>(1-acc)} for i in range(len(question_interact_true_accrate))]\n",
    "\n",
    "del df_all_response #, question_accrate, question_interact_ok, question_interact, question_interact_true_ok, question_interact_true\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T08:11:54.371787Z",
     "start_time": "2022-12-20T08:11:54.368519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pickle\\nwith open('./input/question_similiar2.pickle','wb+') as f:\\n    tmp = {\\n        'question_similiar_reverse':question_similiar_reverse,\\n        'question_true_similiar_reverse':question_true_similiar_reverse,\\n        'question_similiar_reverse_strict':question_similiar_reverse_strict,\\n        'question_true_similiar_reverse_strict':question_true_similiar_reverse_strict\\n    }\\n    pickle.dump(tmp, f)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pickle\n",
    "with open('./input/question_similiar2.pickle','wb+') as f:\n",
    "    tmp = {\n",
    "        'question_similiar_reverse':question_similiar_reverse,\n",
    "        'question_true_similiar_reverse':question_true_similiar_reverse,\n",
    "        'question_similiar_reverse_strict':question_similiar_reverse_strict,\n",
    "        'question_true_similiar_reverse_strict':question_true_similiar_reverse_strict\n",
    "    }\n",
    "    pickle.dump(tmp, f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T08:11:54.554363Z",
     "start_time": "2022-12-20T08:11:54.373274Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('./input/question_similiar2.pickle','rb') as f:\n",
    "#     tmp = pickle.load(f)\n",
    "# question_similiar_reverse = tmp['question_similiar_reverse']\n",
    "# question_true_similiar_reverse = tmp['question_true_similiar_reverse']\n",
    "# question_similiar_reverse_strict = tmp['question_similiar_reverse_strict']\n",
    "# question_true_similiar_reverse_strict = tmp['question_true_similiar_reverse_strict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 局部特征-sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T03:36:50.490318Z",
     "start_time": "2022-12-30T03:36:50.356724Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_tmp,df_tmp2, df_tmp3, columns_tmp = feature_engineering2(df.iloc[:3000].copy(), df_test.iloc[:3000].copy(), df_val=df.iloc[3000:6000].copy(), \\n                                         tr_data_enhance=2, val_data_enhance=1)\\nprint(columns_tmp)\\ndf_tmp\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将测试集的已有信息也放进来（特征工程和训练集）\n",
    "useful_features_dtypes = {'uid': np.dtype('int16'), 'question': np.dtype('int16'), 'response': np.dtype('int8'), 'timestamp': np.dtype('int64'), 'type': np.dtype('int8'), 'concept_cnt': np.dtype('int8'), 'concept_hot_cnt': np.dtype('int8'), 'concept_1': np.dtype('int16'), 'concept_2': np.dtype('int16'), 'concept_3': np.dtype('int16'), 'concept_4': np.dtype('int16'), 'concept_5': np.dtype('int16'), 'concept_6': np.dtype('int16'), 'content_cnt': np.dtype('int16'), 'kc_group_cnt': np.dtype('int8'), 'kc_cnt': np.dtype('int8'), 'kc_1': np.dtype('int16'), 'kc_2': np.dtype('int16'), 'kc_3': np.dtype('int16'), 'kc_4': np.dtype('int16'), 'kc_5': np.dtype('int16'), 'kc_6': np.dtype('int16'), 'kc_7': np.dtype('int16'), 'kc_8': np.dtype('int8'), 'analysis_cnt': np.dtype('int16'), 'time_day': np.dtype('int16'), 'time_hour': np.dtype('int8'), 'time_is_workday': np.dtype('int8'), 'time_weekday': np.dtype('int8'), 'time_year': np.dtype('int16'), 'data_type': np.dtype('O'), 'uid_record_cumsum': np.dtype('int16'), 'uid_record_sum': np.dtype('int16'), 'concept_showcnt_1': np.dtype('int32'), 'concept_accrate_1': np.dtype('float32'), 'concept_showcnt_2': np.dtype('int32'), 'concept_accrate_2': np.dtype('float32'), 'concept_showcnt_3': np.dtype('int32'), 'concept_accrate_3': np.dtype('float32'), 'concept_showcnt_4': np.dtype('int16'), 'concept_accrate_4': np.dtype('float32'), 'concept_showcnt_5': np.dtype('int16'), 'concept_accrate_5': np.dtype('float32'), 'concept_showcnt_6': np.dtype('int16'), 'concept_accrate_6': np.dtype('float32'), 'concept_type_showcnt_1': np.dtype('int32'), 'concept_type_accrate_1': np.dtype('float32'), 'concept_type_showcnt_2': np.dtype('int32'), 'concept_type_accrate_2': np.dtype('float32'), 'concept_type_showcnt_3': np.dtype('int16'), 'concept_type_accrate_3': np.dtype('float32'), 'concept_type_showcnt_4': np.dtype('int16'), 'concept_type_accrate_4': np.dtype('float32'), 'concept_type_showcnt_5': np.dtype('int16'), 'concept_type_accrate_5': np.dtype('float32'), 'concept_type_showcnt_6': np.dtype('int16'), 'concept_type_accrate_6': np.dtype('float32'), 'concept_min_accrate': np.dtype('float32'), 'concept_mean_accrate': np.dtype('float32'), 'concept_max_accrate': np.dtype('float32'), 'concept_min_showcnt': np.dtype('int32'), 'concept_mean_showcnt': np.dtype('float32'), 'concept_max_showcnt': np.dtype('int32'), 'concepttype_min_accrate': np.dtype('float32'), 'concepttype_mean_accrate': np.dtype('float32'), 'concepttype_max_accrate': np.dtype('float32'), 'concepttype_min_showcnt': np.dtype('int32'), 'concepttype_mean_showcnt': np.dtype('float32'), 'concepttype_max_showcnt': np.dtype('int32'), 'kc_showcnt_1': np.dtype('int32'), 'kc_accrate_1': np.dtype('float32'), 'kc_showcnt_2': np.dtype('int32'), 'kc_accrate_2': np.dtype('float32'), 'kc_showcnt_3': np.dtype('int32'), 'kc_accrate_3': np.dtype('float32'), 'kc_showcnt_4': np.dtype('int32'), 'kc_accrate_4': np.dtype('float32'), 'kc_showcnt_5': np.dtype('int32'), 'kc_accrate_5': np.dtype('float32'), 'kc_showcnt_6': np.dtype('int32'), 'kc_accrate_6': np.dtype('float32'), 'kc_showcnt_7': np.dtype('int32'), 'kc_accrate_7': np.dtype('float32'), 'kc_showcnt_8': np.dtype('int32'), 'kc_accrate_8': np.dtype('float32'), 'kc_type_showcnt_1': np.dtype('int32'), 'kc_type_accrate_1': np.dtype('float32'), 'kc_type_showcnt_2': np.dtype('int32'), 'kc_type_accrate_2': np.dtype('float32'), 'kc_type_showcnt_3': np.dtype('int32'), 'kc_type_accrate_3': np.dtype('float32'), 'kc_type_showcnt_4': np.dtype('int32'), 'kc_type_accrate_4': np.dtype('float32'), 'kc_type_showcnt_5': np.dtype('int32'), 'kc_type_accrate_5': np.dtype('float32'), 'kc_type_showcnt_6': np.dtype('int32'), 'kc_type_accrate_6': np.dtype('float32'), 'kc_type_showcnt_7': np.dtype('int32'), 'kc_type_accrate_7': np.dtype('float32'), 'kc_type_showcnt_8': np.dtype('int32'), 'kc_type_accrate_8': np.dtype('float32'), 'kc_min_accrate': np.dtype('float32'), 'kc_mean_accrate': np.dtype('float32'), 'kc_max_accrate': np.dtype('float32'), 'kc_min_showcnt': np.dtype('int32'), 'kc_mean_showcnt': np.dtype('float32'), 'kc_max_showcnt': np.dtype('int32'), 'kctype_min_accrate': np.dtype('float32'), 'kctype_mean_accrate': np.dtype('float32'), 'kctype_max_accrate': np.dtype('float32'), 'kctype_min_showcnt': np.dtype('int32'), 'kctype_mean_showcnt': np.dtype('float32'), 'kctype_max_showcnt': np.dtype('int32'), 'question_showcnt': np.dtype('int16'), 'question_accrate': np.dtype('float32'), 'type_showcnt': np.dtype('int32'), 'type_accrate': np.dtype('float32'), 'time_hour_showcnt': np.dtype('int32'), 'time_hour_accrate': np.dtype('float32'), 'time_is_workday_showcnt': np.dtype('int32'), 'time_is_workday_accrate': np.dtype('float32'), 'time_weekday_showcnt': np.dtype('int32'), 'time_weekday_accrate': np.dtype('float32'), 'timestamp_question_cnt': np.dtype('int16'), 'timestamp_question_accrate': np.dtype('float32'), 'question_showcnt_without_timestamp_question': np.dtype('int16'), 'question_accrate_without_timestamp_question': np.dtype('float32'), 'uid_question_utilnow_3600_asc': np.dtype('int8'), 'uid_question_submittimes_3600_asc': np.dtype('int16'), 'uid_unique_submittimes_3600_asc': np.dtype('int8'), 'uid_timedistance_to_last_submit_asc': np.dtype('int32'), 'uid_timestamp_question_submit': np.dtype('int8'), 'uid_question_utilnow_21600_asc': np.dtype('int8'), 'uid_question_submittimes_21600_asc': np.dtype('int16'), 'uid_unique_submittimes_21600_asc': np.dtype('int8'), 'uid_question_utilnow_94608000_asc': np.dtype('int8'), 'uid_question_submittimes_94608000_asc': np.dtype('int16'), 'uid_unique_submittimes_94608000_asc': np.dtype('int16'), 'uid_question_utilnow_94608000_desc': np.dtype('int8'), 'uid_question_submittimes_94608000_desc': np.dtype('int16'), 'uid_unique_submittimes_94608000_desc': np.dtype('int16'), 'uid_timedistance_to_last_submit_desc': np.dtype('int32'), 'uid_kc_utilnow_3600_asc': np.dtype('int16'), 'uid_kc_utilnow_21600_asc': np.dtype('int16'), 'uid_kc_utilnow_94608000_asc': np.dtype('int16'), 'uid_kc_utilnow_94608000_desc': np.dtype('int16'), 'new_kc_days_min': np.dtype('float32'), 'uid_new_kc_days_min': np.dtype('float32'), 'uid_concept_utilnow_3600_asc': np.dtype('int8'), 'uid_concept_utilnow_21600_asc': np.dtype('int8'), 'uid_concept_utilnow_94608000_asc': np.dtype('int8'), 'uid_concept_utilnow_94608000_desc': np.dtype('int8'), 'new_concept_days_min': np.dtype('float32'), 'uid_new_concept_days_min': np.dtype('float32'), 'uid_timestamp_question_meansubmit': np.dtype('float32'), 'uid_timestamp_showcnt': np.dtype('int8'), 'new_question_days': np.dtype('float32'), 'uid_new_question_days': np.dtype('float32'), 'real_response': np.dtype('int8'), 'is_enhance': np.dtype('int8'), 'uid_showcnt': np.dtype('int16'), 'uid_accrate': np.dtype('float32'), 'uid_question_accrate': np.dtype('float32'), 'uid_concept_accrate_1': np.dtype('float32'), 'uid_concept_accrate_2': np.dtype('float32'), 'uid_concept_accrate_3': np.dtype('float32'), 'uid_concept_accrate_4': np.dtype('float32'), 'uid_concept_accrate_5': np.dtype('float32'), 'uid_concept_accrate_6': np.dtype('float32'), 'uid_concept_type_accrate_1': np.dtype('float32'), 'uid_concept_type_accrate_2': np.dtype('float32'), 'uid_concept_type_accrate_3': np.dtype('float32'), 'uid_concept_type_accrate_4': np.dtype('float32'), 'uid_concept_type_accrate_5': np.dtype('float32'), 'uid_concept_type_accrate_6': np.dtype('int8'), 'uidconcept_min_accrate': np.dtype('float32'), 'uidconcept_mean_accrate': np.dtype('float32'), 'uidconcept_max_accrate': np.dtype('float32'), 'uidconcepttype_min_accrate': np.dtype('float32'), 'uidconcepttype_mean_accrate': np.dtype('float32'), 'uidconcepttype_max_accrate': np.dtype('float32'), 'uid_kc_accrate_1': np.dtype('float32'), 'uid_kc_accrate_2': np.dtype('float32'), 'uid_kc_accrate_3': np.dtype('float32'), 'uid_kc_accrate_4': np.dtype('float32'), 'uid_kc_accrate_5': np.dtype('float32'), 'uid_kc_accrate_6': np.dtype('float32'), 'uid_kc_accrate_7': np.dtype('float32'), 'uid_kc_accrate_8': np.dtype('float32'), 'uid_kc_type_accrate_1': np.dtype('float32'), 'uid_kc_type_accrate_2': np.dtype('float32'), 'uid_kc_type_accrate_3': np.dtype('float32'), 'uid_kc_type_accrate_4': np.dtype('float32'), 'uid_kc_type_accrate_5': np.dtype('float32'), 'uid_kc_type_accrate_6': np.dtype('float32'), 'uid_kc_type_accrate_7': np.dtype('float32'), 'uid_kc_type_accrate_8': np.dtype('float32'), 'uidkc_min_accrate': np.dtype('float32'), 'uidkc_mean_accrate': np.dtype('float32'), 'uidkc_max_accrate': np.dtype('float32'), 'uidkctype_min_accrate': np.dtype('float32'), 'uidkctype_mean_accrate': np.dtype('float32'), 'uidkctype_max_accrate': np.dtype('float32'), 'hours_to_half_split_timestamp': np.dtype('int32'), 'records_to_half_split_uid_record_cumsum': np.dtype('int16'), 'cnt_finishsimiliar': np.dtype('float32'), 'acctop5_finishsimiliar': np.dtype('float32'), 'acctop1_finishsimiliar': np.dtype('float32'), 'cnt_accsimiliar': np.dtype('float32'), 'acctop5_accsimiliar': np.dtype('float32'), 'acctop1_accsimiliar': np.dtype('float32'), 'cnt_finishstrictsimiliar': np.dtype('float32'), 'acctop5_finishstrictsimiliar': np.dtype('float32'), 'acctop1_finishstrictsimiliar': np.dtype('float32'), 'cnt_accstrictsimiliar': np.dtype('float32'), 'acctop5_accstrictsimiliar': np.dtype('float32'), 'acctop1_accstrictsimiliar': np.dtype('float32'), 'accrate_similiar': np.dtype('float32'), 'accrate_similiar_strict': np.dtype('float32'), 'acctop5max_similiar': np.dtype('float32'), 'acctop1max_similiar': np.dtype('float32'), 'acctop5max_similiar_strict': np.dtype('float32'), 'acctop1max_similiar_strict': np.dtype('float32')}\n",
    "\n",
    "useful_features = ['uid_concept_utilnow_94608000_desc', 'time_hour_accrate', 'concepttype_mean_showcnt', 'time_weekday', \n",
    "'uid_timestamp_showcnt', 'concept_min_accrate', 'uid_accrate', 'question_accrate', 'kc_showcnt_4', \n",
    "'question_showcnt', 'uid_concept_utilnow_3600_asc', 'concept_max_accrate', 'kc_type_showcnt_1', 'kc_3', \n",
    "'concept_type_accrate_1', 'uid_showcnt', 'time_day', 'question', 'timestamp_question_cnt', 'concept_mean_accrate', \n",
    "'uid_concept_utilnow_21600_asc', 'uid_concept_accrate_4', 'kc_2', 'uidconcepttype_max_accrate', 'type_accrate', \n",
    "'analysis_cnt', 'kc_max_accrate', 'concept_min_showcnt', 'uidkc_mean_accrate'] + \\\n",
    "    ['uid_accrate', 'question_accrate', 'timestamp_question_cnt', 'question', 'timestamp', 'time_day', \n",
    " 'uid_new_question_days', 'uid_kc_utilnow_3600_asc', 'uid_timestamp_showcnt', 'uid_concept_utilnow_21600_asc', \n",
    " 'analysis_cnt', 'new_concept_days_min', 'concepttype_min_accrate', 'concept_mean_accrate', 'question_showcnt', \n",
    " 'time_hour_accrate', 'uidkctype_min_accrate', 'uid_concept_accrate_5'] + \\\n",
    "    ['uid','question','timestamp' ,'response','real_response','is_enhance'] + \\\n",
    "    ['cnt_finishsimiliar', 'acctop5_finishsimiliar',\n",
    "       'acctop1_finishsimiliar', 'cnt_accsimiliar', 'acctop5_accsimiliar',\n",
    "       'acctop1_accsimiliar', 'cnt_finishstrictsimiliar',\n",
    "       'acctop5_finishstrictsimiliar', 'acctop1_finishstrictsimiliar',\n",
    "       'cnt_accstrictsimiliar', 'acctop5_accstrictsimiliar',\n",
    "       'acctop1_accstrictsimiliar', 'accrate_similiar',\n",
    "       'accrate_similiar_strict', 'acctop5max_similiar',\n",
    "       'acctop1max_similiar', 'acctop5max_similiar_strict',\n",
    "       'acctop1max_similiar_strict']\n",
    "useful_features = list(set(useful_features))\n",
    "\n",
    "def feature_engineering2(df_tr, df_test, df_val=None, tr_data_enhance=1, val_data_enhance=1, seed=1, save_files=None):\n",
    "    # 不同统计方式得到的特征，用于不同类型的模型\n",
    "    columns = {\n",
    "        'at':[], # 可以直接使用的特征\n",
    "        'bs':[], # 统计这次提交以前的label\n",
    "        'bt':[], # 统计今天以前的label\n",
    "        'bh':[]  # 只使用一半的label进行统计\n",
    "    }\n",
    "    gc.collect()\n",
    "    \n",
    "    # 开始统计每个人的个人信息（数据增强）,append_columns:是否把列名加入columns字典\n",
    "    def calc_uid_features(df, append_columns=False, data_type='tr'):\n",
    "        \n",
    "        df_response = df[df['response']!=-1]\n",
    "        \n",
    "        if data_type in ('tr','val'):\n",
    "            col = 'uid'\n",
    "            df = df.drop([col+'_showcnt',col+'_accrate'], axis=1)\n",
    "            tmp = df_response.groupby(col)['response'].agg(['count','mean']).rename(columns={'count':col+'_showcnt', 'mean':col+'_accrate'})\n",
    "            df=df.merge(tmp, how='left', left_on=col, right_index=True, suffixes=(None,'_1'))\n",
    "            columns['bh'].extend([col+'_showcnt',col+'_accrate'])\n",
    "            \n",
    "                \n",
    "        #\"\"\" 不work\n",
    "        # concept : df_response 的累计正确率\n",
    "        col = 'uid'\n",
    "        df_tmp = pd.concat([\n",
    "            df_response.loc[df_response['concept_1']!=-1,['uid','response','concept_1','type']].rename(columns={'concept_1':'concept'}),\n",
    "            df_response.loc[df_response['concept_2']!=-1,['uid','response','concept_2','type']].rename(columns={'concept_2':'concept'}),\n",
    "            df_response.loc[df_response['concept_3']!=-1,['uid','response','concept_3','type']].rename(columns={'concept_3':'concept'}),\n",
    "            df_response.loc[df_response['concept_4']!=-1,['uid','response','concept_4','type']].rename(columns={'concept_4':'concept'}),\n",
    "            df_response.loc[df_response['concept_5']!=-1,['uid','response','concept_5','type']].rename(columns={'concept_5':'concept'}),\n",
    "            df_response.loc[df_response['concept_6']!=-1,['uid','response','concept_6','type']].rename(columns={'concept_6':'concept'}),\n",
    "        ])\n",
    "        col2 = 'concept'\n",
    "        tmp = df_tmp.groupby([col, col2])['response'].agg('mean').rename(col+'_'+col2+'_accrate')\n",
    "        df=df.merge(tmp, how='left', left_on=[col,col2+'_4'], right_index=True, suffixes=(None,'_4')).\\\n",
    "                merge(tmp, how='left', left_on=[col,col2+'_5'], right_index=True, suffixes=(None,'_5')).\\\n",
    "                rename(columns={col+'_'+col2+'_accrate':col+'_'+col2+'_accrate'+'_4'}).fillna(-1)\n",
    "        col3 = 'type'  # {'count':len,'mean':np.mean}\n",
    "        tmp = df_tmp.groupby([col,col2,col3])['response'].agg('mean').rename(col+'_'+col2+'_'+col3+'_accrate')\n",
    "        df=df.merge(tmp, how='left', left_on=[col,col2+'_1',col3], right_index=True, suffixes=(None,'_1'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_2',col3], right_index=True, suffixes=(None,'_2'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_3',col3], right_index=True, suffixes=(None,'_3'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_4',col3], right_index=True, suffixes=(None,'_4'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_5',col3], right_index=True, suffixes=(None,'_5'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_6',col3], right_index=True, suffixes=(None,'_6'))\\\n",
    "            .rename(columns={col+'_'+col2+'_'+col3+'_accrate':col+'_'+col2+'_'+col3+'_accrate'+'_1'}).fillna(-1)\n",
    "        for i in range(1,7):\n",
    "            columns['bh'].extend([col+'_'+col2+'_'+col3+'_accrate_'+str(i),col+'_'+col2+'_accrate_'+str(i)])\n",
    "        df[col+col2+col3+'_max_accrate'] = df[['uid_concept_type_accrate_1','uid_concept_type_accrate_2','uid_concept_type_accrate_3','uid_concept_type_accrate_4','uid_concept_type_accrate_5','uid_concept_type_accrate_6']].parallel_apply(lambda x: max([xx if xx!=-1 else -9 for xx in x]), axis=1)\n",
    "        columns['at'].extend([col+col2+col3+'_max_accrate'])\n",
    "        \n",
    "    \n",
    "        # kc : df_response 的累计正确率\n",
    "        df_tmp = pd.concat([\n",
    "            df_response.loc[df_response['kc_1']!=-1,['uid','response','kc_1','timestamp','type']].rename(columns={'kc_1':'kc'}),\n",
    "            df_response.loc[df_response['kc_2']!=-1,['uid','response','kc_2','timestamp','type']].rename(columns={'kc_2':'kc'}),\n",
    "            df_response.loc[df_response['kc_3']!=-1,['uid','response','kc_3','timestamp','type']].rename(columns={'kc_3':'kc'}),\n",
    "            df_response.loc[df_response['kc_4']!=-1,['uid','response','kc_4','timestamp','type']].rename(columns={'kc_4':'kc'}),\n",
    "            df_response.loc[df_response['kc_5']!=-1,['uid','response','kc_5','timestamp','type']].rename(columns={'kc_5':'kc'}),\n",
    "            df_response.loc[df_response['kc_6']!=-1,['uid','response','kc_6','timestamp','type']].rename(columns={'kc_6':'kc'}),\n",
    "            df_response.loc[df_response['kc_7']!=-1,['uid','response','kc_7','timestamp','type']].rename(columns={'kc_7':'kc'}),\n",
    "            df_response.loc[df_response['kc_8']!=-1,['uid','response','kc_8','timestamp','type']].rename(columns={'kc_8':'kc'}),\n",
    "        ])\n",
    "        gc.collect()\n",
    "        col2 = 'kc'\n",
    "        tmp = df_tmp.groupby([col, col2])['response'].agg('mean').rename(col+'_'+col2+'_accrate')\n",
    "        df=df.merge(tmp, how='left', left_on=[col,col2+'_1'], right_index=True, suffixes=(None,'_1'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_2'], right_index=True, suffixes=(None,'_2'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_3'], right_index=True, suffixes=(None,'_3'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_4'], right_index=True, suffixes=(None,'_4'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_5'], right_index=True, suffixes=(None,'_5'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_6'], right_index=True, suffixes=(None,'_6'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_7'], right_index=True, suffixes=(None,'_7'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_8'], right_index=True, suffixes=(None,'_8'))\\\n",
    "            .rename(columns={col+'_'+col2+'_accrate':col+'_'+col2+'_accrate'+'_1'})\n",
    "        for i in range(1,9):\n",
    "            columns['bh'].extend([col+'_'+col2+'_'+col3+'_accrate_'+str(i), col+'_'+col2+'_accrate_'+str(i)])\n",
    "        df[col+col2+'_mean_accrate'] = df[['uid_kc_accrate_1','uid_kc_accrate_2','uid_kc_accrate_3','uid_kc_accrate_4','uid_kc_accrate_5','uid_kc_accrate_6','uid_kc_accrate_7','uid_kc_accrate_8']].parallel_apply(lambda x: sum([xx for xx in x if xx!=-1])/(len([xx for xx in x if xx!=-1])+0.0001), axis=1)\n",
    "        columns['at'].extend([col+col2+'_min_accrate',col+col2+'_mean_accrate',col+col2+'_max_accrate'])\n",
    "        \n",
    "        del df_tmp\n",
    "        gc.collect()\n",
    "        \n",
    "        # 找到相似题目，映射到原特征中，计算相似题目做过/会做多少；top1、top3 accrate\n",
    "        def tmp_func(df, timelimit_value=3600000, columns_need_set=None):\n",
    "            if timelimit_value<0:\n",
    "                idx_raw = df.index\n",
    "                df = df.iloc[::-1].reset_index(drop=True)\n",
    "            timelimit = str(timelimit_value)\n",
    "            from collections import defaultdict\n",
    "            global question_interact_ok,question_interact,question_interact_true_ok,question_interact_true\n",
    "            global question_similiar_reverse,question_true_similiar_reverse,question_similiar_reverse_strict,question_true_similiar_reverse_strict\n",
    "            global question_info_sim,question_info_sim_strict\n",
    "            finished_questions = defaultdict(int)\n",
    "            true_questions = defaultdict(int)\n",
    "            start = -1\n",
    "            res = {}\n",
    "            # 注册要使用的列名\n",
    "            res['accrate_similiar_strict'] = []\n",
    "            for similiar_name in ('finishsimiliar','accsimiliar','finishstrictsimiliar','accstrictsimiliar'):\n",
    "                res['cnt_'+similiar_name] = []\n",
    "                res['acctop5_'+similiar_name] = []\n",
    "                res['acctop1_'+similiar_name] = []\n",
    "                for contentsim_name, contentsim in (('contentsim',question_info_sim),('contentsimstrict',question_info_sim_strict)):\n",
    "                    res['cnt_'+similiar_name+'_'+contentsim_name] = []\n",
    "                    res['acctop5_'+similiar_name+'_'+contentsim_name] = []\n",
    "                    res['acctop1_'+similiar_name+'_'+contentsim_name] = []\n",
    "\n",
    "            for idx, (question, response, timestamp) in df[['question', 'response', 'timestamp']].iterrows():\n",
    "                # 超时的数据排除出去\n",
    "                if start == -1:\n",
    "                    start = 0 if timelimit_value>0 else len(df)-1\n",
    "                else:\n",
    "                    while (timelimit_value>0 and timestamp - df['timestamp'].iloc[start] > timelimit_value) or (timelimit_value<0 and df['timestamp'].iloc[start]-timestamp > -timelimit_value):\n",
    "                        if df['response'].iloc[start] == 1:\n",
    "                            true_questions[df['question'].iloc[start]] -= 1\n",
    "                        finished_questions[df['question'].iloc[start]] -= 1\n",
    "                        start += (1 if timelimit_value>0 else -1)\n",
    "\n",
    "                cols_here = ['cnt_finishsimiliar','acctop5_finishsimiliar','acctop1_finishsimiliar','acctop1max_similiar','acctop5max_similiar_strict','accrate_similiar','acctop5max_similiar']\n",
    "                if columns_need_set is None or np.sum([1 if x in columns_need_set else 0 for x in cols_here])>0:\n",
    "                    question_similiar_list = sorted([acc for i,acc in question_similiar_reverse[question].items() for _ in range(finished_questions[i])], reverse=True)\n",
    "                    res['cnt_finishsimiliar'].append(len(question_similiar_list))\n",
    "                    res['acctop5_finishsimiliar'].append(sum(question_similiar_list[:5])/(len(question_similiar_list[:5])+0.000001))\n",
    "                    res['acctop1_finishsimiliar'].append(sum(question_similiar_list[:1])/(len(question_similiar_list[:1])+0.000001))\n",
    "                \n",
    "                cols_here = ['cnt_accsimiliar','acctop5_accsimiliar','acctop1_accsimiliar','accrate_similiar','acctop5max_similiar','acctop1max_similiar','acctop5max_similiar_strict']\n",
    "                if columns_need_set is None or np.sum([1 if x in columns_need_set else 0 for x in cols_here])>0:\n",
    "                    question_true_similiar_list = sorted([acc for i,acc in question_true_similiar_reverse[question].items() for _ in range(true_questions[i])], reverse=True)\n",
    "                    res['cnt_accsimiliar'].append(len(question_true_similiar_list))\n",
    "                    res['acctop5_accsimiliar'].append(sum(question_true_similiar_list[:5])/(len(question_true_similiar_list[:5])+0.000001))\n",
    "                    res['acctop1_accsimiliar'].append(sum(question_true_similiar_list[:1])/(len(question_true_similiar_list[:1])+0.000001))\n",
    "                \n",
    "                cols_here = ['cnt_finishstrictsimiliar','acctop5_finishstrictsimiliar','acctop1_finishstrictsimiliar',\n",
    "                             'accrate_similiar_strict','acctop1max_similiar_strict']\n",
    "                if columns_need_set is None or np.sum([1 if x in columns_need_set else 0 for x in cols_here])>0:\n",
    "                    question_similiar_strict_list = sorted([acc for i,acc in question_similiar_reverse_strict[question].items() for _ in range(finished_questions[i])], reverse=True)\n",
    "                    res['cnt_finishstrictsimiliar'].append(len(question_similiar_strict_list))\n",
    "                    res['acctop5_finishstrictsimiliar'].append(sum(question_similiar_strict_list[:5])/(len(question_similiar_strict_list[:5])+0.000001))\n",
    "                    res['acctop1_finishstrictsimiliar'].append(sum(question_similiar_strict_list[:1])/(len(question_similiar_strict_list[:1])+0.000001))\n",
    "                \n",
    "                cols_here = ['cnt_accstrictsimiliar','acctop5_accstrictsimiliar','acctop1_accstrictsimiliar',\n",
    "                             'accrate_similiar_strict','acctop1max_similiar_strict']\n",
    "                if columns_need_set is None or np.sum([1 if x in columns_need_set else 0 for x in cols_here])>0:\n",
    "                    question_true_similiar_strict_list = sorted([acc for i,acc in question_true_similiar_reverse_strict[question].items() for _ in range(true_questions[i])], reverse=True)\n",
    "                    res['cnt_accstrictsimiliar'].append(len(question_true_similiar_strict_list))\n",
    "                    res['acctop5_accstrictsimiliar'].append(sum(question_true_similiar_strict_list[:5])/(len(question_true_similiar_strict_list[:5])+0.000001))\n",
    "                    res['acctop1_accstrictsimiliar'].append(sum(question_true_similiar_strict_list[:1])/(len(question_true_similiar_strict_list[:1])+0.000001))\n",
    "\n",
    "                for contentsim_name, contentsim in (('contentsim',question_info_sim),('contentsimstrict',question_info_sim_strict)):\n",
    "                    cols_here = ['cnt_finishsimiliar'+'_'+contentsim_name,'acctop5_finishsimiliar'+'_'+contentsim_name,'acctop1_finishsimiliar'+'_'+contentsim_name,\n",
    "                                 'acctop1max_similiar'+'_'+contentsim_name,'acctop5max_similiar_strict'+'_'+contentsim_name,'accrate_similiar'+'_'+contentsim_name,'acctop5max_similiar'+'_'+contentsim_name]\n",
    "                    if columns_need_set is None or np.sum([1 if x in columns_need_set else 0 for x in cols_here])>0:\n",
    "                        question_similiar_list = sorted([acc for i,acc in question_similiar_reverse[question].items() if i in contentsim[question] for _ in range(finished_questions[i])], reverse=True)\n",
    "                        res['cnt_finishsimiliar'+'_'+contentsim_name].append(len(question_similiar_list))\n",
    "                        res['acctop5_finishsimiliar'+'_'+contentsim_name].append(sum(question_similiar_list[:5])/(len(question_similiar_list[:5])+0.000001))\n",
    "                        res['acctop1_finishsimiliar'+'_'+contentsim_name].append(sum(question_similiar_list[:1])/(len(question_similiar_list[:1])+0.000001))\n",
    "\n",
    "                    cols_here = ['cnt_accsimiliar'+'_'+contentsim_name,'acctop5_accsimiliar'+'_'+contentsim_name,'acctop1_accsimiliar'+'_'+contentsim_name,\n",
    "                                 'accrate_similiar'+'_'+contentsim_name,'acctop5max_similiar'+'_'+contentsim_name,'acctop1max_similiar'+'_'+contentsim_name,'acctop5max_similiar_strict'+'_'+contentsim_name]\n",
    "                    if columns_need_set is None or np.sum([1 if x in columns_need_set else 0 for x in cols_here])>0:\n",
    "                        question_true_similiar_list = sorted([acc for i,acc in question_true_similiar_reverse[question].items() if i in contentsim[question] for _ in range(true_questions[i])], reverse=True)\n",
    "                        res['cnt_accsimiliar'+'_'+contentsim_name].append(len(question_true_similiar_list))\n",
    "                        res['acctop5_accsimiliar'+'_'+contentsim_name].append(sum(question_true_similiar_list[:5])/(len(question_true_similiar_list[:5])+0.000001))\n",
    "                        res['acctop1_accsimiliar'+'_'+contentsim_name].append(sum(question_true_similiar_list[:1])/(len(question_true_similiar_list[:1])+0.000001))\n",
    "\n",
    "                    cols_here = ['cnt_finishstrictsimiliar'+'_'+contentsim_name,'acctop5_finishstrictsimiliar'+'_'+contentsim_name,'acctop1_finishstrictsimiliar'+'_'+contentsim_name,\n",
    "                                 'accrate_similiar_strict'+'_'+contentsim_name,'acctop1max_similiar_strict'+'_'+contentsim_name]\n",
    "                    if columns_need_set is None or np.sum([1 if x in columns_need_set else 0 for x in cols_here])>0:\n",
    "                        question_similiar_strict_list = sorted([acc for i,acc in question_similiar_reverse_strict[question].items() if i in contentsim[question] for _ in range(finished_questions[i])], reverse=True)\n",
    "                        res['cnt_finishstrictsimiliar'+'_'+contentsim_name].append(len(question_similiar_strict_list))\n",
    "                        res['acctop5_finishstrictsimiliar'+'_'+contentsim_name].append(sum(question_similiar_strict_list[:5])/(len(question_similiar_strict_list[:5])+0.000001))\n",
    "                        res['acctop1_finishstrictsimiliar'+'_'+contentsim_name].append(sum(question_similiar_strict_list[:1])/(len(question_similiar_strict_list[:1])+0.000001))\n",
    "\n",
    "                    cols_here = ['cnt_accstrictsimiliar'+'_'+contentsim_name,'acctop5_accstrictsimiliar'+'_'+contentsim_name,'acctop1_accstrictsimiliar'+'_'+contentsim_name,\n",
    "                                 'accrate_similiar_strict'+'_'+contentsim_name,'acctop1max_similiar_strict'+'_'+contentsim_name]\n",
    "                    if columns_need_set is None or np.sum([1 if x in columns_need_set else 0 for x in cols_here])>0:\n",
    "                        question_true_similiar_strict_list = sorted([acc for i,acc in question_true_similiar_reverse_strict[question].items() if i in contentsim[question] for _ in range(true_questions[i])], reverse=True)\n",
    "                        res['cnt_accstrictsimiliar'+'_'+contentsim_name].append(len(question_true_similiar_strict_list))\n",
    "                        res['acctop5_accstrictsimiliar'+'_'+contentsim_name].append(sum(question_true_similiar_strict_list[:5])/(len(question_true_similiar_strict_list[:5])+0.000001))\n",
    "                        res['acctop1_accstrictsimiliar'+'_'+contentsim_name].append(sum(question_true_similiar_strict_list[:1])/(len(question_true_similiar_strict_list[:1])+0.000001))\n",
    "                    \n",
    "                if response == 1:\n",
    "                    true_questions[question] += 1\n",
    "                finished_questions[question] += 1\n",
    "\n",
    "            for similiar_name in ('finishsimiliar','accsimiliar','finishstrictsimiliar','accstrictsimiliar'):\n",
    "                if 'cnt_'+similiar_name in columns_need_set or \\\n",
    "                    ('accrate_similiar' in columns_need_set and similiar_name in ('accsimiliar','finishsimiliar')) or \\\n",
    "                    ('accrate_similiar_strict' in columns_need_set and similiar_name in ('accstrictsimiliar','finishstrictsimiliar')): \n",
    "                    df['cnt_'+similiar_name+'_'+timelimit] = res['cnt_'+similiar_name]\n",
    "                if 'acctop5_'+similiar_name in columns_need_set or \\\n",
    "                    ('acctop5max_similiar' in columns_need_set and similiar_name in ('accsimiliar','finishsimiliar')): \n",
    "                    df['acctop5_'+similiar_name+'_'+timelimit] = res['acctop5_'+similiar_name]\n",
    "                if 'acctop1_'+similiar_name in columns_need_set or \\\n",
    "                    ('acctop1max_similiar' in columns_need_set and similiar_name in ('accsimiliar','finishsimiliar')) or \\\n",
    "                    ('acctop5max_similiar_strict' in columns_need_set and similiar_name in ('accsimiliar','finishsimiliar')) or \\\n",
    "                    ('acctop1max_similiar_strict' in columns_need_set and similiar_name in ('accstrictsimiliar','finishstrictsimiliar')): \n",
    "                    df['acctop1_'+similiar_name+'_'+timelimit] = res['acctop1_'+similiar_name]\n",
    "            if 'accrate_similiar' in columns_need_set: df['accrate_similiar'+'_'+timelimit] = df['cnt_accsimiliar'+'_'+timelimit]/(df['cnt_finishsimiliar'+'_'+timelimit]+0.000001)    \n",
    "            if 'accrate_similiar_strict' in columns_need_set: df['accrate_similiar_strict'+'_'+timelimit] = df['cnt_accstrictsimiliar'+'_'+timelimit]/(df['cnt_finishstrictsimiliar'+'_'+timelimit]+0.000001)\n",
    "            if 'acctop5max_similiar' in columns_need_set: df['acctop5max_similiar'+'_'+timelimit] = df[['acctop5_finishsimiliar'+'_'+timelimit,'acctop5_accsimiliar'+'_'+timelimit]].max(axis=1)    \n",
    "            if 'acctop1max_similiar' in columns_need_set: df['acctop1max_similiar'+'_'+timelimit] = df[['acctop1_finishsimiliar'+'_'+timelimit,'acctop1_accsimiliar'+'_'+timelimit]].max(axis=1)    \n",
    "            if 'acctop5max_similiar_strict' in columns_need_set: df['acctop5max_similiar_strict'+'_'+timelimit] = df[['acctop1_finishsimiliar'+'_'+timelimit,'acctop1_accsimiliar'+'_'+timelimit]].max(axis=1)    \n",
    "            if 'acctop1max_similiar_strict' in columns_need_set: df['acctop1max_similiar_strict'+'_'+timelimit] = df[['acctop1_finishstrictsimiliar'+'_'+timelimit,'acctop1_accstrictsimiliar'+'_'+timelimit]].max(axis=1)\n",
    "\n",
    "            for contentsim_name, contentsim in (('contentsim',question_info_sim),('contentsimstrict',question_info_sim_strict)):\n",
    "                for similiar_name in ('finishsimiliar','accsimiliar','finishstrictsimiliar','accstrictsimiliar'):\n",
    "                    if 'cnt_'+similiar_name+'_'+contentsim_name in columns_need_set or \\\n",
    "                        ('accrate_similiar'+'_'+contentsim_name in columns_need_set and similiar_name in ('accsimiliar','finishsimiliar')) or \\\n",
    "                        ('accrate_similiar_strict'+'_'+contentsim_name in columns_need_set and similiar_name in ('accstrictsimiliar','finishstrictsimiliar')): \n",
    "                        df['cnt_'+similiar_name+'_'+contentsim_name+'_'+timelimit] = res['cnt_'+similiar_name+'_'+contentsim_name]\n",
    "                    if 'acctop5_'+similiar_name+'_'+contentsim_name in columns_need_set or \\\n",
    "                        ('acctop5max_similiar'+'_'+contentsim_name in columns_need_set and similiar_name in ('accsimiliar','finishsimiliar')): \n",
    "                        df['acctop5_'+similiar_name+'_'+contentsim_name+'_'+timelimit] = res['acctop5_'+similiar_name+'_'+contentsim_name]\n",
    "                    if 'acctop1_'+similiar_name+'_'+contentsim_name in columns_need_set or \\\n",
    "                        ('acctop1max_similiar'+'_'+contentsim_name in columns_need_set and similiar_name in ('accsimiliar','finishsimiliar')) or \\\n",
    "                        ('acctop5max_similiar_strict'+'_'+contentsim_name in columns_need_set and similiar_name in ('accsimiliar','finishsimiliar')) or \\\n",
    "                        ('acctop1max_similiar_strict'+'_'+contentsim_name in columns_need_set and similiar_name in ('accstrictsimiliar','finishstrictsimiliar')): \n",
    "                        df['acctop1_'+similiar_name+'_'+contentsim_name+'_'+timelimit] = res['acctop1_'+similiar_name+'_'+contentsim_name]\n",
    "                if 'accrate_similiar'+'_'+contentsim_name in columns_need_set: df['accrate_similiar'+'_'+contentsim_name+'_'+timelimit] = df['cnt_accsimiliar'+'_'+contentsim_name+'_'+timelimit]/(df['cnt_finishsimiliar'+'_'+contentsim_name+'_'+timelimit]+0.000001)    \n",
    "                if 'accrate_similiar_strict'+'_'+contentsim_name in columns_need_set: df['accrate_similiar_strict'+'_'+contentsim_name+'_'+timelimit] = df['cnt_accstrictsimiliar'+'_'+contentsim_name+'_'+timelimit]/(df['cnt_finishstrictsimiliar'+'_'+contentsim_name+'_'+timelimit]+0.000001)\n",
    "                if 'acctop5max_similiar'+'_'+contentsim_name in columns_need_set: df['acctop5max_similiar'+'_'+contentsim_name+'_'+timelimit] = df[['acctop5_finishsimiliar'+'_'+contentsim_name+'_'+timelimit,'acctop5_accsimiliar'+'_'+contentsim_name+'_'+timelimit]].max(axis=1)    \n",
    "                if 'acctop1max_similiar'+'_'+contentsim_name in columns_need_set: df['acctop1max_similiar'+'_'+contentsim_name+'_'+timelimit] = df[['acctop1_finishsimiliar'+'_'+contentsim_name+'_'+timelimit,'acctop1_accsimiliar'+'_'+contentsim_name+'_'+timelimit]].max(axis=1)    \n",
    "                if 'acctop5max_similiar_strict'+'_'+contentsim_name in columns_need_set: df['acctop5max_similiar_strict'+'_'+contentsim_name+'_'+timelimit] = df[['acctop1_finishsimiliar'+'_'+contentsim_name+'_'+timelimit,'acctop1_accsimiliar'+'_'+contentsim_name+'_'+timelimit]].max(axis=1)    \n",
    "                if 'acctop1max_similiar_strict'+'_'+contentsim_name in columns_need_set: df['acctop1max_similiar_strict'+'_'+contentsim_name+'_'+timelimit] = df[['acctop1_finishstrictsimiliar'+'_'+contentsim_name+'_'+timelimit,'acctop1_accstrictsimiliar'+'_'+contentsim_name+'_'+timelimit]].max(axis=1)\n",
    "            if timelimit_value<0:\n",
    "                df = df.iloc[::-1].set_index(idx_raw)\n",
    "            for contentsim_name in ('_contentsim','_contentsimstrict',''):\n",
    "                for similiar_name in ('finishsimiliar','accsimiliar','finishstrictsimiliar','accstrictsimiliar'):\n",
    "                    if 'cnt_'+similiar_name+'_'+contentsim_name in columns_need_set: df['cnt_'+similiar_name+contentsim_name+'_'+timelimit] = df['cnt_'+similiar_name+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                    if 'acctop5_'+similiar_name+'_'+contentsim_name in columns_need_set: df['acctop5_'+similiar_name+contentsim_name+'_'+timelimit] = df['acctop5_'+similiar_name+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                    if 'acctop1_'+similiar_name+'_'+contentsim_name in columns_need_set: df['acctop1_'+similiar_name+contentsim_name+'_'+timelimit] = df['acctop1_'+similiar_name+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                if 'accrate_similiar'+'_'+contentsim_name in columns_need_set: df['accrate_similiar'+contentsim_name+'_'+timelimit] = df['accrate_similiar'+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                if 'accrate_similiar_strict'+'_'+contentsim_name in columns_need_set: df['accrate_similiar_strict'+contentsim_name+'_'+timelimit] = df['accrate_similiar_strict'+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                if 'acctop5max_similiar'+'_'+contentsim_name in columns_need_set: df['acctop5max_similiar'+contentsim_name+'_'+timelimit] = df['acctop5max_similiar'+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                if 'acctop1max_similiar'+'_'+contentsim_name in columns_need_set: df['acctop1max_similiar'+contentsim_name+'_'+timelimit] = df['acctop1max_similiar'+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                if 'acctop5max_similiar_strict'+'_'+contentsim_name in columns_need_set: df['acctop5max_similiar_strict'+contentsim_name+'_'+timelimit] = df['acctop5max_similiar_strict'+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                if 'acctop1max_similiar_strict'+'_'+contentsim_name in columns_need_set: df['acctop1max_similiar_strict'+contentsim_name+'_'+timelimit] = df['acctop1max_similiar_strict'+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                    \n",
    "            return df\n",
    "\n",
    "        \n",
    "        columns_need_set = set(['_'.join(x.split('_')[:-1]) for x in columns_sim_res[1] if '-' not in x and '31536000000' in x])\n",
    "        df = df.groupby('uid').parallel_apply(partial(tmp_func, timelimit_value=365*24*3600*1000,columns_need_set=columns_need_set)).reset_index(drop=True)\n",
    "        columns_need_set = set(['_'.join(x.split('_')[:-1]) for x in columns_sim_res[1] if '-' not in x and '1209600000' in x])\n",
    "        df = df.groupby('uid').parallel_apply(partial(tmp_func, timelimit_value=14*24*3600*1000,columns_need_set=columns_need_set)).reset_index(drop=True)\n",
    "        columns_need_set = set(['_'.join(x.split('_')[:-1]) for x in columns_sim_res[1] if '-' not in x and '86400000' in x])\n",
    "        df = df.groupby('uid').parallel_apply(partial(tmp_func, timelimit_value=24*3600*1000,columns_need_set=columns_need_set)).reset_index(drop=True)\n",
    "        columns_need_set = set(['_'.join(x.split('_')[:-1]) for x in columns_sim_res[1] if '-' not in x and '3600000' in x])\n",
    "        df = df.groupby('uid').parallel_apply(partial(tmp_func, timelimit_value=3600*1000,columns_need_set=columns_need_set)).reset_index(drop=True)\n",
    "        columns_need_set = set(['_'.join(x.split('_')[:-1]) for x in columns_sim_res[1] if '-1209600000' in x])\n",
    "        df = df.groupby('uid').parallel_apply(partial(tmp_func, timelimit_value=-14*24*3600*1000,columns_need_set=columns_need_set)).reset_index(drop=True)\n",
    "        columns_need_set = set(['_'.join(x.split('_')[:-1]) for x in columns_sim_res[1] if '-21600000' in x])\n",
    "        df = df.groupby('uid').parallel_apply(partial(tmp_func, timelimit_value=-6*3600*1000,columns_need_set=columns_need_set)).reset_index(drop=True)\n",
    "        \n",
    "        # 训练、验证集：只需要保存需要预测的就行了\n",
    "        if data_type in ['tr','val']:\n",
    "        #if data_type in ['val']:\n",
    "            df = df[df['response']==-1]\n",
    "\n",
    "        df.fillna(-1, inplace=True)\n",
    "        \n",
    "        # 压缩数据，压缩为指定格式\n",
    "        # df = df[useful_features]\n",
    "        df=df[list(set(kf_or+['uid','timestamp','question','real_response','response','is_enhance','uid_record_cumsum','uid_record_sum']))]\n",
    "        for col,dtype in df.dtypes.items():\n",
    "            if col in useful_features_dtypes:\n",
    "                df[col] = df[col].astype(useful_features_dtypes[col])\n",
    "            elif dtype == 'int64':\n",
    "                if col not in ['timestamp','is_enhance']:\n",
    "                    if df[col].max()<=32767 and df[col].min()>=-32768:\n",
    "                        df[col] = df[col].astype('int16')\n",
    "                    else:\n",
    "                        df[col] = df[col].astype('int32')\n",
    "            elif dtype == 'float64':\n",
    "                df[col] = df[col].astype('float32')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    df_tr['real_response'] = df_tr['response']\n",
    "    df_tr['is_enhance'] = 0\n",
    "    df_test['real_response'] = df_test['response']\n",
    "    df_test['is_enhance'] = 0\n",
    "    \n",
    "    # 计算sim矩阵\n",
    "    df_tr_tmp = df_tr.copy()\n",
    "    df_tr_tmp.loc[(df_tr_tmp['uid_record_cumsum']>=df_tr_tmp['uid_record_sum']*0.5)&(df_tr_tmp['uid_record_cumsum']>=90), 'response'] = -1\n",
    "    df_val_tmp = df_val.copy()\n",
    "    df_val_tmp.loc[(df_val_tmp['uid_record_cumsum']>=df_val_tmp['uid_record_sum']*0.5)&(df_val_tmp['uid_record_cumsum']>=90), 'response'] = -1\n",
    "    get_sim_metrix(df_tr_tmp, df_test, df_val=df_val_tmp)\n",
    "    del df_tr_tmp,df_val_tmp\n",
    "    gc.collect()\n",
    "    \n",
    "    df_test = calc_uid_features(df_test, append_columns=True, data_type='test')\n",
    "    if save_files is not None:\n",
    "        df_test.reset_index(drop=True).to_feather(save_files[2])\n",
    "    gc.collect()\n",
    "\n",
    "    data_type, data_enhance = ('val',val_data_enhance)\n",
    "    if df_val is not None and data_enhance>0:\n",
    "        df_val['real_response'] = df_val['response']\n",
    "        df_val['is_enhance'] = 0\n",
    "        dfs = []\n",
    "        rng = np.random.default_rng(seed)\n",
    "        for _ in range(0, data_enhance):\n",
    "            print('val enhance', _)\n",
    "            # 只选取范围内（尝试截断，比如k不能大于3/4）\n",
    "            df_tmp = df_val.copy()\n",
    "            k = rng.random()*0.5+0.25 if _ != 0 else 0.5\n",
    "            df_tmp.loc[(df_tmp['uid_record_cumsum']>=df_tmp['uid_record_sum']*k)&(df_tmp['uid_record_cumsum']>=90), 'response'] = -1\n",
    "            # 超过k*2范围的数据就不要了\n",
    "            tmp = calc_uid_features(df_tmp[(df_tmp['uid_record_cumsum']<=df_tmp['uid_record_sum']*k*2)], data_type=data_type)\n",
    "            tmp['is_enhance'] = _\n",
    "            dfs.append(tmp)\n",
    "            gc.collect()\n",
    "        df_val = pd.concat(dfs, axis=0)\n",
    "        if save_files is not None:\n",
    "            df_val.reset_index(drop=True).to_feather(save_files[1])\n",
    "        gc.collect()\n",
    "    \n",
    "    data_type, data_enhance = ('tr',tr_data_enhance)\n",
    "    if data_enhance>0:\n",
    "        dfs = []\n",
    "        rng = np.random.default_rng(seed)\n",
    "        for _ in range(0, data_enhance):\n",
    "            print('tr enhance', _)\n",
    "            # 只选取范围内（尝试截断，比如k不能大于3/4）\n",
    "            df_tmp = df_tr.copy()\n",
    "            k = rng.random()*0.5+0.25 if _ != 0 else 0.5\n",
    "            df_tmp.loc[(df_tmp['uid_record_cumsum']>=df_tmp['uid_record_sum']*k)&(df_tmp['uid_record_cumsum']>=90), 'response'] = -1\n",
    "            # 更新sim矩阵\n",
    "            get_sim_metrix(df_tmp, df_test, df_val=df_val)\n",
    "            # 超过k*2范围的数据就不要了\n",
    "            tmp = calc_uid_features(df_tmp[(df_tmp['uid_record_cumsum']<=df_tmp['uid_record_sum']*k*2)], data_type=data_type)\n",
    "            tmp = tmp.copy()\n",
    "            tmp.reset_index(drop=True, inplace=True)\n",
    "            tmp['is_enhance'] = _\n",
    "            dfs.append(tmp)\n",
    "            gc.collect()\n",
    "        print('merging df_tr')\n",
    "        df_tr = pd.concat(dfs, axis=0)\n",
    "        del dfs\n",
    "        if save_files is not None:\n",
    "            print('resetindex df_tr')\n",
    "            df_tr.reset_index(drop=True, inplace=True)\n",
    "            print('tofeather df_tr')\n",
    "            df_tr.to_feather(save_files[0])\n",
    "        gc.collect()\n",
    "    gc.collect()\n",
    "    \n",
    "    if save_files is not None:\n",
    "        return \n",
    "    if df_val is not None:\n",
    "        return df_tr, df_val, df_test, columns\n",
    "    else:\n",
    "        return df_tr, df_test, columns\n",
    "\n",
    "\"\"\"\n",
    "df_tmp,df_tmp2, df_tmp3, columns_tmp = feature_engineering2(df.iloc[:3000].copy(), df_test.iloc[:3000].copy(), df_val=df.iloc[3000:6000].copy(), \n",
    "                                         tr_data_enhance=2, val_data_enhance=1)\n",
    "print(columns_tmp)\n",
    "df_tmp\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T03:36:50.739456Z",
     "start_time": "2022-12-30T03:36:50.492281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_tmp,df_tmp2, df_tmp3, columns_tmp = feature_engineering2(df.iloc[:3000].copy(), df_test.iloc[:3000].copy(), df_val=df.iloc[3000:6000].copy(), \\n                                         tr_data_enhance=2, val_data_enhance=1)\\nprint(columns_tmp)\\ndf_tmp\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将测试集的已有信息也放进来（特征工程和训练集）\n",
    "useful_features_dtypes = {'uid': np.dtype('int16'), 'question': np.dtype('int16'), 'response': np.dtype('int8'), 'timestamp': np.dtype('int64'), 'type': np.dtype('int8'), 'concept_cnt': np.dtype('int8'), 'concept_hot_cnt': np.dtype('int8'), 'concept_1': np.dtype('int16'), 'concept_2': np.dtype('int16'), 'concept_3': np.dtype('int16'), 'concept_4': np.dtype('int16'), 'concept_5': np.dtype('int16'), 'concept_6': np.dtype('int16'), 'content_cnt': np.dtype('int16'), 'kc_group_cnt': np.dtype('int8'), 'kc_cnt': np.dtype('int8'), 'kc_1': np.dtype('int16'), 'kc_2': np.dtype('int16'), 'kc_3': np.dtype('int16'), 'kc_4': np.dtype('int16'), 'kc_5': np.dtype('int16'), 'kc_6': np.dtype('int16'), 'kc_7': np.dtype('int16'), 'kc_8': np.dtype('int8'), 'analysis_cnt': np.dtype('int16'), 'time_day': np.dtype('int16'), 'time_hour': np.dtype('int8'), 'time_is_workday': np.dtype('int8'), 'time_weekday': np.dtype('int8'), 'time_year': np.dtype('int16'), 'data_type': np.dtype('O'), 'uid_record_cumsum': np.dtype('int16'), 'uid_record_sum': np.dtype('int16'), 'concept_showcnt_1': np.dtype('int32'), 'concept_accrate_1': np.dtype('float32'), 'concept_showcnt_2': np.dtype('int32'), 'concept_accrate_2': np.dtype('float32'), 'concept_showcnt_3': np.dtype('int32'), 'concept_accrate_3': np.dtype('float32'), 'concept_showcnt_4': np.dtype('int16'), 'concept_accrate_4': np.dtype('float32'), 'concept_showcnt_5': np.dtype('int16'), 'concept_accrate_5': np.dtype('float32'), 'concept_showcnt_6': np.dtype('int16'), 'concept_accrate_6': np.dtype('float32'), 'concept_type_showcnt_1': np.dtype('int32'), 'concept_type_accrate_1': np.dtype('float32'), 'concept_type_showcnt_2': np.dtype('int32'), 'concept_type_accrate_2': np.dtype('float32'), 'concept_type_showcnt_3': np.dtype('int16'), 'concept_type_accrate_3': np.dtype('float32'), 'concept_type_showcnt_4': np.dtype('int16'), 'concept_type_accrate_4': np.dtype('float32'), 'concept_type_showcnt_5': np.dtype('int16'), 'concept_type_accrate_5': np.dtype('float32'), 'concept_type_showcnt_6': np.dtype('int16'), 'concept_type_accrate_6': np.dtype('float32'), 'concept_min_accrate': np.dtype('float32'), 'concept_mean_accrate': np.dtype('float32'), 'concept_max_accrate': np.dtype('float32'), 'concept_min_showcnt': np.dtype('int32'), 'concept_mean_showcnt': np.dtype('float32'), 'concept_max_showcnt': np.dtype('int32'), 'concepttype_min_accrate': np.dtype('float32'), 'concepttype_mean_accrate': np.dtype('float32'), 'concepttype_max_accrate': np.dtype('float32'), 'concepttype_min_showcnt': np.dtype('int32'), 'concepttype_mean_showcnt': np.dtype('float32'), 'concepttype_max_showcnt': np.dtype('int32'), 'kc_showcnt_1': np.dtype('int32'), 'kc_accrate_1': np.dtype('float32'), 'kc_showcnt_2': np.dtype('int32'), 'kc_accrate_2': np.dtype('float32'), 'kc_showcnt_3': np.dtype('int32'), 'kc_accrate_3': np.dtype('float32'), 'kc_showcnt_4': np.dtype('int32'), 'kc_accrate_4': np.dtype('float32'), 'kc_showcnt_5': np.dtype('int32'), 'kc_accrate_5': np.dtype('float32'), 'kc_showcnt_6': np.dtype('int32'), 'kc_accrate_6': np.dtype('float32'), 'kc_showcnt_7': np.dtype('int32'), 'kc_accrate_7': np.dtype('float32'), 'kc_showcnt_8': np.dtype('int32'), 'kc_accrate_8': np.dtype('float32'), 'kc_type_showcnt_1': np.dtype('int32'), 'kc_type_accrate_1': np.dtype('float32'), 'kc_type_showcnt_2': np.dtype('int32'), 'kc_type_accrate_2': np.dtype('float32'), 'kc_type_showcnt_3': np.dtype('int32'), 'kc_type_accrate_3': np.dtype('float32'), 'kc_type_showcnt_4': np.dtype('int32'), 'kc_type_accrate_4': np.dtype('float32'), 'kc_type_showcnt_5': np.dtype('int32'), 'kc_type_accrate_5': np.dtype('float32'), 'kc_type_showcnt_6': np.dtype('int32'), 'kc_type_accrate_6': np.dtype('float32'), 'kc_type_showcnt_7': np.dtype('int32'), 'kc_type_accrate_7': np.dtype('float32'), 'kc_type_showcnt_8': np.dtype('int32'), 'kc_type_accrate_8': np.dtype('float32'), 'kc_min_accrate': np.dtype('float32'), 'kc_mean_accrate': np.dtype('float32'), 'kc_max_accrate': np.dtype('float32'), 'kc_min_showcnt': np.dtype('int32'), 'kc_mean_showcnt': np.dtype('float32'), 'kc_max_showcnt': np.dtype('int32'), 'kctype_min_accrate': np.dtype('float32'), 'kctype_mean_accrate': np.dtype('float32'), 'kctype_max_accrate': np.dtype('float32'), 'kctype_min_showcnt': np.dtype('int32'), 'kctype_mean_showcnt': np.dtype('float32'), 'kctype_max_showcnt': np.dtype('int32'), 'question_showcnt': np.dtype('int16'), 'question_accrate': np.dtype('float32'), 'type_showcnt': np.dtype('int32'), 'type_accrate': np.dtype('float32'), 'time_hour_showcnt': np.dtype('int32'), 'time_hour_accrate': np.dtype('float32'), 'time_is_workday_showcnt': np.dtype('int32'), 'time_is_workday_accrate': np.dtype('float32'), 'time_weekday_showcnt': np.dtype('int32'), 'time_weekday_accrate': np.dtype('float32'), 'timestamp_question_cnt': np.dtype('int16'), 'timestamp_question_accrate': np.dtype('float32'), 'question_showcnt_without_timestamp_question': np.dtype('int16'), 'question_accrate_without_timestamp_question': np.dtype('float32'), 'uid_question_utilnow_3600_asc': np.dtype('int8'), 'uid_question_submittimes_3600_asc': np.dtype('int16'), 'uid_unique_submittimes_3600_asc': np.dtype('int8'), 'uid_timedistance_to_last_submit_asc': np.dtype('int32'), 'uid_timestamp_question_submit': np.dtype('int8'), 'uid_question_utilnow_21600_asc': np.dtype('int8'), 'uid_question_submittimes_21600_asc': np.dtype('int16'), 'uid_unique_submittimes_21600_asc': np.dtype('int8'), 'uid_question_utilnow_94608000_asc': np.dtype('int8'), 'uid_question_submittimes_94608000_asc': np.dtype('int16'), 'uid_unique_submittimes_94608000_asc': np.dtype('int16'), 'uid_question_utilnow_94608000_desc': np.dtype('int8'), 'uid_question_submittimes_94608000_desc': np.dtype('int16'), 'uid_unique_submittimes_94608000_desc': np.dtype('int16'), 'uid_timedistance_to_last_submit_desc': np.dtype('int32'), 'uid_kc_utilnow_3600_asc': np.dtype('int16'), 'uid_kc_utilnow_21600_asc': np.dtype('int16'), 'uid_kc_utilnow_94608000_asc': np.dtype('int16'), 'uid_kc_utilnow_94608000_desc': np.dtype('int16'), 'new_kc_days_min': np.dtype('float32'), 'uid_new_kc_days_min': np.dtype('float32'), 'uid_concept_utilnow_3600_asc': np.dtype('int8'), 'uid_concept_utilnow_21600_asc': np.dtype('int8'), 'uid_concept_utilnow_94608000_asc': np.dtype('int8'), 'uid_concept_utilnow_94608000_desc': np.dtype('int8'), 'new_concept_days_min': np.dtype('float32'), 'uid_new_concept_days_min': np.dtype('float32'), 'uid_timestamp_question_meansubmit': np.dtype('float32'), 'uid_timestamp_showcnt': np.dtype('int8'), 'new_question_days': np.dtype('float32'), 'uid_new_question_days': np.dtype('float32'), 'real_response': np.dtype('int8'), 'is_enhance': np.dtype('int8'), 'uid_showcnt': np.dtype('int16'), 'uid_accrate': np.dtype('float32'), 'uid_question_accrate': np.dtype('float32'), 'uid_concept_accrate_1': np.dtype('float32'), 'uid_concept_accrate_2': np.dtype('float32'), 'uid_concept_accrate_3': np.dtype('float32'), 'uid_concept_accrate_4': np.dtype('float32'), 'uid_concept_accrate_5': np.dtype('float32'), 'uid_concept_accrate_6': np.dtype('float32'), 'uid_concept_type_accrate_1': np.dtype('float32'), 'uid_concept_type_accrate_2': np.dtype('float32'), 'uid_concept_type_accrate_3': np.dtype('float32'), 'uid_concept_type_accrate_4': np.dtype('float32'), 'uid_concept_type_accrate_5': np.dtype('float32'), 'uid_concept_type_accrate_6': np.dtype('int8'), 'uidconcept_min_accrate': np.dtype('float32'), 'uidconcept_mean_accrate': np.dtype('float32'), 'uidconcept_max_accrate': np.dtype('float32'), 'uidconcepttype_min_accrate': np.dtype('float32'), 'uidconcepttype_mean_accrate': np.dtype('float32'), 'uidconcepttype_max_accrate': np.dtype('float32'), 'uid_kc_accrate_1': np.dtype('float32'), 'uid_kc_accrate_2': np.dtype('float32'), 'uid_kc_accrate_3': np.dtype('float32'), 'uid_kc_accrate_4': np.dtype('float32'), 'uid_kc_accrate_5': np.dtype('float32'), 'uid_kc_accrate_6': np.dtype('float32'), 'uid_kc_accrate_7': np.dtype('float32'), 'uid_kc_accrate_8': np.dtype('float32'), 'uid_kc_type_accrate_1': np.dtype('float32'), 'uid_kc_type_accrate_2': np.dtype('float32'), 'uid_kc_type_accrate_3': np.dtype('float32'), 'uid_kc_type_accrate_4': np.dtype('float32'), 'uid_kc_type_accrate_5': np.dtype('float32'), 'uid_kc_type_accrate_6': np.dtype('float32'), 'uid_kc_type_accrate_7': np.dtype('float32'), 'uid_kc_type_accrate_8': np.dtype('float32'), 'uidkc_min_accrate': np.dtype('float32'), 'uidkc_mean_accrate': np.dtype('float32'), 'uidkc_max_accrate': np.dtype('float32'), 'uidkctype_min_accrate': np.dtype('float32'), 'uidkctype_mean_accrate': np.dtype('float32'), 'uidkctype_max_accrate': np.dtype('float32'), 'hours_to_half_split_timestamp': np.dtype('int32'), 'records_to_half_split_uid_record_cumsum': np.dtype('int16'), 'cnt_finishsimiliar': np.dtype('float32'), 'acctop5_finishsimiliar': np.dtype('float32'), 'acctop1_finishsimiliar': np.dtype('float32'), 'cnt_accsimiliar': np.dtype('float32'), 'acctop5_accsimiliar': np.dtype('float32'), 'acctop1_accsimiliar': np.dtype('float32'), 'cnt_finishstrictsimiliar': np.dtype('float32'), 'acctop5_finishstrictsimiliar': np.dtype('float32'), 'acctop1_finishstrictsimiliar': np.dtype('float32'), 'cnt_accstrictsimiliar': np.dtype('float32'), 'acctop5_accstrictsimiliar': np.dtype('float32'), 'acctop1_accstrictsimiliar': np.dtype('float32'), 'accrate_similiar': np.dtype('float32'), 'accrate_similiar_strict': np.dtype('float32'), 'acctop5max_similiar': np.dtype('float32'), 'acctop1max_similiar': np.dtype('float32'), 'acctop5max_similiar_strict': np.dtype('float32'), 'acctop1max_similiar_strict': np.dtype('float32')}\n",
    "\n",
    "useful_features = ['uid_concept_utilnow_94608000_desc', 'time_hour_accrate', 'concepttype_mean_showcnt', 'time_weekday', \n",
    "'uid_timestamp_showcnt', 'concept_min_accrate', 'uid_accrate', 'question_accrate', 'kc_showcnt_4', \n",
    "'question_showcnt', 'uid_concept_utilnow_3600_asc', 'concept_max_accrate', 'kc_type_showcnt_1', 'kc_3', \n",
    "'concept_type_accrate_1', 'uid_showcnt', 'time_day', 'question', 'timestamp_question_cnt', 'concept_mean_accrate', \n",
    "'uid_concept_utilnow_21600_asc', 'uid_concept_accrate_4', 'kc_2', 'uidconcepttype_max_accrate', 'type_accrate', \n",
    "'analysis_cnt', 'kc_max_accrate', 'concept_min_showcnt', 'uidkc_mean_accrate'] + \\\n",
    "    ['uid_accrate', 'question_accrate', 'timestamp_question_cnt', 'question', 'timestamp', 'time_day', \n",
    " 'uid_new_question_days', 'uid_kc_utilnow_3600_asc', 'uid_timestamp_showcnt', 'uid_concept_utilnow_21600_asc', \n",
    " 'analysis_cnt', 'new_concept_days_min', 'concepttype_min_accrate', 'concept_mean_accrate', 'question_showcnt', \n",
    " 'time_hour_accrate', 'uidkctype_min_accrate', 'uid_concept_accrate_5'] + \\\n",
    "    ['uid','question','timestamp' ,'response','real_response','is_enhance'] + \\\n",
    "    ['cnt_finishsimiliar', 'acctop5_finishsimiliar',\n",
    "       'acctop1_finishsimiliar', 'cnt_accsimiliar', 'acctop5_accsimiliar',\n",
    "       'acctop1_accsimiliar', 'cnt_finishstrictsimiliar',\n",
    "       'acctop5_finishstrictsimiliar', 'acctop1_finishstrictsimiliar',\n",
    "       'cnt_accstrictsimiliar', 'acctop5_accstrictsimiliar',\n",
    "       'acctop1_accstrictsimiliar', 'accrate_similiar',\n",
    "       'accrate_similiar_strict', 'acctop5max_similiar',\n",
    "       'acctop1max_similiar', 'acctop5max_similiar_strict',\n",
    "       'acctop1max_similiar_strict']\n",
    "useful_features = list(set(useful_features))\n",
    "\n",
    "def feature_engineering3(df_tr, df_test, df_val=None, tr_data_enhance=1, val_data_enhance=1, seed=1, save_files=None):\n",
    "    # 不同统计方式得到的特征，用于不同类型的模型\n",
    "    columns = {\n",
    "        'at':[], # 可以直接使用的特征\n",
    "        'bs':[], # 统计这次提交以前的label\n",
    "        'bt':[], # 统计今天以前的label\n",
    "        'bh':[]  # 只使用一半的label进行统计\n",
    "    }\n",
    "    gc.collect()\n",
    "    \n",
    "    # 开始统计每个人的个人信息（数据增强）,append_columns:是否把列名加入columns字典\n",
    "    def calc_uid_features(df, append_columns=False, data_type='tr'):\n",
    "        \n",
    "        df_response = df[df['response']!=-1]\n",
    "        \n",
    "        if data_type in ('tr','val'):\n",
    "            col = 'uid'\n",
    "            df = df.drop([col+'_showcnt',col+'_accrate'], axis=1)\n",
    "            tmp = df_response.groupby(col)['response'].agg(['count','mean']).rename(columns={'count':col+'_showcnt', 'mean':col+'_accrate'})\n",
    "            df=df.merge(tmp, how='left', left_on=col, right_index=True, suffixes=(None,'_1'))\n",
    "            columns['bh'].extend([col+'_showcnt',col+'_accrate'])\n",
    "            \n",
    "                \n",
    "        #\"\"\" 不work\n",
    "        # concept : df_response 的累计正确率\n",
    "        col = 'uid'\n",
    "        df_tmp = pd.concat([\n",
    "            df_response.loc[df_response['concept_1']!=-1,['uid','response','concept_1','type']].rename(columns={'concept_1':'concept'}),\n",
    "            df_response.loc[df_response['concept_2']!=-1,['uid','response','concept_2','type']].rename(columns={'concept_2':'concept'}),\n",
    "            df_response.loc[df_response['concept_3']!=-1,['uid','response','concept_3','type']].rename(columns={'concept_3':'concept'}),\n",
    "            df_response.loc[df_response['concept_4']!=-1,['uid','response','concept_4','type']].rename(columns={'concept_4':'concept'}),\n",
    "            df_response.loc[df_response['concept_5']!=-1,['uid','response','concept_5','type']].rename(columns={'concept_5':'concept'}),\n",
    "            df_response.loc[df_response['concept_6']!=-1,['uid','response','concept_6','type']].rename(columns={'concept_6':'concept'}),\n",
    "        ])\n",
    "        col2 = 'concept'\n",
    "        tmp = df_tmp.groupby([col, col2])['response'].agg('mean').rename(col+'_'+col2+'_accrate')\n",
    "        df=df.merge(tmp, how='left', left_on=[col,col2+'_4'], right_index=True, suffixes=(None,'_4')).\\\n",
    "                merge(tmp, how='left', left_on=[col,col2+'_5'], right_index=True, suffixes=(None,'_5')).\\\n",
    "                rename(columns={col+'_'+col2+'_accrate':col+'_'+col2+'_accrate'+'_4'}).fillna(-1)\n",
    "        col3 = 'type'  # {'count':len,'mean':np.mean}\n",
    "        tmp = df_tmp.groupby([col,col2,col3])['response'].agg('mean').rename(col+'_'+col2+'_'+col3+'_accrate')\n",
    "        df=df.merge(tmp, how='left', left_on=[col,col2+'_1',col3], right_index=True, suffixes=(None,'_1'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_2',col3], right_index=True, suffixes=(None,'_2'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_3',col3], right_index=True, suffixes=(None,'_3'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_4',col3], right_index=True, suffixes=(None,'_4'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_5',col3], right_index=True, suffixes=(None,'_5'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_6',col3], right_index=True, suffixes=(None,'_6'))\\\n",
    "            .rename(columns={col+'_'+col2+'_'+col3+'_accrate':col+'_'+col2+'_'+col3+'_accrate'+'_1'}).fillna(-1)\n",
    "        for i in range(1,7):\n",
    "            columns['bh'].extend([col+'_'+col2+'_'+col3+'_accrate_'+str(i),col+'_'+col2+'_accrate_'+str(i)])\n",
    "        df[col+col2+col3+'_max_accrate'] = df[['uid_concept_type_accrate_1','uid_concept_type_accrate_2','uid_concept_type_accrate_3','uid_concept_type_accrate_4','uid_concept_type_accrate_5','uid_concept_type_accrate_6']].parallel_apply(lambda x: max([xx if xx!=-1 else -9 for xx in x]), axis=1)\n",
    "        columns['at'].extend([col+col2+col3+'_max_accrate'])\n",
    "        \n",
    "    \n",
    "        # kc : df_response 的累计正确率\n",
    "        df_tmp = pd.concat([\n",
    "            df_response.loc[df_response['kc_1']!=-1,['uid','response','kc_1','timestamp','type']].rename(columns={'kc_1':'kc'}),\n",
    "            df_response.loc[df_response['kc_2']!=-1,['uid','response','kc_2','timestamp','type']].rename(columns={'kc_2':'kc'}),\n",
    "            df_response.loc[df_response['kc_3']!=-1,['uid','response','kc_3','timestamp','type']].rename(columns={'kc_3':'kc'}),\n",
    "            df_response.loc[df_response['kc_4']!=-1,['uid','response','kc_4','timestamp','type']].rename(columns={'kc_4':'kc'}),\n",
    "            df_response.loc[df_response['kc_5']!=-1,['uid','response','kc_5','timestamp','type']].rename(columns={'kc_5':'kc'}),\n",
    "            df_response.loc[df_response['kc_6']!=-1,['uid','response','kc_6','timestamp','type']].rename(columns={'kc_6':'kc'}),\n",
    "            df_response.loc[df_response['kc_7']!=-1,['uid','response','kc_7','timestamp','type']].rename(columns={'kc_7':'kc'}),\n",
    "            df_response.loc[df_response['kc_8']!=-1,['uid','response','kc_8','timestamp','type']].rename(columns={'kc_8':'kc'}),\n",
    "        ])\n",
    "        gc.collect()\n",
    "        col2 = 'kc'\n",
    "        tmp = df_tmp.groupby([col, col2])['response'].agg('mean').rename(col+'_'+col2+'_accrate')\n",
    "        df=df.merge(tmp, how='left', left_on=[col,col2+'_1'], right_index=True, suffixes=(None,'_1'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_2'], right_index=True, suffixes=(None,'_2'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_3'], right_index=True, suffixes=(None,'_3'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_4'], right_index=True, suffixes=(None,'_4'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_5'], right_index=True, suffixes=(None,'_5'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_6'], right_index=True, suffixes=(None,'_6'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_7'], right_index=True, suffixes=(None,'_7'))\\\n",
    "            .merge(tmp, how='left', left_on=[col,col2+'_8'], right_index=True, suffixes=(None,'_8'))\\\n",
    "            .rename(columns={col+'_'+col2+'_accrate':col+'_'+col2+'_accrate'+'_1'})\n",
    "        for i in range(1,9):\n",
    "            columns['bh'].extend([col+'_'+col2+'_'+col3+'_accrate_'+str(i), col+'_'+col2+'_accrate_'+str(i)])\n",
    "        df[col+col2+'_mean_accrate'] = df[['uid_kc_accrate_1','uid_kc_accrate_2','uid_kc_accrate_3','uid_kc_accrate_4','uid_kc_accrate_5','uid_kc_accrate_6','uid_kc_accrate_7','uid_kc_accrate_8']].parallel_apply(lambda x: sum([xx for xx in x if xx!=-1])/(len([xx for xx in x if xx!=-1])+0.0001), axis=1)\n",
    "        columns['at'].extend([col+col2+'_min_accrate',col+col2+'_mean_accrate',col+col2+'_max_accrate'])\n",
    "        \n",
    "        del df_tmp\n",
    "        gc.collect()\n",
    "        \n",
    "        # 找到相似题目，映射到原特征中，计算相似题目做过/会做多少；top1、top3 accrate\n",
    "        def tmp_func(df, timelimit_value=3600000, columns_need_set=None):\n",
    "            if timelimit_value<0:\n",
    "                idx_raw = df.index\n",
    "                df = df.iloc[::-1].reset_index(drop=True)\n",
    "            timelimit = str(timelimit_value)\n",
    "            from collections import defaultdict\n",
    "            global question_interact_ok,question_interact,question_interact_true_ok,question_interact_true\n",
    "            global question_similiar_reverse,question_true_similiar_reverse,question_similiar_reverse_strict,question_true_similiar_reverse_strict\n",
    "            global question_info_sim,question_info_sim_strict\n",
    "            finished_questions = defaultdict(int)\n",
    "            true_questions = defaultdict(int)\n",
    "            start = -1\n",
    "            res = {}\n",
    "            # 注册要使用的列名\n",
    "            res['accrate_similiar_strict'] = []\n",
    "            for similiar_name in ('finishsimiliar','accsimiliar','finishstrictsimiliar','accstrictsimiliar'):\n",
    "                res['cnt_'+similiar_name] = []\n",
    "                res['acctop5_'+similiar_name] = []\n",
    "                res['acctop1_'+similiar_name] = []\n",
    "                for contentsim_name, contentsim in (('contentsim',question_info_sim),('contentsimstrict',question_info_sim_strict)):\n",
    "                    res['cnt_'+similiar_name+'_'+contentsim_name] = []\n",
    "                    res['acctop5_'+similiar_name+'_'+contentsim_name] = []\n",
    "                    res['acctop1_'+similiar_name+'_'+contentsim_name] = []\n",
    "\n",
    "            for idx, (question, response, timestamp) in df[['question', 'response', 'timestamp']].iterrows():\n",
    "                # 超时的数据排除出去\n",
    "                if start == -1:\n",
    "                    start = 0 if timelimit_value>0 else len(df)-1\n",
    "                else:\n",
    "                    while (timelimit_value>0 and timestamp - df['timestamp'].iloc[start] > timelimit_value) or (timelimit_value<0 and df['timestamp'].iloc[start]-timestamp > -timelimit_value):\n",
    "                        if df['response'].iloc[start] == 1:\n",
    "                            true_questions[df['question'].iloc[start]] -= 1\n",
    "                        finished_questions[df['question'].iloc[start]] -= 1\n",
    "                        start += (1 if timelimit_value>0 else -1)\n",
    "\n",
    "                cols_here = ['cnt_finishsimiliar','acctop5_finishsimiliar','acctop1_finishsimiliar','acctop1max_similiar','acctop5max_similiar_strict','accrate_similiar','acctop5max_similiar']\n",
    "                if columns_need_set is None or np.sum([1 if x in columns_need_set else 0 for x in cols_here])>0:\n",
    "                    question_similiar_list = sorted([acc for i,acc in question_similiar_reverse[question].items() for _ in range(finished_questions[i])], reverse=True)\n",
    "                    res['cnt_finishsimiliar'].append(len(question_similiar_list))\n",
    "                    res['acctop5_finishsimiliar'].append(sum(question_similiar_list[:5])/(len(question_similiar_list[:5])+0.000001))\n",
    "                    res['acctop1_finishsimiliar'].append(sum(question_similiar_list[:1])/(len(question_similiar_list[:1])+0.000001))\n",
    "                \n",
    "                cols_here = ['cnt_accsimiliar','acctop5_accsimiliar','acctop1_accsimiliar','accrate_similiar','acctop5max_similiar','acctop1max_similiar','acctop5max_similiar_strict']\n",
    "                if columns_need_set is None or np.sum([1 if x in columns_need_set else 0 for x in cols_here])>0:\n",
    "                    question_true_similiar_list = sorted([acc for i,acc in question_true_similiar_reverse[question].items() for _ in range(true_questions[i])], reverse=True)\n",
    "                    res['cnt_accsimiliar'].append(len(question_true_similiar_list))\n",
    "                    res['acctop5_accsimiliar'].append(sum(question_true_similiar_list[:5])/(len(question_true_similiar_list[:5])+0.000001))\n",
    "                    res['acctop1_accsimiliar'].append(sum(question_true_similiar_list[:1])/(len(question_true_similiar_list[:1])+0.000001))\n",
    "                \n",
    "                cols_here = ['cnt_finishstrictsimiliar','acctop5_finishstrictsimiliar','acctop1_finishstrictsimiliar',\n",
    "                             'accrate_similiar_strict','acctop1max_similiar_strict']\n",
    "                if columns_need_set is None or np.sum([1 if x in columns_need_set else 0 for x in cols_here])>0:\n",
    "                    question_similiar_strict_list = sorted([acc for i,acc in question_similiar_reverse_strict[question].items() for _ in range(finished_questions[i])], reverse=True)\n",
    "                    res['cnt_finishstrictsimiliar'].append(len(question_similiar_strict_list))\n",
    "                    res['acctop5_finishstrictsimiliar'].append(sum(question_similiar_strict_list[:5])/(len(question_similiar_strict_list[:5])+0.000001))\n",
    "                    res['acctop1_finishstrictsimiliar'].append(sum(question_similiar_strict_list[:1])/(len(question_similiar_strict_list[:1])+0.000001))\n",
    "                \n",
    "                cols_here = ['cnt_accstrictsimiliar','acctop5_accstrictsimiliar','acctop1_accstrictsimiliar',\n",
    "                             'accrate_similiar_strict','acctop1max_similiar_strict']\n",
    "                if columns_need_set is None or np.sum([1 if x in columns_need_set else 0 for x in cols_here])>0:\n",
    "                    question_true_similiar_strict_list = sorted([acc for i,acc in question_true_similiar_reverse_strict[question].items() for _ in range(true_questions[i])], reverse=True)\n",
    "                    res['cnt_accstrictsimiliar'].append(len(question_true_similiar_strict_list))\n",
    "                    res['acctop5_accstrictsimiliar'].append(sum(question_true_similiar_strict_list[:5])/(len(question_true_similiar_strict_list[:5])+0.000001))\n",
    "                    res['acctop1_accstrictsimiliar'].append(sum(question_true_similiar_strict_list[:1])/(len(question_true_similiar_strict_list[:1])+0.000001))\n",
    "\n",
    "                for contentsim_name, contentsim in (('contentsim',question_info_sim),('contentsimstrict',question_info_sim_strict)):\n",
    "                    cols_here = ['cnt_finishsimiliar'+'_'+contentsim_name,'acctop5_finishsimiliar'+'_'+contentsim_name,'acctop1_finishsimiliar'+'_'+contentsim_name,\n",
    "                                 'acctop1max_similiar'+'_'+contentsim_name,'acctop5max_similiar_strict'+'_'+contentsim_name,'accrate_similiar'+'_'+contentsim_name,'acctop5max_similiar'+'_'+contentsim_name]\n",
    "                    if columns_need_set is None or np.sum([1 if x in columns_need_set else 0 for x in cols_here])>0:\n",
    "                        question_similiar_list = sorted([acc for i,acc in question_similiar_reverse[question].items() if i in contentsim[question] for _ in range(finished_questions[i])], reverse=True)\n",
    "                        res['cnt_finishsimiliar'+'_'+contentsim_name].append(len(question_similiar_list))\n",
    "                        res['acctop5_finishsimiliar'+'_'+contentsim_name].append(sum(question_similiar_list[:5])/(len(question_similiar_list[:5])+0.000001))\n",
    "                        res['acctop1_finishsimiliar'+'_'+contentsim_name].append(sum(question_similiar_list[:1])/(len(question_similiar_list[:1])+0.000001))\n",
    "\n",
    "                    cols_here = ['cnt_accsimiliar'+'_'+contentsim_name,'acctop5_accsimiliar'+'_'+contentsim_name,'acctop1_accsimiliar'+'_'+contentsim_name,\n",
    "                                 'accrate_similiar'+'_'+contentsim_name,'acctop5max_similiar'+'_'+contentsim_name,'acctop1max_similiar'+'_'+contentsim_name,'acctop5max_similiar_strict'+'_'+contentsim_name]\n",
    "                    if columns_need_set is None or np.sum([1 if x in columns_need_set else 0 for x in cols_here])>0:\n",
    "                        question_true_similiar_list = sorted([acc for i,acc in question_true_similiar_reverse[question].items() if i in contentsim[question] for _ in range(true_questions[i])], reverse=True)\n",
    "                        res['cnt_accsimiliar'+'_'+contentsim_name].append(len(question_true_similiar_list))\n",
    "                        res['acctop5_accsimiliar'+'_'+contentsim_name].append(sum(question_true_similiar_list[:5])/(len(question_true_similiar_list[:5])+0.000001))\n",
    "                        res['acctop1_accsimiliar'+'_'+contentsim_name].append(sum(question_true_similiar_list[:1])/(len(question_true_similiar_list[:1])+0.000001))\n",
    "\n",
    "                    cols_here = ['cnt_finishstrictsimiliar'+'_'+contentsim_name,'acctop5_finishstrictsimiliar'+'_'+contentsim_name,'acctop1_finishstrictsimiliar'+'_'+contentsim_name,\n",
    "                                 'accrate_similiar_strict'+'_'+contentsim_name,'acctop1max_similiar_strict'+'_'+contentsim_name]\n",
    "                    if columns_need_set is None or np.sum([1 if x in columns_need_set else 0 for x in cols_here])>0:\n",
    "                        question_similiar_strict_list = sorted([acc for i,acc in question_similiar_reverse_strict[question].items() if i in contentsim[question] for _ in range(finished_questions[i])], reverse=True)\n",
    "                        res['cnt_finishstrictsimiliar'+'_'+contentsim_name].append(len(question_similiar_strict_list))\n",
    "                        res['acctop5_finishstrictsimiliar'+'_'+contentsim_name].append(sum(question_similiar_strict_list[:5])/(len(question_similiar_strict_list[:5])+0.000001))\n",
    "                        res['acctop1_finishstrictsimiliar'+'_'+contentsim_name].append(sum(question_similiar_strict_list[:1])/(len(question_similiar_strict_list[:1])+0.000001))\n",
    "\n",
    "                    cols_here = ['cnt_accstrictsimiliar'+'_'+contentsim_name,'acctop5_accstrictsimiliar'+'_'+contentsim_name,'acctop1_accstrictsimiliar'+'_'+contentsim_name,\n",
    "                                 'accrate_similiar_strict'+'_'+contentsim_name,'acctop1max_similiar_strict'+'_'+contentsim_name]\n",
    "                    if columns_need_set is None or np.sum([1 if x in columns_need_set else 0 for x in cols_here])>0:\n",
    "                        question_true_similiar_strict_list = sorted([acc for i,acc in question_true_similiar_reverse_strict[question].items() if i in contentsim[question] for _ in range(true_questions[i])], reverse=True)\n",
    "                        res['cnt_accstrictsimiliar'+'_'+contentsim_name].append(len(question_true_similiar_strict_list))\n",
    "                        res['acctop5_accstrictsimiliar'+'_'+contentsim_name].append(sum(question_true_similiar_strict_list[:5])/(len(question_true_similiar_strict_list[:5])+0.000001))\n",
    "                        res['acctop1_accstrictsimiliar'+'_'+contentsim_name].append(sum(question_true_similiar_strict_list[:1])/(len(question_true_similiar_strict_list[:1])+0.000001))\n",
    "                    \n",
    "                if response == 1:\n",
    "                    true_questions[question] += 1\n",
    "                finished_questions[question] += 1\n",
    "\n",
    "            for similiar_name in ('finishsimiliar','accsimiliar','finishstrictsimiliar','accstrictsimiliar'):\n",
    "                if 'cnt_'+similiar_name in columns_need_set or \\\n",
    "                    ('accrate_similiar' in columns_need_set and similiar_name in ('accsimiliar','finishsimiliar')) or \\\n",
    "                    ('accrate_similiar_strict' in columns_need_set and similiar_name in ('accstrictsimiliar','finishstrictsimiliar')): \n",
    "                    df['cnt_'+similiar_name+'_'+timelimit] = res['cnt_'+similiar_name]\n",
    "                if 'acctop5_'+similiar_name in columns_need_set or \\\n",
    "                    ('acctop5max_similiar' in columns_need_set and similiar_name in ('accsimiliar','finishsimiliar')): \n",
    "                    df['acctop5_'+similiar_name+'_'+timelimit] = res['acctop5_'+similiar_name]\n",
    "                if 'acctop1_'+similiar_name in columns_need_set or \\\n",
    "                    ('acctop1max_similiar' in columns_need_set and similiar_name in ('accsimiliar','finishsimiliar')) or \\\n",
    "                    ('acctop5max_similiar_strict' in columns_need_set and similiar_name in ('accsimiliar','finishsimiliar')) or \\\n",
    "                    ('acctop1max_similiar_strict' in columns_need_set and similiar_name in ('accstrictsimiliar','finishstrictsimiliar')): \n",
    "                    df['acctop1_'+similiar_name+'_'+timelimit] = res['acctop1_'+similiar_name]\n",
    "            if 'accrate_similiar' in columns_need_set: df['accrate_similiar'+'_'+timelimit] = df['cnt_accsimiliar'+'_'+timelimit]/(df['cnt_finishsimiliar'+'_'+timelimit]+0.000001)    \n",
    "            if 'accrate_similiar_strict' in columns_need_set: df['accrate_similiar_strict'+'_'+timelimit] = df['cnt_accstrictsimiliar'+'_'+timelimit]/(df['cnt_finishstrictsimiliar'+'_'+timelimit]+0.000001)\n",
    "            if 'acctop5max_similiar' in columns_need_set: df['acctop5max_similiar'+'_'+timelimit] = df[['acctop5_finishsimiliar'+'_'+timelimit,'acctop5_accsimiliar'+'_'+timelimit]].max(axis=1)    \n",
    "            if 'acctop1max_similiar' in columns_need_set: df['acctop1max_similiar'+'_'+timelimit] = df[['acctop1_finishsimiliar'+'_'+timelimit,'acctop1_accsimiliar'+'_'+timelimit]].max(axis=1)    \n",
    "            if 'acctop5max_similiar_strict' in columns_need_set: df['acctop5max_similiar_strict'+'_'+timelimit] = df[['acctop1_finishsimiliar'+'_'+timelimit,'acctop1_accsimiliar'+'_'+timelimit]].max(axis=1)    \n",
    "            if 'acctop1max_similiar_strict' in columns_need_set: df['acctop1max_similiar_strict'+'_'+timelimit] = df[['acctop1_finishstrictsimiliar'+'_'+timelimit,'acctop1_accstrictsimiliar'+'_'+timelimit]].max(axis=1)\n",
    "\n",
    "            for contentsim_name, contentsim in (('contentsim',question_info_sim),('contentsimstrict',question_info_sim_strict)):\n",
    "                for similiar_name in ('finishsimiliar','accsimiliar','finishstrictsimiliar','accstrictsimiliar'):\n",
    "                    if 'cnt_'+similiar_name+'_'+contentsim_name in columns_need_set or \\\n",
    "                        ('accrate_similiar'+'_'+contentsim_name in columns_need_set and similiar_name in ('accsimiliar','finishsimiliar')) or \\\n",
    "                        ('accrate_similiar_strict'+'_'+contentsim_name in columns_need_set and similiar_name in ('accstrictsimiliar','finishstrictsimiliar')): \n",
    "                        df['cnt_'+similiar_name+'_'+contentsim_name+'_'+timelimit] = res['cnt_'+similiar_name+'_'+contentsim_name]\n",
    "                    if 'acctop5_'+similiar_name+'_'+contentsim_name in columns_need_set or \\\n",
    "                        ('acctop5max_similiar'+'_'+contentsim_name in columns_need_set and similiar_name in ('accsimiliar','finishsimiliar')): \n",
    "                        df['acctop5_'+similiar_name+'_'+contentsim_name+'_'+timelimit] = res['acctop5_'+similiar_name+'_'+contentsim_name]\n",
    "                    if 'acctop1_'+similiar_name+'_'+contentsim_name in columns_need_set or \\\n",
    "                        ('acctop1max_similiar'+'_'+contentsim_name in columns_need_set and similiar_name in ('accsimiliar','finishsimiliar')) or \\\n",
    "                        ('acctop5max_similiar_strict'+'_'+contentsim_name in columns_need_set and similiar_name in ('accsimiliar','finishsimiliar')) or \\\n",
    "                        ('acctop1max_similiar_strict'+'_'+contentsim_name in columns_need_set and similiar_name in ('accstrictsimiliar','finishstrictsimiliar')): \n",
    "                        df['acctop1_'+similiar_name+'_'+contentsim_name+'_'+timelimit] = res['acctop1_'+similiar_name+'_'+contentsim_name]\n",
    "                if 'accrate_similiar'+'_'+contentsim_name in columns_need_set: df['accrate_similiar'+'_'+contentsim_name+'_'+timelimit] = df['cnt_accsimiliar'+'_'+contentsim_name+'_'+timelimit]/(df['cnt_finishsimiliar'+'_'+contentsim_name+'_'+timelimit]+0.000001)    \n",
    "                if 'accrate_similiar_strict'+'_'+contentsim_name in columns_need_set: df['accrate_similiar_strict'+'_'+contentsim_name+'_'+timelimit] = df['cnt_accstrictsimiliar'+'_'+contentsim_name+'_'+timelimit]/(df['cnt_finishstrictsimiliar'+'_'+contentsim_name+'_'+timelimit]+0.000001)\n",
    "                if 'acctop5max_similiar'+'_'+contentsim_name in columns_need_set: df['acctop5max_similiar'+'_'+contentsim_name+'_'+timelimit] = df[['acctop5_finishsimiliar'+'_'+contentsim_name+'_'+timelimit,'acctop5_accsimiliar'+'_'+contentsim_name+'_'+timelimit]].max(axis=1)    \n",
    "                if 'acctop1max_similiar'+'_'+contentsim_name in columns_need_set: df['acctop1max_similiar'+'_'+contentsim_name+'_'+timelimit] = df[['acctop1_finishsimiliar'+'_'+contentsim_name+'_'+timelimit,'acctop1_accsimiliar'+'_'+contentsim_name+'_'+timelimit]].max(axis=1)    \n",
    "                if 'acctop5max_similiar_strict'+'_'+contentsim_name in columns_need_set: df['acctop5max_similiar_strict'+'_'+contentsim_name+'_'+timelimit] = df[['acctop1_finishsimiliar'+'_'+contentsim_name+'_'+timelimit,'acctop1_accsimiliar'+'_'+contentsim_name+'_'+timelimit]].max(axis=1)    \n",
    "                if 'acctop1max_similiar_strict'+'_'+contentsim_name in columns_need_set: df['acctop1max_similiar_strict'+'_'+contentsim_name+'_'+timelimit] = df[['acctop1_finishstrictsimiliar'+'_'+contentsim_name+'_'+timelimit,'acctop1_accstrictsimiliar'+'_'+contentsim_name+'_'+timelimit]].max(axis=1)\n",
    "            if timelimit_value<0:\n",
    "                df = df.iloc[::-1].set_index(idx_raw)\n",
    "            for contentsim_name in ('_contentsim','_contentsimstrict',''):\n",
    "                for similiar_name in ('finishsimiliar','accsimiliar','finishstrictsimiliar','accstrictsimiliar'):\n",
    "                    if 'cnt_'+similiar_name+'_'+contentsim_name in columns_need_set: df['cnt_'+similiar_name+contentsim_name+'_'+timelimit] = df['cnt_'+similiar_name+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                    if 'acctop5_'+similiar_name+'_'+contentsim_name in columns_need_set: df['acctop5_'+similiar_name+contentsim_name+'_'+timelimit] = df['acctop5_'+similiar_name+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                    if 'acctop1_'+similiar_name+'_'+contentsim_name in columns_need_set: df['acctop1_'+similiar_name+contentsim_name+'_'+timelimit] = df['acctop1_'+similiar_name+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                if 'accrate_similiar'+'_'+contentsim_name in columns_need_set: df['accrate_similiar'+contentsim_name+'_'+timelimit] = df['accrate_similiar'+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                if 'accrate_similiar_strict'+'_'+contentsim_name in columns_need_set: df['accrate_similiar_strict'+contentsim_name+'_'+timelimit] = df['accrate_similiar_strict'+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                if 'acctop5max_similiar'+'_'+contentsim_name in columns_need_set: df['acctop5max_similiar'+contentsim_name+'_'+timelimit] = df['acctop5max_similiar'+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                if 'acctop1max_similiar'+'_'+contentsim_name in columns_need_set: df['acctop1max_similiar'+contentsim_name+'_'+timelimit] = df['acctop1max_similiar'+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                if 'acctop5max_similiar_strict'+'_'+contentsim_name in columns_need_set: df['acctop5max_similiar_strict'+contentsim_name+'_'+timelimit] = df['acctop5max_similiar_strict'+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                if 'acctop1max_similiar_strict'+'_'+contentsim_name in columns_need_set: df['acctop1max_similiar_strict'+contentsim_name+'_'+timelimit] = df['acctop1max_similiar_strict'+contentsim_name+'_'+timelimit].astype('float32')\n",
    "                    \n",
    "            return df\n",
    "\n",
    "        \n",
    "        columns_need_set = set(['_'.join(x.split('_')[:-1]) for x in columns_sim_res[1] if '-' not in x and '31536000000' in x])\n",
    "        df = df.groupby('uid').parallel_apply(partial(tmp_func, timelimit_value=365*24*3600*1000,columns_need_set=columns_need_set)).reset_index(drop=True)\n",
    "        columns_need_set = set(['_'.join(x.split('_')[:-1]) for x in columns_sim_res[1] if '-' not in x and '1209600000' in x])\n",
    "        df = df.groupby('uid').parallel_apply(partial(tmp_func, timelimit_value=14*24*3600*1000,columns_need_set=columns_need_set)).reset_index(drop=True)\n",
    "        columns_need_set = set(['_'.join(x.split('_')[:-1]) for x in columns_sim_res[1] if '-' not in x and '86400000' in x])\n",
    "        df = df.groupby('uid').parallel_apply(partial(tmp_func, timelimit_value=24*3600*1000,columns_need_set=columns_need_set)).reset_index(drop=True)\n",
    "        columns_need_set = set(['_'.join(x.split('_')[:-1]) for x in columns_sim_res[1] if '-' not in x and '3600000' in x])\n",
    "        df = df.groupby('uid').parallel_apply(partial(tmp_func, timelimit_value=3600*1000,columns_need_set=columns_need_set)).reset_index(drop=True)\n",
    "        columns_need_set = set(['_'.join(x.split('_')[:-1]) for x in columns_sim_res[1] if '-1209600000' in x])\n",
    "        df = df.groupby('uid').parallel_apply(partial(tmp_func, timelimit_value=-14*24*3600*1000,columns_need_set=columns_need_set)).reset_index(drop=True)\n",
    "        columns_need_set = set(['_'.join(x.split('_')[:-1]) for x in columns_sim_res[1] if '-21600000' in x])\n",
    "        df = df.groupby('uid').parallel_apply(partial(tmp_func, timelimit_value=-6*3600*1000,columns_need_set=columns_need_set)).reset_index(drop=True)\n",
    "        \n",
    "        # 训练、验证集：只需要保存需要预测的就行了\n",
    "        if data_type in ['tr','val']:\n",
    "        #if data_type in ['val']:\n",
    "            df = df[df['response']==-1]\n",
    "\n",
    "        df.fillna(-1, inplace=True)\n",
    "        \n",
    "        # 压缩数据，压缩为指定格式\n",
    "        # df = df[useful_features]\n",
    "        df=df[list(set(kf_or+['uid','timestamp','question','real_response','response','is_enhance','uid_record_cumsum','uid_record_sum']))]\n",
    "        for col,dtype in df.dtypes.items():\n",
    "            if col in useful_features_dtypes:\n",
    "                df[col] = df[col].astype(useful_features_dtypes[col])\n",
    "            elif dtype == 'int64':\n",
    "                if col not in ['timestamp','is_enhance']:\n",
    "                    if df[col].max()<=32767 and df[col].min()>=-32768:\n",
    "                        df[col] = df[col].astype('int16')\n",
    "                    else:\n",
    "                        df[col] = df[col].astype('int32')\n",
    "            elif dtype == 'float64':\n",
    "                df[col] = df[col].astype('float32')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    df_tr['real_response'] = df_tr['response']\n",
    "    df_tr['is_enhance'] = 0\n",
    "    df_test['real_response'] = df_test['response']\n",
    "    df_test['is_enhance'] = 0\n",
    "    \n",
    "    # 计算sim矩阵\n",
    "    df_tr_tmp = df_tr.copy()\n",
    "    df_tr_tmp.loc[(df_tr_tmp['uid_record_cumsum']>=df_tr_tmp['uid_record_sum']*0.5)&(df_tr_tmp['uid_record_cumsum']>=90), 'response'] = -1\n",
    "    get_sim_metrix(df_tr_tmp, df_test)\n",
    "    del df_tr_tmp\n",
    "    gc.collect()\n",
    "    \n",
    "    df_test = calc_uid_features(df_test, append_columns=True, data_type='test')\n",
    "    if save_files is not None:\n",
    "        df_test.reset_index(drop=True).to_feather(save_files[2])\n",
    "    gc.collect()\n",
    "\n",
    "    data_type, data_enhance = ('val',val_data_enhance)\n",
    "    if df_val is not None and data_enhance>0:\n",
    "        df_val['real_response'] = df_val['response']\n",
    "        df_val['is_enhance'] = 0\n",
    "        dfs = []\n",
    "        rng = np.random.default_rng(seed)\n",
    "        for _ in range(0, data_enhance):\n",
    "            print('val enhance', _)\n",
    "            # 只选取范围内（尝试截断，比如k不能大于3/4）\n",
    "            df_tmp = df_val.copy()\n",
    "            k = rng.random()*0.5+0.25 if _ != 0 else 0.5\n",
    "            df_tmp.loc[(df_tmp['uid_record_cumsum']>=df_tmp['uid_record_sum']*k)&(df_tmp['uid_record_cumsum']>=90), 'response'] = -1\n",
    "            # 超过k*2范围的数据就不要了\n",
    "            tmp = calc_uid_features(df_tmp[(df_tmp['uid_record_cumsum']<=df_tmp['uid_record_sum']*k*2)], data_type=data_type)\n",
    "            tmp['is_enhance'] = _\n",
    "            dfs.append(tmp)\n",
    "            gc.collect()\n",
    "        df_val = pd.concat(dfs, axis=0)\n",
    "        if save_files is not None:\n",
    "            df_val.reset_index(drop=True).to_feather(save_files[1])\n",
    "        gc.collect()\n",
    "    \n",
    "    data_type, data_enhance = ('tr',tr_data_enhance)\n",
    "    if data_enhance>0:\n",
    "        dfs = []\n",
    "        rng = np.random.default_rng(seed)\n",
    "        for _ in range(0, data_enhance):\n",
    "            print('tr enhance', _)\n",
    "            # 只选取范围内（尝试截断，比如k不能大于3/4）\n",
    "            df_tmp = df_tr.copy()\n",
    "            k = rng.random()*0.5+0.25 if _ != 0 else 0.5\n",
    "            df_tmp.loc[(df_tmp['uid_record_cumsum']>=df_tmp['uid_record_sum']*k)&(df_tmp['uid_record_cumsum']>=90), 'response'] = -1\n",
    "            # 更新sim矩阵\n",
    "            get_sim_metrix(df_tmp, df_test)\n",
    "            # 超过k*2范围的数据就不要了\n",
    "            tmp = calc_uid_features(df_tmp[(df_tmp['uid_record_cumsum']<=df_tmp['uid_record_sum']*k*2)], data_type=data_type)\n",
    "            tmp = tmp.copy()\n",
    "            tmp.reset_index(drop=True, inplace=True)\n",
    "            tmp['is_enhance'] = _\n",
    "            dfs.append(tmp)\n",
    "            gc.collect()\n",
    "        print('merging df_tr')\n",
    "        df_tr = pd.concat(dfs, axis=0)\n",
    "        del dfs\n",
    "        if save_files is not None:\n",
    "            print('resetindex df_tr')\n",
    "            df_tr.reset_index(drop=True, inplace=True)\n",
    "            print('tofeather df_tr')\n",
    "            df_tr.to_feather(save_files[0])\n",
    "        gc.collect()\n",
    "    gc.collect()\n",
    "    \n",
    "    if save_files is not None:\n",
    "        return \n",
    "    if df_val is not None:\n",
    "        return df_tr, df_val, df_test, columns\n",
    "    else:\n",
    "        return df_tr, df_test, columns\n",
    "\n",
    "\"\"\"\n",
    "df_tmp,df_tmp2, df_tmp3, columns_tmp = feature_engineering2(df.iloc[:3000].copy(), df_test.iloc[:3000].copy(), df_val=df.iloc[3000:6000].copy(), \n",
    "                                         tr_data_enhance=2, val_data_enhance=1)\n",
    "print(columns_tmp)\n",
    "df_tmp\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T06:00:38.080822Z",
     "start_time": "2022-12-19T06:00:35.380921Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_tr2,df_test2, columns_tmp = feature_engineering2(df.copy(), df_test.copy(), df_val=None, tr_data_enhance=0, val_data_enhance=0)\n",
    "#df_test2.reset_index(drop=True).to_feather(f'./input/cache/cache_df_test_vj-sim2.101_1_0_tmp.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T14:16:06.753259Z",
     "start_time": "2022-12-30T14:15:48.632880Z"
    }
   },
   "outputs": [],
   "source": [
    "emb_p = pd.read_csv('input/question_w2v_emb_all_test_window256_iter10.csv')  # 'item', 'embedding''18.2343,13.352396,-4.3354278,27.098478,25.468166'\n",
    "def split_emb_func(row):\n",
    "    row['emb1'],row['emb2'],row['emb3'],row['emb4'],row['emb5'] = map(float,row['embedding'].split(','))\n",
    "    return row\n",
    "emb_p = emb_p.apply(split_emb_func,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T14:04:38.618704Z",
     "start_time": "2022-12-30T14:04:38.600686Z"
    }
   },
   "outputs": [],
   "source": [
    "def try_predict(df, columns, y_col, lgb_params, kf, metrics, df_test=None, \n",
    "                debug=0, is_try=0, verbose=1, without_columns=None, with_columns=None, tr_data_enhance=3, val_data_enhance=1, \n",
    "                seed=1, version='v1', use_focal_loss=False, weight_func=None, only_save=False):\n",
    "    gc.collect()\n",
    "    if debug==0:\n",
    "        debug = 9999999999\n",
    "    #y_hat = np.zeros(df.iloc[:debug].shape[0])\n",
    "    if df_test is not None:\n",
    "        y_test = np.zeros(df_test.shape[0])\n",
    "    res = []\n",
    "    for kf_i, (tr_idx,val_idx) in enumerate(kf):\n",
    "        if is_try>0 and kf_i+1 != is_try:\n",
    "            continue\n",
    "        df_tr, df_val = df.iloc[tr_idx[:debug]], df.iloc[val_idx[:debug]]\n",
    "        \n",
    "        # 特征工程\n",
    "        if verbose: print(datetime.datetime.now(), 'feature_engineering...')\n",
    "        if not os.path.exists('./input/cache'): os.mkdir('./input/cache')\n",
    "        if not os.path.exists(f'./input/cache/cache_df_tr_{str(version)}_{str(seed)}_{str(kf_i)}.feather'):\n",
    "            save_files = [f'./input/cache/cache_df_tr_{str(version)}_{str(seed)}_{str(kf_i)}.feather',\n",
    "                          f'./input/cache/cache_df_val_{str(version)}_{str(seed)}_{str(kf_i)}.feather',\n",
    "                         f'./input/cache/cache_df_test_{str(version)}_{str(seed)}_{str(kf_i)}.feather']\n",
    "            #df_tr, df_val, df_test2, columns2 = \n",
    "            feature_engineering2(df_tr.copy(), df_test.copy(), df_val=df_val.copy(), \n",
    "                                                      tr_data_enhance=tr_data_enhance, val_data_enhance=val_data_enhance,seed=seed,save_files=save_files)\n",
    "            gc.collect()\n",
    "            #df_tr.reset_index(drop=True).to_feather(f'./input/cache/cache_df_tr_{str(version)}_{str(seed)}_{str(kf_i)}.feather')\n",
    "            #df_val.reset_index(drop=True).to_feather(f'./input/cache/cache_df_val_{str(version)}_{str(seed)}_{str(kf_i)}.feather')\n",
    "            #df_test2.reset_index(drop=True).to_feather(f'./input/cache/cache_df_test_{str(version)}_{str(seed)}_{str(kf_i)}.feather')\n",
    "        else:\n",
    "            df_tr = pd.read_feather(f'./input/cache/cache_df_tr_{str(version)}_{str(seed)}_{str(kf_i)}.feather').reset_index(drop=True)\n",
    "            df_val = pd.read_feather(f'./input/cache/cache_df_val_{str(version)}_{str(seed)}_{str(kf_i)}.feather').reset_index(drop=True)\n",
    "            df_test2 = pd.read_feather(f'./input/cache/cache_df_test_{str(version)}_{str(seed)}_{str(kf_i)}.feather').reset_index(drop=True)\n",
    "        df_tr = df_tr.merge(emb_p[['item','emb1','emb2','emb3','emb4','emb5']],how='left',left_on='question',right_on='item')\n",
    "        df_val = df_val.merge(emb_p[['item','emb1','emb2','emb3','emb4','emb5']],how='left',left_on='question',right_on='item')\n",
    "        df_test2 = df_test2.merge(emb_p[['item','emb1','emb2','emb3','emb4','emb5']],how='left',left_on='question',right_on='item')\n",
    "\n",
    "\n",
    "        x_cols = [x for x in df_tr.columns if x not in [y_col]+without_columns] if with_columns is None else with_columns+['emb1','emb2','emb3','emb4','emb5']\n",
    "\n",
    "        if only_save:\n",
    "            continue \n",
    "        if weight_func is not None:\n",
    "            weight_tr, weight_val = weight_func(df_tr), weight_func(df_val)\n",
    "        else:\n",
    "            weight_tr, weight_val = None, None\n",
    "        \n",
    "        df_test2.loc[df_test2['question_accrate']==-1, 'question_accrate'] = np.nan\n",
    "        \n",
    "        # lgb\n",
    "        lgb_train = lgb.Dataset(df_tr.loc[df_tr['response']==-1,x_cols].to_numpy(dtype='float32'), df_tr.loc[df_tr['response']==-1,y_col], weight=weight_tr)\n",
    "        df_tr = None\n",
    "        gc.collect()\n",
    "        #lgb_train = lgb.Dataset(df_tr[x_cols], df_tr[y_col])\n",
    "        lgb_val = lgb.Dataset(df_val.loc[df_val['response']==-1,x_cols].to_numpy(dtype='float32'), df_val.loc[df_val['response']==-1,y_col], weight=weight_val)\n",
    "        gc.collect()\n",
    "        #lgb_val = lgb.Dataset(df_val[x_cols], df_val[y_col])\n",
    "        if verbose: print(datetime.datetime.now(), 'training...')\n",
    "        if use_focal_loss:\n",
    "            model = lgb.train(lgb_params,lgb_train,num_boost_round=100000,valid_sets=[lgb_val],early_stopping_rounds=30,verbose_eval=100,fobj=focal_loss) #,feval=eval_error)\n",
    "        else:\n",
    "            model = lgb.train(lgb_params,lgb_train,num_boost_round=100000,valid_sets=[lgb_val],early_stopping_rounds=30,verbose_eval=100)\n",
    "        if verbose: print(datetime.datetime.now(), 'evaluating...')\n",
    "        y_val_pred = model.predict(df_val[x_cols])\n",
    "        score = metrics[0](df_val.loc[df_val['response']==-1, y_col], y_val_pred[np.where(df_val['response']==-1)[0]])\n",
    "        res.append(list([metrics[0](df_val[y_col], y_val_pred), metrics[0](df_val[y_col], y_val_pred, sample_weight=weight_val)]) + \n",
    "                   list([metrics[0](df_val.loc[(df_val['response']==-1)&(df_val['is_enhance']==0), y_col], y_val_pred[np.where((df_val['response']==-1)&(df_val['is_enhance']==0))[0]]),\n",
    "                        score]))\n",
    "        #res.append(list([metric(df_val[y_col], y_val_pred, df_val[x_cols]) for metric in metrics]) )\n",
    "        if verbose: print(datetime.datetime.now(), 'now score:', res)\n",
    "        #y_hat[val_idx] = y_val_pred\n",
    "        if df_test2 is not None:\n",
    "            y_pred_test = model.predict(df_test2[x_cols])\n",
    "            y_test += y_pred_test\n",
    "            y_pred_test = pd.DataFrame(np.array(y_pred_test).reshape(-1,1), columns=['pred'])\n",
    "            y_pred_test.to_feather(f'./output/pred_lgbms_{str(round(score,6))}_fold{kf_i}_{datetime.datetime.now().strftime(\"%y%m%d-%H%M%S\")}_.feather')\n",
    "\n",
    "        if is_try:\n",
    "            break\n",
    "    if df_test is not None:\n",
    "        return res, y_test/(len(kf) if not is_try else 1.0)\n",
    "    else:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T14:06:07.673045Z",
     "start_time": "2022-12-30T14:06:07.666161Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': ['auc'],\n",
    "    'num_leaves': 474, \n",
    "    'max_depth': 12, \n",
    "    'learning_rate': 0.1407968542304061,\n",
    "    'feature_fraction': 0.4,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_freq': 1,\n",
    "    \"lambda_l2\": 0.03796153986418542,\n",
    "    \"lambda_l1\": 3.8922663169769365,\n",
    "    'max_bin':152,\n",
    "    'min_data_in_bin':110,\n",
    "    'min_data_in_leaf':241,\n",
    "    'min_gain_to_split':0.35000000000000003,\n",
    "    'subsample':0.7402345943066192,\n",
    "    \"nthread\": -1,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "lgb_params_jiangxing1227={'bagging_fraction': 0.5, 'boosting': 'goss', 'feature_fraction': 0.7000000000000001, 'lambda_l1': 1.2023047772488058e-05, 'lambda_l2': 0.24166153734311607, 'learning_rate': 0.010847402166847181, 'max_bin': 248, 'max_depth': 11, 'metric': 'binary_logloss', 'min_data_in_bin': 256, 'min_data_in_leaf': 165, 'min_gain_to_split': 3.6, 'nthread': -1, 'num_leaves': 379, 'objective': 'cross_entropy', 'seed': 1, 'verbose': -1, 'verbosity': -1, 'top_rate': 0.08755113350652709, 'other_rate': 0.40917745426269403, 'subsample': 1.0}\n",
    "lgb_params_jiangxing1230gbdt={'bagging_fraction': 0.45, 'boosting': 'gbdt', 'feature_fraction': 0.35000000000000003, 'lambda_l1': 4.5816175014092746e-05, 'lambda_l2': 5.8867950364954655, 'learning_rate': 0.03707980348379979, 'max_bin': 152, 'max_depth': 12, 'metric': 'auc', 'min_data_in_bin': 231, 'min_data_in_leaf': 47, 'min_gain_to_split': 2.95, 'nthread': -1, 'num_leaves': 369, 'objective': 'cross_entropy', 'seed': 1, 'verbose': -1, 'verbosity': -1, 'subsample': 0.7576548599070091}\n",
    "\n",
    "without_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T14:05:09.598735Z",
     "start_time": "2022-12-30T14:05:09.592086Z"
    }
   },
   "outputs": [],
   "source": [
    "with_columns=['uid_concept_utilnow_94608000_desc', 'time_hour_accrate', 'concepttype_mean_showcnt', 'time_weekday', 'uid_timestamp_showcnt', 'concept_min_accrate', 'uid_accrate', 'question_accrate', 'kc_showcnt_4', 'question_showcnt', 'uid_concept_utilnow_3600_asc', 'concept_max_accrate', 'kc_type_showcnt_1', 'kc_3', 'concept_type_accrate_1', 'uid_showcnt', 'time_day', 'question', 'timestamp_question_cnt', 'concept_mean_accrate', 'uid_concept_utilnow_21600_asc', 'uid_concept_accrate_4', 'kc_2', 'uidconcepttype_max_accrate', 'type_accrate', 'analysis_cnt', 'kc_max_accrate', 'concept_min_showcnt', 'uidkc_mean_accrate'] + \\\n",
    "['cnt_finishsimiliar', 'acctop5_finishsimiliar',\n",
    "       'acctop1_finishsimiliar', 'cnt_accsimiliar', 'acctop5_accsimiliar',\n",
    "       'acctop1_accsimiliar', 'cnt_finishstrictsimiliar',\n",
    "       'acctop5_finishstrictsimiliar', 'acctop1_finishstrictsimiliar',\n",
    "       'cnt_accstrictsimiliar', 'acctop5_accstrictsimiliar',\n",
    "       'acctop1_accstrictsimiliar', 'accrate_similiar',\n",
    "       'accrate_similiar_strict', 'acctop5max_similiar',\n",
    "       'acctop1max_similiar', 'acctop5max_similiar_strict',\n",
    "       'acctop1max_similiar_strict']\n",
    "without_columns = ['uid','response','timestamp','data_type','real_response','is_enhance']\n",
    "with_columns = ['acctop5_finishstrictsimiliar_contentsim_-21600000', 'content_cnt', 'kc_type_accrate_5', 'accrate_similiar_31536000000', 'cnt_finishstrictsimiliar_31536000000', 'timestamp', 'uid_unique_submittimes_3600_asc', 'acctop1_accstrictsimiliar_31536000000', 'acctop1_finishstrictsimiliar_31536000000', 'uid_concept_type_accrate_6', 'uid_kc_accrate_6', 'concepttype_min_showcnt', 'kc_6', 'concept_min_showcnt', 'kc_type_showcnt_5', 'uid_question_utilnow_21600_asc', 'concept_mean_accrate', 'uid_question_utilnow_3600_asc', 'acctop5max_similiar_contentsim_-21600000', 'time_hour_accrate', 'uid_concept_utilnow_21600_asc', 'cnt_finishstrictsimiliar_contentsim_-21600000', 'acctop1_finishsimiliar_31536000000', 'acctop5_finishstrictsimiliar_31536000000', 'kc_showcnt_4', 'question_accrate', 'accrate_similiar_strict_31536000000', 'acctop5_finishstrictsimiliar_contentsimstrict_-21600000', 'acctop5_finishstrictsimiliar_-21600000', 'uid_question_utilnow_21600_desc', 'timestamp_question_cnt', 'new_question_days', 'uid_concept_utilnow_3600_asc', 'cnt_finishsimiliar_contentsim_-21600000', 'type_accrate', 'concept_type_accrate_1', 'uid_continue_learning_mins', 'concept_accrate_1', 'acctop1max_similiar_strict_contentsimstrict_-21600000', 'uid_timedistance_to_last_submit_desc', 'question_showcnt', 'acctop5max_similiar_strict_31536000000', 'uid_question_utilnow_1314000_desc', 'kc_type_showcnt_6', 'acctop5max_similiar_strict_-21600000', 'uid_concept_utilnow_259200_asc', 'acctop1_accsimiliar_31536000000', 'acctop5max_similiar_strict_contentsim_-21600000', 'cnt_finishstrictsimiliar_-21600000', 'acctop1max_similiar_strict_contentsim_-21600000', 'timediff1', 'uid_accrate', 'uid_concept_type_accrate_2', 'acctop5max_similiar_strict_contentsimstrict_-21600000', 'cnt_accstrictsimiliar_31536000000', 'uid_timestamp_question_meansubmit', 'kc_group_cnt', 'kc_type_accrate_7', 'cnt_accsimiliar_31536000000', 'uid_question_utilnow_259200_asc', 'uid_question_utilnow_31536000_asc', 'uid_timestamp_showcnt', 'acctop5_finishsimiliar_31536000000', 'cnt_finishsimiliar_contentsimstrict_-21600000', 'concept_type_showcnt_1', 'time_weekday_accrate', 'acctop5_accstrictsimiliar_31536000000', 'cnt_finishsimiliar_-21600000', 'acctop5max_similiar_contentsimstrict_-21600000', 'question', 'acctop1max_similiar_strict_-21600000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_by_uid(df, n_splits=3, weight='uid-length'):\n",
    "    # 加权采样，根据uid的长短进行加权\n",
    "    if weight == 'uid-length':\n",
    "        weight = df['uid'].value_counts()\n",
    "        weight = pd.cut(weight, [0, 200, 350, 450, 10000], labels=False).reset_index().rename(columns={'uid':'weight_col','index':'uid'})  # index:uid, uid:桶编号\n",
    "    elif weight == 'uid-accrate':\n",
    "        weight = df.groupby('uid')['response'].mean()\n",
    "        weight = pd.cut(weight, list(range(0,101,5)), labels=False).reset_index().rename(columns={'response':'weight_col'})\n",
    "    # 采样\n",
    "    kf_uid = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1).split(weight,weight['weight_col']))\n",
    "    res = []\n",
    "    for (kf_tr, kf_val) in kf_uid:\n",
    "        tr_uid = set([weight.loc[i, 'uid'] for i in kf_tr])\n",
    "        tr = np.where(df['uid'].isin(tr_uid))[0]\n",
    "        val = np.where(~df['uid'].isin(tr_uid))[0]\n",
    "        res.append((tr,val))\n",
    "    return res\n",
    "\n",
    "# 计算测试集的 uid_accrate 样本分布\n",
    "df_test_uid_acc = [0]*20  # range(0,100,5)\n",
    "for i,row in df_test.groupby(['uid'])['uid_accrate'].agg(['max','count']).iterrows():\n",
    "    x = row['max']\n",
    "    d = int(x//0.05) if int(x//0.05)<20 else 19\n",
    "    df_test_uid_acc[d]+=row['count']\n",
    "df_test_uid_acc = df_test_uid_acc / np.sum(df_test_uid_acc)\n",
    "def weight_func(df):\n",
    "    df_uid_acc = [0]*20  # range(0,100,5)\n",
    "    for i,row in df.groupby(['uid'])['uid_accrate'].agg(['max','count']).iterrows():\n",
    "        x = row['max']\n",
    "        d = int(x//0.05) if int(x//0.05)<20 else 19\n",
    "        df_uid_acc[d]+=row['count']\n",
    "    df_uid_acc = df_uid_acc / np.sum(df_uid_acc)\n",
    "    weight_bin = (df_test_uid_acc/df_uid_acc)\n",
    "    weight_bin[weight_bin>5]=0\n",
    "    return np.array(df['uid_accrate'].apply(lambda x: weight_bin[int(x//0.05)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_n_splits = 10\n",
    "kf = kfold_by_uid(df, n_splits=kf_n_splits, weight='uid-length')\n",
    "metric = lambda y,y_hat,*args,**argvs: roc_auc_score(y,y_hat)\n",
    "\n",
    "\n",
    "# 生成数据\n",
    "score, y_test1 = try_predict(df, columns, 'real_response', lgb_params, kf, [roc_auc_score], df_test=df_test, \n",
    "                             debug=0, is_try=0, verbose=1, without_columns=without_columns, with_columns=kf0, \n",
    "                             tr_data_enhance=10, val_data_enhance=1, seed=3, version='vj-sim3_10.101', use_focal_loss=False, weight_func=weight_func,\n",
    "                            only_save=True)\n",
    "\n",
    "for with_columns in [kf0,kf1,kf9]:\n",
    "    for lgb_params in [lgb_params_jiangxing1227, lgb_params_jiangxing1230gbdt]:\n",
    "        gc.collect()\n",
    "        # 模型训练\n",
    "        score, y_test1 = try_predict(df, columns, 'real_response', lgb_params, kf, [roc_auc_score], df_test=df_test, \n",
    "                                     debug=0, is_try=0, verbose=1, without_columns=without_columns, with_columns=with_columns, \n",
    "                                     tr_data_enhance=10, val_data_enhance=1, seed=3, version='vj-sim3_10.101', use_focal_loss=False, weight_func=weight_func,\n",
    "                                    only_save=False)\n",
    "        gc.collect()\n",
    "        print(score) # 删第一块数据\n",
    "        print(np.mean(score,axis=0)) # score, weighted, enhance=0, score\n",
    "    #my_final_sub(y_test1, output_name=f'./submission/baseline_simv2_k5_101_kf_all_tune.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_n_splits = 20\n",
    "kf = kfold_by_uid(df, n_splits=kf_n_splits, weight='uid-length')\n",
    "metric = lambda y,y_hat,*args,**argvs: roc_auc_score(y,y_hat)\n",
    "\n",
    "# 生成数据\n",
    "score, y_test1 = try_predict(df, columns, 'real_response', lgb_params, kf, [roc_auc_score], df_test=df_test, \n",
    "                             debug=0, is_try=0, verbose=1, without_columns=without_columns, with_columns=kf0, \n",
    "                             tr_data_enhance=20, val_data_enhance=1, seed=3, version='vj-sim3_20.201', use_focal_loss=False, weight_func=weight_func,\n",
    "                            only_save=True)\n",
    "\n",
    "for with_columns in [kf0,kf1,kf9]:\n",
    "    for lgb_params in [lgb_params_jiangxing1227, lgb_params_jiangxing1230gbdt]:\n",
    "        gc.collect()\n",
    "        # 模型训练\n",
    "        score, y_test1 = try_predict(df, columns, 'real_response', lgb_params, kf, [roc_auc_score], df_test=df_test, \n",
    "                                     debug=0, is_try=0, verbose=1, without_columns=without_columns, with_columns=with_columns, \n",
    "                                     tr_data_enhance=20, val_data_enhance=1, seed=3, version='vj-sim3_20.201', use_focal_loss=False, weight_func=weight_func,\n",
    "                                    only_save=False)\n",
    "        gc.collect()\n",
    "        print(score) # 删第一块数据\n",
    "        print(np.mean(score,axis=0)) # score, weighted, enhance=0, score\n",
    "        #my_final_sub(y_test1, output_name=f'./submission/baseline_simv2_k5_101_kf_all_tune.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = None\n",
    "for file in os.listdir('output'):\n",
    "    tmp = np.array(pd.read_feather('output/'+file)['pred'])\n",
    "    if y_test is None:\n",
    "        y_test = np.zeros_like(tmp)\n",
    "    y_test += tmp\n",
    "my_final_sub(y_test, output_name=f'./submission/ensemble_final.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fs2]",
   "language": "python",
   "name": "conda-env-fs2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "334px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
